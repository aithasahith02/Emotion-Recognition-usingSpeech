{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rSku0_cX3dB"
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWJ9phRhUDrM"
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NI3q89z5YLVq"
   },
   "outputs": [],
   "source": [
    "def load_data(train_size=0.8,test_size=0.2):\n",
    "    X, y = [], []\n",
    "    try :\n",
    "        for file in glob.glob(\"C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset/Actor_*/*.wav\"):\n",
    "            # get the base name of the audio file\n",
    "            print(file)\n",
    "            basename = os.path.basename(file)\n",
    "            print(basename)\n",
    "          # get the emotion label\n",
    "            emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "          # we allow only AVAILABLE_EMOTIONS we set\n",
    "            if emotion not in AVAILABLE_EMOTIONS:\n",
    "                continue\n",
    "          # extract speech features\n",
    "            features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "          # add to data\n",
    "            X.append(features)\n",
    "            l={'happy':0.0,'sad':1.0,'neutral':3.0,'angry':4.0}\n",
    "            y.append(l[emotion])\n",
    "    except :\n",
    "         pass\n",
    "    # split the data to training and testing and return it\n",
    "    return train_test_split(np.array(X), y, test_size=test_size,train_size=train_size,random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "AVAILABLE_EMOTIONS = {\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"neutral\",\n",
    "    \"happy\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "p7USodbIYQli",
    "outputId": "7fd11920-7a3e-405e-a828-3f7d50aa97ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-01-01-01.wav\n",
      "03-01-01-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-01-02-01.wav\n",
      "03-01-01-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-02-01-01.wav\n",
      "03-01-01-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-02-02-01.wav\n",
      "03-01-01-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-01-01-01.wav\n",
      "03-01-02-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-01-02-01.wav\n",
      "03-01-02-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-02-01-01.wav\n",
      "03-01-02-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-02-02-01.wav\n",
      "03-01-02-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-01-01-01.wav\n",
      "03-01-02-02-01-01-01.wav"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-01-02-01.wav\n",
      "03-01-02-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-02-01-01.wav\n",
      "03-01-02-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-02-02-01.wav\n",
      "03-01-02-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-01-01-01.wav\n",
      "03-01-03-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-01-02-01.wav\n",
      "03-01-03-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-02-01-01.wav\n",
      "03-01-03-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-02-02-01.wav\n",
      "03-01-03-01-02-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-01-01-01.wav\n",
      "03-01-03-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-01-02-01.wav\n",
      "03-01-03-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-02-01-01.wav\n",
      "03-01-03-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-02-02-01.wav\n",
      "03-01-03-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-01-01-01.wav\n",
      "03-01-04-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-01-02-01.wav\n",
      "03-01-04-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-02-01-01.wav\n",
      "03-01-04-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-02-02-01.wav\n",
      "03-01-04-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-01-01-01.wav\n",
      "03-01-04-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-01-02-01.wav\n",
      "03-01-04-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-02-01-01.wav\n",
      "03-01-04-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-02-02-01.wav\n",
      "03-01-04-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-01-01-01.wav\n",
      "03-01-05-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-01-02-01.wav\n",
      "03-01-05-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-02-01-01.wav\n",
      "03-01-05-01-02-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.00061035 -0.00048828 -0.00039673 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.00231934  0.00213623 -0.00231934 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-02-02-01.wav\n",
      "03-01-05-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-01-01-01.wav\n",
      "03-01-05-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-01-02-01.wav\n",
      "03-01-05-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-02-01-01.wav\n",
      "03-01-05-02-02-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 7.3242188e-04  1.0986328e-03 -6.7138672e-04 ...  9.1552734e-05\n",
      "  3.6621094e-04  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.00033569 0.00024414 0.00024414 ... 0.00036621 0.00033569 0.00045776] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-02-02-01.wav\n",
      "03-01-05-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-01-01-01.wav\n",
      "03-01-06-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-01-02-01.wav\n",
      "03-01-06-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-02-01-01.wav\n",
      "03-01-06-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-02-02-01.wav\n",
      "03-01-06-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-01-01-01.wav\n",
      "03-01-06-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-01-02-01.wav\n",
      "03-01-06-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-02-01-01.wav\n",
      "03-01-06-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-02-02-01.wav\n",
      "03-01-06-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-01-01-01.wav\n",
      "03-01-07-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-01-02-01.wav\n",
      "03-01-07-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-02-01-01.wav\n",
      "03-01-07-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-02-02-01.wav\n",
      "03-01-07-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-01-01-01.wav\n",
      "03-01-07-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-01-02-01.wav\n",
      "03-01-07-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-02-01-01.wav\n",
      "03-01-07-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-02-02-01.wav\n",
      "03-01-07-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-01-01-01.wav\n",
      "03-01-08-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-01-02-01.wav\n",
      "03-01-08-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-02-01-01.wav\n",
      "03-01-08-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-02-02-01.wav\n",
      "03-01-08-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-01-01-01.wav\n",
      "03-01-08-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-01-02-01.wav\n",
      "03-01-08-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-02-01-01.wav\n",
      "03-01-08-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-02-02-01.wav\n",
      "03-01-08-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-01-01-02.wav\n",
      "03-01-01-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-01-02-02.wav\n",
      "03-01-01-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-02-01-02.wav\n",
      "03-01-01-01-02-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-02-02-02.wav\n",
      "03-01-01-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-01-01-02.wav\n",
      "03-01-02-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-01-02-02.wav\n",
      "03-01-02-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-02-01-02.wav\n",
      "03-01-02-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-02-02-02.wav\n",
      "03-01-02-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-01-01-02.wav\n",
      "03-01-02-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-01-02-02.wav\n",
      "03-01-02-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-02-01-02.wav\n",
      "03-01-02-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-02-02-02.wav\n",
      "03-01-02-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-01-01-02.wav\n",
      "03-01-03-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-01-02-02.wav\n",
      "03-01-03-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-02-01-02.wav\n",
      "03-01-03-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-02-02-02.wav\n",
      "03-01-03-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-01-01-02.wav\n",
      "03-01-03-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-01-02-02.wav\n",
      "03-01-03-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-02-01-02.wav\n",
      "03-01-03-02-02-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-02-02-02.wav\n",
      "03-01-03-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-01-01-02.wav\n",
      "03-01-04-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-01-02-02.wav\n",
      "03-01-04-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-02-01-02.wav\n",
      "03-01-04-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-02-02-02.wav\n",
      "03-01-04-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-01-01-02.wav\n",
      "03-01-04-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-01-02-02.wav\n",
      "03-01-04-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-02-01-02.wav\n",
      "03-01-04-02-02-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-02-02-02.wav\n",
      "03-01-04-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-01-01-02.wav\n",
      "03-01-05-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-01-02-02.wav\n",
      "03-01-05-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-02-01-02.wav\n",
      "03-01-05-01-02-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-02-02-02.wav\n",
      "03-01-05-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-01-01-02.wav\n",
      "03-01-05-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-01-02-02.wav\n",
      "03-01-05-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-02-01-02.wav\n",
      "03-01-05-02-02-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-02-02-02.wav\n",
      "03-01-05-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-01-01-02.wav\n",
      "03-01-06-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-01-02-02.wav\n",
      "03-01-06-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-02-01-02.wav\n",
      "03-01-06-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-02-02-02.wav\n",
      "03-01-06-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-01-01-02.wav\n",
      "03-01-06-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-01-02-02.wav\n",
      "03-01-06-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-02-01-02.wav\n",
      "03-01-06-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-02-02-02.wav\n",
      "03-01-06-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-01-01-02.wav\n",
      "03-01-07-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-01-02-02.wav\n",
      "03-01-07-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-02-01-02.wav\n",
      "03-01-07-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-02-02-02.wav\n",
      "03-01-07-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-01-01-02.wav\n",
      "03-01-07-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-01-02-02.wav\n",
      "03-01-07-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-02-01-02.wav\n",
      "03-01-07-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-02-02-02.wav\n",
      "03-01-07-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-01-01-02.wav\n",
      "03-01-08-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-01-02-02.wav\n",
      "03-01-08-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-02-01-02.wav\n",
      "03-01-08-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-02-02-02.wav\n",
      "03-01-08-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-01-01-02.wav\n",
      "03-01-08-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-01-02-02.wav\n",
      "03-01-08-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-02-01-02.wav\n",
      "03-01-08-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-02-02-02.wav\n",
      "03-01-08-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-01-01-03.wav\n",
      "03-01-01-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-01-02-03.wav\n",
      "03-01-01-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-02-01-03.wav\n",
      "03-01-01-01-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  6.1035156e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-02-02-03.wav\n",
      "03-01-01-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-01-01-03.wav\n",
      "03-01-02-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-01-02-03.wav\n",
      "03-01-02-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-02-01-03.wav\n",
      "03-01-02-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-02-02-03.wav\n",
      "03-01-02-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-01-01-03.wav\n",
      "03-01-02-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-01-02-03.wav\n",
      "03-01-02-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-02-01-03.wav\n",
      "03-01-02-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-02-02-03.wav\n",
      "03-01-02-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-01-01-03.wav\n",
      "03-01-03-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-01-02-03.wav\n",
      "03-01-03-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-02-01-03.wav\n",
      "03-01-03-01-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  9.1552734e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 5.1879883e-04 -6.1035156e-05 -4.2724609e-04 ...  0.0000000e+00\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-02-02-03.wav\n",
      "03-01-03-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-01-01-03.wav\n",
      "03-01-03-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-01-02-03.wav\n",
      "03-01-03-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-02-01-03.wav\n",
      "03-01-03-02-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.5258789e-04 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.00027466 -0.00024414 -0.00027466 ... -0.00015259 -0.00021362\n",
      " -0.00024414] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-04 -1.0986328e-03 ...  2.7465820e-04\n",
      "  3.0517578e-04  3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -1.5258789e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-02-02-03.wav\n",
      "03-01-03-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-01-01-03.wav\n",
      "03-01-04-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-01-02-03.wav\n",
      "03-01-04-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-02-01-03.wav\n",
      "03-01-04-01-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 6.1035156e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00042725 -0.00039673\n",
      " -0.00033569] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  2.7465820e-04\n",
      "  3.0517578e-04  2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-02-02-03.wav\n",
      "03-01-04-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-01-01-03.wav\n",
      "03-01-04-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-01-02-03.wav\n",
      "03-01-04-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-02-01-03.wav\n",
      "03-01-04-02-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.7138672e-04 -7.0190430e-04 -6.1035156e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  3.0517578e-05 ... -3.6926270e-03\n",
      " -7.4768066e-03 -8.6975098e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00247192 0.00247192 0.00244141] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  9.1552734e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-02-02-03.wav\n",
      "03-01-04-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-01-01-03.wav\n",
      "03-01-05-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-01-02-03.wav\n",
      "03-01-05-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-02-01-03.wav\n",
      "03-01-05-01-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -1.8310547e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  3.0517578e-05 ... -5.8593750e-03\n",
      " -5.8898926e-03 -6.0729980e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.8310547e-04  1.2207031e-04  3.0517578e-04 ... -1.8310547e-04\n",
      " -6.1035156e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.4086914e-04  2.7465820e-04 -6.1035156e-05 ... -1.7089844e-03\n",
      " -1.8615723e-03 -1.8005371e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-02-02-03.wav\n",
      "03-01-05-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-01-01-03.wav\n",
      "03-01-05-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-01-02-03.wav\n",
      "03-01-05-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-02-01-03.wav\n",
      "03-01-05-02-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 2.1362305e-04 3.3569336e-04 ... 0.0000000e+00 3.0517578e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 9.4604492e-04 7.0190430e-04\n",
      " 8.8500977e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-02-02-03.wav\n",
      "03-01-05-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-01-01-03.wav\n",
      "03-01-06-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-01-02-03.wav\n",
      "03-01-06-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-02-01-03.wav\n",
      "03-01-06-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-02-02-03.wav\n",
      "03-01-06-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-01-01-03.wav\n",
      "03-01-06-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-01-02-03.wav\n",
      "03-01-06-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-02-01-03.wav\n",
      "03-01-06-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-02-02-03.wav\n",
      "03-01-06-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-01-01-03.wav\n",
      "03-01-07-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-01-02-03.wav\n",
      "03-01-07-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-02-01-03.wav\n",
      "03-01-07-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-02-02-03.wav\n",
      "03-01-07-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-01-01-03.wav\n",
      "03-01-07-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-01-02-03.wav\n",
      "03-01-07-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-02-01-03.wav\n",
      "03-01-07-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-02-02-03.wav\n",
      "03-01-07-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-01-01-03.wav\n",
      "03-01-08-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-01-02-03.wav\n",
      "03-01-08-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-02-01-03.wav\n",
      "03-01-08-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-02-02-03.wav\n",
      "03-01-08-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-01-01-03.wav\n",
      "03-01-08-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-01-02-03.wav\n",
      "03-01-08-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-02-01-03.wav\n",
      "03-01-08-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-02-02-03.wav\n",
      "03-01-08-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-01-01-04.wav\n",
      "03-01-01-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-01-02-04.wav\n",
      "03-01-01-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-02-01-04.wav\n",
      "03-01-01-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-02-02-04.wav\n",
      "03-01-01-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-01-01-04.wav\n",
      "03-01-02-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-01-02-04.wav\n",
      "03-01-02-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-02-01-04.wav\n",
      "03-01-02-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-02-02-04.wav\n",
      "03-01-02-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-01-01-04.wav\n",
      "03-01-02-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-01-02-04.wav\n",
      "03-01-02-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-02-01-04.wav\n",
      "03-01-02-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-02-02-04.wav\n",
      "03-01-02-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-01-01-04.wav\n",
      "03-01-03-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-01-02-04.wav\n",
      "03-01-03-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-02-01-04.wav\n",
      "03-01-03-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-02-02-04.wav\n",
      "03-01-03-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-01-01-04.wav\n",
      "03-01-03-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-01-02-04.wav\n",
      "03-01-03-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-02-01-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-03-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-02-02-04.wav\n",
      "03-01-03-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-01-01-04.wav\n",
      "03-01-04-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-01-02-04.wav\n",
      "03-01-04-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-02-01-04.wav\n",
      "03-01-04-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-02-02-04.wav\n",
      "03-01-04-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-01-01-04.wav\n",
      "03-01-04-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-01-02-04.wav\n",
      "03-01-04-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-02-01-04.wav\n",
      "03-01-04-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-02-02-04.wav\n",
      "03-01-04-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-01-01-04.wav\n",
      "03-01-05-01-01-01-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -9.1552734e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 9.1552734e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-01-02-04.wav\n",
      "03-01-05-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-02-01-04.wav\n",
      "03-01-05-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-02-02-04.wav\n",
      "03-01-05-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-01-01-04.wav\n",
      "03-01-05-02-01-01-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-01-02-04.wav\n",
      "03-01-05-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-02-01-04.wav\n",
      "03-01-05-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-02-02-04.wav\n",
      "03-01-05-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-01-01-04.wav\n",
      "03-01-06-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-01-02-04.wav\n",
      "03-01-06-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-02-01-04.wav\n",
      "03-01-06-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-02-02-04.wav\n",
      "03-01-06-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-01-01-04.wav\n",
      "03-01-06-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-01-02-04.wav\n",
      "03-01-06-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-02-01-04.wav\n",
      "03-01-06-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-02-02-04.wav\n",
      "03-01-06-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-01-01-04.wav\n",
      "03-01-07-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-01-02-04.wav\n",
      "03-01-07-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-02-01-04.wav\n",
      "03-01-07-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-02-02-04.wav\n",
      "03-01-07-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-01-01-04.wav\n",
      "03-01-07-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-01-02-04.wav\n",
      "03-01-07-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-02-01-04.wav\n",
      "03-01-07-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-02-02-04.wav\n",
      "03-01-07-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-01-01-04.wav\n",
      "03-01-08-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-01-02-04.wav\n",
      "03-01-08-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-02-01-04.wav\n",
      "03-01-08-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-02-02-04.wav\n",
      "03-01-08-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-01-01-04.wav\n",
      "03-01-08-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-01-02-04.wav\n",
      "03-01-08-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-02-01-04.wav\n",
      "03-01-08-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-02-02-04.wav\n",
      "03-01-08-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-01-01-05.wav\n",
      "03-01-01-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-01-02-05.wav\n",
      "03-01-01-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-02-01-05.wav\n",
      "03-01-01-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-02-02-05.wav\n",
      "03-01-01-01-02-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -9.1552734e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05  6.1035156e-05 ... -9.1552734e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-01-01-05.wav\n",
      "03-01-02-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-01-02-05.wav\n",
      "03-01-02-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-02-01-05.wav\n",
      "03-01-02-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-02-02-05.wav\n",
      "03-01-02-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-01-01-05.wav\n",
      "03-01-02-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-01-02-05.wav\n",
      "03-01-02-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-02-01-05.wav\n",
      "03-01-02-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-02-02-05.wav\n",
      "03-01-02-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-01-01-05.wav\n",
      "03-01-03-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-01-02-05.wav\n",
      "03-01-03-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-02-01-05.wav\n",
      "03-01-03-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-02-02-05.wav\n",
      "03-01-03-01-02-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 6.1035156e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04 -1.5258789e-04 -1.5258789e-04 ...  0.0000000e+00\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-01-01-05.wav\n",
      "03-01-03-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-01-02-05.wav\n",
      "03-01-03-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-02-01-05.wav\n",
      "03-01-03-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-02-02-05.wav\n",
      "03-01-03-02-02-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  6.1035156e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 3.0517578e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-01-01-05.wav\n",
      "03-01-04-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-01-02-05.wav\n",
      "03-01-04-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-02-01-05.wav\n",
      "03-01-04-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-02-02-05.wav\n",
      "03-01-04-01-02-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.00054932 0.00057983 0.00057983 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-01-01-05.wav\n",
      "03-01-04-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-01-02-05.wav\n",
      "03-01-04-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-02-01-05.wav\n",
      "03-01-04-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-02-02-05.wav\n",
      "03-01-04-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-01-01-05.wav\n",
      "03-01-05-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-01-02-05.wav\n",
      "03-01-05-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-02-01-05.wav\n",
      "03-01-05-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-02-02-05.wav\n",
      "03-01-05-01-02-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-01-01-05.wav\n",
      "03-01-05-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-01-02-05.wav\n",
      "03-01-05-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-02-01-05.wav\n",
      "03-01-05-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-02-02-05.wav\n",
      "03-01-05-02-02-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -9.1552734e-05 ...  4.2724609e-04\n",
      "  4.2724609e-04  4.2724609e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-01-01-05.wav\n",
      "03-01-06-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-01-02-05.wav\n",
      "03-01-06-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-02-01-05.wav\n",
      "03-01-06-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-02-02-05.wav\n",
      "03-01-06-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-01-01-05.wav\n",
      "03-01-06-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-01-02-05.wav\n",
      "03-01-06-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-02-01-05.wav\n",
      "03-01-06-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-02-02-05.wav\n",
      "03-01-06-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-01-01-05.wav\n",
      "03-01-07-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-01-02-05.wav\n",
      "03-01-07-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-02-01-05.wav\n",
      "03-01-07-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-02-02-05.wav\n",
      "03-01-07-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-01-01-05.wav\n",
      "03-01-07-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-01-02-05.wav\n",
      "03-01-07-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-02-01-05.wav\n",
      "03-01-07-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-02-02-05.wav\n",
      "03-01-07-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-01-01-05.wav\n",
      "03-01-08-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-01-02-05.wav\n",
      "03-01-08-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-02-01-05.wav\n",
      "03-01-08-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-02-02-05.wav\n",
      "03-01-08-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-01-01-05.wav\n",
      "03-01-08-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-01-02-05.wav\n",
      "03-01-08-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-02-01-05.wav\n",
      "03-01-08-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-02-02-05.wav\n",
      "03-01-08-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-01-01-06.wav\n",
      "03-01-01-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-01-02-06.wav\n",
      "03-01-01-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-02-01-06.wav\n",
      "03-01-01-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-02-02-06.wav\n",
      "03-01-01-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-01-01-06.wav\n",
      "03-01-02-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-01-02-06.wav\n",
      "03-01-02-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-02-01-06.wav\n",
      "03-01-02-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-02-02-06.wav\n",
      "03-01-02-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-01-01-06.wav\n",
      "03-01-02-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-01-02-06.wav\n",
      "03-01-02-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-02-01-06.wav\n",
      "03-01-02-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-02-02-06.wav\n",
      "03-01-02-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-01-01-06.wav\n",
      "03-01-03-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-01-02-06.wav\n",
      "03-01-03-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-02-01-06.wav\n",
      "03-01-03-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-02-02-06.wav\n",
      "03-01-03-01-02-02-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  3.0517578e-05\n",
      " -3.0517578e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-01-01-06.wav\n",
      "03-01-03-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-01-02-06.wav\n",
      "03-01-03-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-02-01-06.wav\n",
      "03-01-03-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-02-02-06.wav\n",
      "03-01-03-02-02-02-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 6.1035156e-04 6.1035156e-04\n",
      " 5.7983398e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-01-01-06.wav\n",
      "03-01-04-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-01-02-06.wav\n",
      "03-01-04-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-02-01-06.wav\n",
      "03-01-04-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-02-02-06.wav\n",
      "03-01-04-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-01-01-06.wav\n",
      "03-01-04-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-01-02-06.wav\n",
      "03-01-04-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-02-01-06.wav\n",
      "03-01-04-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-02-02-06.wav\n",
      "03-01-04-02-02-02-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.00024414 0.00021362 0.00021362 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-01-01-06.wav\n",
      "03-01-05-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-01-02-06.wav\n",
      "03-01-05-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-02-01-06.wav\n",
      "03-01-05-01-02-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00015259 0.00015259 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-02-02-06.wav\n",
      "03-01-05-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-01-01-06.wav\n",
      "03-01-05-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-01-02-06.wav\n",
      "03-01-05-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-02-01-06.wav\n",
      "03-01-05-02-02-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 8.2397461e-04  5.1879883e-04  3.0517578e-04 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05 -3.0517578e-05 -4.8828125e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  9.1552734e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-02-02-06.wav\n",
      "03-01-05-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-01-01-06.wav\n",
      "03-01-06-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-01-02-06.wav\n",
      "03-01-06-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-02-01-06.wav\n",
      "03-01-06-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-02-02-06.wav\n",
      "03-01-06-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-01-01-06.wav\n",
      "03-01-06-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-01-02-06.wav\n",
      "03-01-06-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-02-01-06.wav\n",
      "03-01-06-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-02-02-06.wav\n",
      "03-01-06-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-01-01-06.wav\n",
      "03-01-07-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-01-02-06.wav\n",
      "03-01-07-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-02-01-06.wav\n",
      "03-01-07-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-02-02-06.wav\n",
      "03-01-07-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-01-01-06.wav\n",
      "03-01-07-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-01-02-06.wav\n",
      "03-01-07-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-02-01-06.wav\n",
      "03-01-07-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-02-02-06.wav\n",
      "03-01-07-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-01-01-06.wav\n",
      "03-01-08-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-01-02-06.wav\n",
      "03-01-08-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-02-01-06.wav\n",
      "03-01-08-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-02-02-06.wav\n",
      "03-01-08-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-01-01-06.wav\n",
      "03-01-08-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-01-02-06.wav\n",
      "03-01-08-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-02-01-06.wav\n",
      "03-01-08-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-02-02-06.wav\n",
      "03-01-08-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-01-01-07.wav\n",
      "03-01-01-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-01-02-07.wav\n",
      "03-01-01-01-01-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-2.1362305e-04 -1.8310547e-04  6.1035156e-05 ... -1.5258789e-04\n",
      " -1.8310547e-04 -2.4414062e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -1.2207031e-04  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-02-01-07.wav\n",
      "03-01-01-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-02-02-07.wav\n",
      "03-01-01-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-01-01-07.wav\n",
      "03-01-02-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-01-02-07.wav\n",
      "03-01-02-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-02-01-07.wav\n",
      "03-01-02-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-02-02-07.wav\n",
      "03-01-02-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-01-01-07.wav\n",
      "03-01-02-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-01-02-07.wav\n",
      "03-01-02-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-02-01-07.wav\n",
      "03-01-02-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-02-02-07.wav\n",
      "03-01-02-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-01-01-07.wav\n",
      "03-01-03-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-01-02-07.wav\n",
      "03-01-03-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-02-01-07.wav\n",
      "03-01-03-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-02-02-07.wav\n",
      "03-01-03-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-01-01-07.wav\n",
      "03-01-03-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-01-02-07.wav\n",
      "03-01-03-02-01-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05  0.0000000e+00  3.0517578e-05 ...  2.7465820e-04\n",
      "  2.4414062e-04  2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  6.1035156e-05\n",
      "  9.1552734e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 2.1362305e-04  7.9345703e-04 -1.2207031e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-02-01-07.wav\n",
      "03-01-03-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-02-02-07.wav\n",
      "03-01-03-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-01-01-07.wav\n",
      "03-01-04-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-01-02-07.wav\n",
      "03-01-04-01-01-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05 -6.1035156e-05 ... -3.3569336e-04\n",
      " -3.9672852e-04 -4.2724609e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  4.2724609e-04  6.4086914e-04 ...  1.2207031e-04\n",
      "  9.1552734e-05  1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-02-01-07.wav\n",
      "03-01-04-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-02-02-07.wav\n",
      "03-01-04-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-01-01-07.wav\n",
      "03-01-04-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-01-02-07.wav"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05 -2.4414062e-04 -3.9672852e-04 ...  3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  3.0517578e-05 ...  1.0681152e-03\n",
      "  1.0681152e-03  1.0681152e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.00042725  0.00033569  0.00033569 ... -0.00402832 -0.00390625\n",
      " -0.00390625] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "03-01-04-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-02-01-07.wav\n",
      "03-01-04-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-02-02-07.wav\n",
      "03-01-04-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-01-01-07.wav\n",
      "03-01-05-01-01-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -8.2397461e-04\n",
      " -8.2397461e-04 -8.2397461e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  9.1552734e-05  1.2207031e-04 ... -2.1057129e-03\n",
      " -2.1362305e-03 -2.1362305e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-01-02-07.wav\n",
      "03-01-05-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-02-01-07.wav\n",
      "03-01-05-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-02-02-07.wav\n",
      "03-01-05-01-02-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.00064087 -0.00057983 -0.00054932 ...  0.00231934  0.00228882\n",
      "  0.00228882] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.00012207  0.00015259  0.00012207 ... -0.00204468 -0.00201416\n",
      " -0.00204468] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -1.8310547e-04 ...  3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -3.3569336e-04\n",
      " -3.3569336e-04 -3.3569336e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-01-01-07.wav\n",
      "03-01-05-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-01-02-07.wav\n",
      "03-01-05-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-02-01-07.wav\n",
      "03-01-05-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-02-02-07.wav\n",
      "03-01-05-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-01-01-07.wav\n",
      "03-01-06-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-01-02-07.wav\n",
      "03-01-06-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-02-01-07.wav\n",
      "03-01-06-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-02-02-07.wav\n",
      "03-01-06-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-01-01-07.wav\n",
      "03-01-06-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-01-02-07.wav\n",
      "03-01-06-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-02-01-07.wav\n",
      "03-01-06-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-02-02-07.wav\n",
      "03-01-06-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-01-01-07.wav\n",
      "03-01-07-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-01-02-07.wav\n",
      "03-01-07-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-02-01-07.wav\n",
      "03-01-07-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-02-02-07.wav\n",
      "03-01-07-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-01-01-07.wav\n",
      "03-01-07-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-01-02-07.wav\n",
      "03-01-07-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-02-01-07.wav\n",
      "03-01-07-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-02-02-07.wav\n",
      "03-01-07-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-01-01-07.wav\n",
      "03-01-08-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-01-02-07.wav\n",
      "03-01-08-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-02-01-07.wav\n",
      "03-01-08-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-02-02-07.wav\n",
      "03-01-08-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-01-01-07.wav\n",
      "03-01-08-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-01-02-07.wav\n",
      "03-01-08-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-02-01-07.wav\n",
      "03-01-08-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-02-02-07.wav\n",
      "03-01-08-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-01-01-08.wav\n",
      "03-01-01-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-01-02-08.wav\n",
      "03-01-01-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-02-01-08.wav\n",
      "03-01-01-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-02-02-08.wav\n",
      "03-01-01-01-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.00015259 -0.00015259 -0.00015259 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 9.1552734e-05 1.2207031e-04 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.00018311 0.00018311 0.00021362 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-01-01-08.wav\n",
      "03-01-02-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-01-02-08.wav\n",
      "03-01-02-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-02-01-08.wav\n",
      "03-01-02-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-02-02-08.wav\n",
      "03-01-02-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-01-01-08.wav\n",
      "03-01-02-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-01-02-08.wav\n",
      "03-01-02-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-02-01-08.wav\n",
      "03-01-02-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-02-02-08.wav\n",
      "03-01-02-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-01-01-08.wav\n",
      "03-01-03-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-01-02-08.wav\n",
      "03-01-03-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-02-01-08.wav\n",
      "03-01-03-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-02-02-08.wav\n",
      "03-01-03-01-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 6.1035156e-05 ... 9.1552734e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  3.0517578e-05 ... -1.5258789e-04\n",
      " -1.2207031e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-01-01-08.wav\n",
      "03-01-03-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-01-02-08.wav\n",
      "03-01-03-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-02-01-08.wav\n",
      "03-01-03-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-02-02-08.wav\n",
      "03-01-03-02-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -6.1035156e-05 -6.1035156e-05 ...  6.1035156e-05\n",
      "  3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -3.6621094e-04\n",
      " -3.6621094e-04 -3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05 -6.1035156e-05 ... -2.7465820e-04\n",
      " -2.1362305e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-01-01-08.wav\n",
      "03-01-04-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-01-02-08.wav\n",
      "03-01-04-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-02-01-08.wav\n",
      "03-01-04-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-02-02-08.wav\n",
      "03-01-04-01-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[2.4414062e-04 2.4414062e-04 2.4414062e-04 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.00012207 0.00015259 0.00015259 ... 0.00015259 0.00018311 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-01-01-08.wav\n",
      "03-01-04-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-01-02-08.wav\n",
      "03-01-04-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-02-01-08.wav\n",
      "03-01-04-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-02-02-08.wav\n",
      "03-01-04-02-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 1.8310547e-04  2.1362305e-04  2.1362305e-04 ... -1.2207031e-04\n",
      "  0.0000000e+00 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00088501 0.00076294 0.00076294] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00231934 0.00238037 0.00234985] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-01-01-08.wav\n",
      "03-01-05-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-01-02-08.wav\n",
      "03-01-05-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-02-01-08.wav\n",
      "03-01-05-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-02-02-08.wav\n",
      "03-01-05-01-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ... -8.5449219e-04\n",
      " -6.4086914e-04  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ... -2.4414062e-04\n",
      " -2.1667480e-03 -2.4414062e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  6.1035156e-05  1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.00018311 -0.00018311 -0.00018311 ...  0.00027466  0.00027466\n",
      "  0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-01-01-08.wav\n",
      "03-01-05-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-01-02-08.wav\n",
      "03-01-05-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-02-01-08.wav\n",
      "03-01-05-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-02-02-08.wav\n",
      "03-01-05-02-02-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.00018311  0.00015259  0.00018311 ... -0.00021362 -0.00018311\n",
      " -0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.00012207 0.00012207 0.00012207 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[1.8310547e-04 1.8310547e-04 1.8310547e-04 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-01-01-08.wav\n",
      "03-01-06-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-01-02-08.wav\n",
      "03-01-06-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-02-01-08.wav\n",
      "03-01-06-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-02-02-08.wav\n",
      "03-01-06-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-01-01-08.wav\n",
      "03-01-06-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-01-02-08.wav\n",
      "03-01-06-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-02-01-08.wav\n",
      "03-01-06-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-02-02-08.wav\n",
      "03-01-06-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-01-01-08.wav\n",
      "03-01-07-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-01-02-08.wav\n",
      "03-01-07-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-02-01-08.wav\n",
      "03-01-07-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-02-02-08.wav\n",
      "03-01-07-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-01-01-08.wav\n",
      "03-01-07-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-01-02-08.wav\n",
      "03-01-07-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-02-01-08.wav\n",
      "03-01-07-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-02-02-08.wav\n",
      "03-01-07-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-01-01-08.wav\n",
      "03-01-08-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-01-02-08.wav\n",
      "03-01-08-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-02-01-08.wav\n",
      "03-01-08-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-02-02-08.wav\n",
      "03-01-08-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-01-01-08.wav\n",
      "03-01-08-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-01-02-08.wav\n",
      "03-01-08-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-02-01-08.wav\n",
      "03-01-08-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-02-02-08.wav\n",
      "03-01-08-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-01-01-09.wav\n",
      "03-01-01-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-01-02-09.wav\n",
      "03-01-01-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-02-01-09.wav\n",
      "03-01-01-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-02-02-09.wav\n",
      "03-01-01-01-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 8.5449219e-04  8.5449219e-04  8.8500977e-04 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-01-01-09.wav\n",
      "03-01-02-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-01-02-09.wav\n",
      "03-01-02-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-02-01-09.wav\n",
      "03-01-02-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-02-02-09.wav\n",
      "03-01-02-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-01-01-09.wav\n",
      "03-01-02-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-01-02-09.wav\n",
      "03-01-02-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-02-01-09.wav\n",
      "03-01-02-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-02-02-09.wav\n",
      "03-01-02-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-01-01-09.wav\n",
      "03-01-03-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-01-02-09.wav\n",
      "03-01-03-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-02-01-09.wav\n",
      "03-01-03-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-02-02-09.wav\n",
      "03-01-03-01-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0007019  0.00067139 0.00067139 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-01-01-09.wav\n",
      "03-01-03-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-01-02-09.wav\n",
      "03-01-03-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-02-01-09.wav\n",
      "03-01-03-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-02-02-09.wav\n",
      "03-01-03-02-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -1.2207031e-04\n",
      " -1.2207031e-04 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05  3.0517578e-05  3.0517578e-05 ...  6.1035156e-05\n",
      " -3.0517578e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-01-01-09.wav\n",
      "03-01-04-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-01-02-09.wav\n",
      "03-01-04-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-02-01-09.wav\n",
      "03-01-04-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-02-02-09.wav\n",
      "03-01-04-01-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-01-01-09.wav\n",
      "03-01-04-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-01-02-09.wav\n",
      "03-01-04-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-02-01-09.wav\n",
      "03-01-04-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-02-02-09.wav\n",
      "03-01-04-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-01-01-09.wav\n",
      "03-01-05-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-01-02-09.wav\n",
      "03-01-05-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-02-01-09.wav\n",
      "03-01-05-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-02-02-09.wav\n",
      "03-01-05-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-01-01-09.wav\n",
      "03-01-05-02-01-01-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00012207 -0.00012207\n",
      " -0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  0.0000000e+00 ... -2.7465820e-04\n",
      " -3.0517578e-04 -2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -1.5258789e-04\n",
      " -1.2207031e-04 -2.1362305e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 1.2207031e-04 1.8310547e-04 ... 1.5258789e-04 1.8310547e-04\n",
      " 1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.00027466  0.00048828  0.0005188  ... -0.00036621 -0.00042725\n",
      " -0.00033569] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-01-02-09.wav\n",
      "03-01-05-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-02-01-09.wav\n",
      "03-01-05-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-02-02-09.wav\n",
      "03-01-05-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-01-01-09.wav\n",
      "03-01-06-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-01-02-09.wav\n",
      "03-01-06-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-02-01-09.wav\n",
      "03-01-06-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-02-02-09.wav\n",
      "03-01-06-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-01-01-09.wav\n",
      "03-01-06-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-01-02-09.wav\n",
      "03-01-06-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-02-01-09.wav\n",
      "03-01-06-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-02-02-09.wav\n",
      "03-01-06-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-01-01-09.wav\n",
      "03-01-07-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-01-02-09.wav\n",
      "03-01-07-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-02-01-09.wav\n",
      "03-01-07-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-02-02-09.wav\n",
      "03-01-07-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-01-01-09.wav\n",
      "03-01-07-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-01-02-09.wav\n",
      "03-01-07-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-02-01-09.wav\n",
      "03-01-07-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-02-02-09.wav\n",
      "03-01-07-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-01-01-09.wav\n",
      "03-01-08-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-01-02-09.wav\n",
      "03-01-08-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-02-01-09.wav\n",
      "03-01-08-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-02-02-09.wav\n",
      "03-01-08-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-01-01-09.wav\n",
      "03-01-08-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-01-02-09.wav\n",
      "03-01-08-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-02-01-09.wav\n",
      "03-01-08-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-02-02-09.wav\n",
      "03-01-08-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-01-01-10.wav\n",
      "03-01-01-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-01-02-10.wav\n",
      "03-01-01-01-01-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 3.0517578e-05 6.1035156e-05 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  2.7465820e-04 ...  6.1035156e-05\n",
      "  9.1552734e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-02-01-10.wav\n",
      "03-01-01-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-02-02-10.wav\n",
      "03-01-01-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-01-01-10.wav\n",
      "03-01-02-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-01-02-10.wav\n",
      "03-01-02-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-02-01-10.wav\n",
      "03-01-02-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-02-02-10.wav\n",
      "03-01-02-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-01-01-10.wav\n",
      "03-01-02-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-01-02-10.wav\n",
      "03-01-02-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-02-01-10.wav\n",
      "03-01-02-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-02-02-10.wav\n",
      "03-01-02-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-01-01-10.wav\n",
      "03-01-03-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-01-02-10.wav\n",
      "03-01-03-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-02-01-10.wav\n",
      "03-01-03-01-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  3.0517578e-05 ...  0.0000000e+00\n",
      " -9.1552734e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  3.0517578e-05 ...  3.9672852e-04\n",
      "  4.5776367e-04 -2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-2.7465820e-04  1.8310547e-04 -6.1035156e-05 ...  9.1552734e-05\n",
      "  1.2207031e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-02-02-10.wav\n",
      "03-01-03-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-01-01-10.wav\n",
      "03-01-03-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-01-02-10.wav\n",
      "03-01-03-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-02-01-10.wav\n",
      "03-01-03-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-02-02-10.wav\n",
      "03-01-03-02-02-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -1.2207031e-04\n",
      " -9.1552734e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 1.4648438e-03  6.1035156e-04  2.1667480e-03 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-01-01-10.wav\n",
      "03-01-04-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-01-02-10.wav\n",
      "03-01-04-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-02-01-10.wav\n",
      "03-01-04-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-02-02-10.wav\n",
      "03-01-04-01-02-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -1.2207031e-04 -9.1552734e-05 ...  0.0000000e+00\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05 -6.1035156e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-01-01-10.wav\n",
      "03-01-04-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-01-02-10.wav\n",
      "03-01-04-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-02-01-10.wav\n",
      "03-01-04-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-02-02-10.wav\n",
      "03-01-04-02-02-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.9672852e-04  1.8310547e-04 -2.7465820e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05 -3.0517578e-05 -2.1362305e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04  6.1035156e-05  1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-01-01-10.wav\n",
      "03-01-05-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-01-02-10.wav\n",
      "03-01-05-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-02-01-10.wav\n",
      "03-01-05-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-02-02-10.wav\n",
      "03-01-05-01-02-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.4086914e-04  2.7465820e-04 -4.5776367e-04 ...  1.2207031e-04\n",
      "  9.1552734e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 1.5258789e-04 1.2207031e-04 ... 3.0517578e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[1.5258789e-04 1.5258789e-04 1.8310547e-04 ... 3.0517578e-05 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-01-01-10.wav\n",
      "03-01-05-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-01-02-10.wav\n",
      "03-01-05-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-02-01-10.wav\n",
      "03-01-05-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-02-02-10.wav\n",
      "03-01-05-02-02-02-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05  3.0517578e-05  6.1035156e-05 ... -3.0517578e-05\n",
      "  6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-01-01-10.wav\n",
      "03-01-06-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-01-02-10.wav\n",
      "03-01-06-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-02-01-10.wav\n",
      "03-01-06-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-02-02-10.wav\n",
      "03-01-06-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-01-01-10.wav\n",
      "03-01-06-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-01-02-10.wav\n",
      "03-01-06-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-02-01-10.wav\n",
      "03-01-06-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-02-02-10.wav\n",
      "03-01-06-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-01-01-10.wav\n",
      "03-01-07-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-01-02-10.wav\n",
      "03-01-07-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-02-01-10.wav\n",
      "03-01-07-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-02-02-10.wav\n",
      "03-01-07-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-01-01-10.wav\n",
      "03-01-07-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-01-02-10.wav\n",
      "03-01-07-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-02-01-10.wav\n",
      "03-01-07-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-02-02-10.wav\n",
      "03-01-07-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-01-01-10.wav\n",
      "03-01-08-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-01-02-10.wav\n",
      "03-01-08-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-02-01-10.wav\n",
      "03-01-08-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-02-02-10.wav\n",
      "03-01-08-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-01-01-10.wav\n",
      "03-01-08-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-01-02-10.wav\n",
      "03-01-08-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-02-01-10.wav\n",
      "03-01-08-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-02-02-10.wav\n",
      "03-01-08-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-01-01-11.wav\n",
      "03-01-01-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-01-02-11.wav\n",
      "03-01-01-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-02-01-11.wav\n",
      "03-01-01-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-02-02-11.wav\n",
      "03-01-01-01-02-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  4.5776367e-04\n",
      "  4.5776367e-04  4.5776367e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-05 -6.1035156e-05 ... -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-01-01-11.wav\n",
      "03-01-02-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-01-02-11.wav\n",
      "03-01-02-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-02-01-11.wav\n",
      "03-01-02-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-02-02-11.wav\n",
      "03-01-02-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-01-01-11.wav\n",
      "03-01-02-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-01-02-11.wav\n",
      "03-01-02-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-02-01-11.wav\n",
      "03-01-02-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-02-02-11.wav\n",
      "03-01-02-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-01-01-11.wav\n",
      "03-01-03-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-01-02-11.wav\n",
      "03-01-03-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-02-01-11.wav\n",
      "03-01-03-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-02-02-11.wav\n",
      "03-01-03-01-02-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 6.1035156e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  2.1362305e-04  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-01-01-11.wav\n",
      "03-01-03-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-01-02-11.wav\n",
      "03-01-03-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-02-01-11.wav\n",
      "03-01-03-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-02-02-11.wav\n",
      "03-01-03-02-02-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[1.2207031e-04 9.1552734e-05 9.1552734e-05 ... 1.8310547e-04 1.8310547e-04\n",
      " 1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 1.5258789e-04  1.2207031e-04  1.2207031e-04 ... -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-01-01-11.wav\n",
      "03-01-04-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-01-02-11.wav\n",
      "03-01-04-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-02-01-11.wav\n",
      "03-01-04-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-02-02-11.wav\n",
      "03-01-04-01-02-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -6.1035156e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ... -9.1552734e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-01-01-11.wav\n",
      "03-01-04-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-01-02-11.wav\n",
      "03-01-04-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-02-01-11.wav\n",
      "03-01-04-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-02-02-11.wav\n",
      "03-01-04-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-01-01-11.wav\n",
      "03-01-05-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-01-02-11.wav\n",
      "03-01-05-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-02-01-11.wav\n",
      "03-01-05-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-02-02-11.wav\n",
      "03-01-05-01-02-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 9.1552734e-05 9.1552734e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.5258789e-04 -1.5258789e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-01-01-11.wav\n",
      "03-01-05-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-01-02-11.wav\n",
      "03-01-05-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-02-01-11.wav\n",
      "03-01-05-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-02-02-11.wav\n",
      "03-01-05-02-02-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -6.1035156e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00027466 -0.00027466\n",
      " -0.00027466] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -9.1552734e-05 -6.1035156e-05 ... -1.2207031e-04\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-01-01-11.wav\n",
      "03-01-06-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-01-02-11.wav\n",
      "03-01-06-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-02-01-11.wav\n",
      "03-01-06-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-02-02-11.wav\n",
      "03-01-06-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-01-01-11.wav\n",
      "03-01-06-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-01-02-11.wav\n",
      "03-01-06-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-02-01-11.wav\n",
      "03-01-06-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-02-02-11.wav\n",
      "03-01-06-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-01-01-11.wav\n",
      "03-01-07-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-01-02-11.wav\n",
      "03-01-07-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-02-01-11.wav\n",
      "03-01-07-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-02-02-11.wav\n",
      "03-01-07-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-01-01-11.wav\n",
      "03-01-07-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-01-02-11.wav\n",
      "03-01-07-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-02-01-11.wav\n",
      "03-01-07-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-02-02-11.wav\n",
      "03-01-07-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-01-01-11.wav\n",
      "03-01-08-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-01-02-11.wav\n",
      "03-01-08-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-02-01-11.wav\n",
      "03-01-08-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-02-02-11.wav\n",
      "03-01-08-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-01-01-11.wav\n",
      "03-01-08-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-01-02-11.wav\n",
      "03-01-08-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-02-01-11.wav\n",
      "03-01-08-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-02-02-11.wav\n",
      "03-01-08-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-01-01-12.wav\n",
      "03-01-01-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-01-02-12.wav\n",
      "03-01-01-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-02-01-12.wav\n",
      "03-01-01-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-02-02-12.wav\n",
      "03-01-01-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-01-01-12.wav\n",
      "03-01-02-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-01-02-12.wav\n",
      "03-01-02-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-02-01-12.wav\n",
      "03-01-02-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-02-02-12.wav\n",
      "03-01-02-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-01-01-12.wav\n",
      "03-01-02-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-01-02-12.wav\n",
      "03-01-02-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-02-01-12.wav\n",
      "03-01-02-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-02-02-12.wav\n",
      "03-01-02-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-01-01-12.wav\n",
      "03-01-03-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-01-02-12.wav\n",
      "03-01-03-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-02-01-12.wav\n",
      "03-01-03-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-02-02-12.wav\n",
      "03-01-03-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-01-01-12.wav\n",
      "03-01-03-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-01-02-12.wav\n",
      "03-01-03-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-02-01-12.wav\n",
      "03-01-03-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-02-02-12.wav\n",
      "03-01-03-02-02-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00021362 -0.00024414\n",
      " -0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-01-01-12.wav\n",
      "03-01-04-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-01-02-12.wav\n",
      "03-01-04-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-02-01-12.wav\n",
      "03-01-04-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-02-02-12.wav\n",
      "03-01-04-01-02-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -3.0212402e-03\n",
      " -3.0212402e-03 -3.0212402e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[1.5258789e-04 1.5258789e-04 9.1552734e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-01-01-12.wav\n",
      "03-01-04-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-01-02-12.wav\n",
      "03-01-04-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-02-01-12.wav\n",
      "03-01-04-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-02-02-12.wav\n",
      "03-01-04-02-02-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.00033569 0.00033569 0.00033569 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.0015564  -0.0015564\n",
      " -0.00158691] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-01-01-12.wav\n",
      "03-01-05-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-01-02-12.wav\n",
      "03-01-05-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-02-01-12.wav\n",
      "03-01-05-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-02-02-12.wav\n",
      "03-01-05-01-02-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00152588 -0.00149536\n",
      " -0.00149536] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00283813 0.0027771  0.0027771 ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-01-01-12.wav\n",
      "03-01-05-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-01-02-12.wav\n",
      "03-01-05-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-02-01-12.wav\n",
      "03-01-05-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-02-02-12.wav\n",
      "03-01-05-02-02-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00021362 -0.00027466\n",
      " -0.00024414] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-01-01-12.wav\n",
      "03-01-06-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-01-02-12.wav\n",
      "03-01-06-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-02-01-12.wav\n",
      "03-01-06-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-02-02-12.wav\n",
      "03-01-06-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-01-01-12.wav\n",
      "03-01-06-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-01-02-12.wav\n",
      "03-01-06-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-02-01-12.wav\n",
      "03-01-06-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-02-02-12.wav\n",
      "03-01-06-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-01-01-12.wav\n",
      "03-01-07-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-01-02-12.wav\n",
      "03-01-07-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-02-01-12.wav\n",
      "03-01-07-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-02-02-12.wav\n",
      "03-01-07-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-01-01-12.wav\n",
      "03-01-07-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-01-02-12.wav\n",
      "03-01-07-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-02-01-12.wav\n",
      "03-01-07-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-02-02-12.wav\n",
      "03-01-07-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-01-01-12.wav\n",
      "03-01-08-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-01-02-12.wav\n",
      "03-01-08-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-02-01-12.wav\n",
      "03-01-08-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-02-02-12.wav\n",
      "03-01-08-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-01-01-12.wav\n",
      "03-01-08-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-01-02-12.wav\n",
      "03-01-08-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-02-01-12.wav\n",
      "03-01-08-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-02-02-12.wav\n",
      "03-01-08-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-01-01-13.wav\n",
      "03-01-01-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-01-02-13.wav\n",
      "03-01-01-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-02-01-13.wav\n",
      "03-01-01-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-02-02-13.wav\n",
      "03-01-01-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-01-01-13.wav\n",
      "03-01-02-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-01-02-13.wav\n",
      "03-01-02-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-02-01-13.wav\n",
      "03-01-02-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-02-02-13.wav\n",
      "03-01-02-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-01-01-13.wav\n",
      "03-01-02-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-01-02-13.wav\n",
      "03-01-02-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-02-01-13.wav\n",
      "03-01-02-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-02-02-13.wav\n",
      "03-01-02-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-01-01-13.wav\n",
      "03-01-03-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-01-02-13.wav\n",
      "03-01-03-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-02-01-13.wav\n",
      "03-01-03-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-02-02-13.wav\n",
      "03-01-03-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-01-01-13.wav\n",
      "03-01-03-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-01-02-13.wav\n",
      "03-01-03-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-02-01-13.wav\n",
      "03-01-03-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-02-02-13.wav\n",
      "03-01-03-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-01-01-13.wav\n",
      "03-01-04-01-01-01-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05  3.0517578e-05 ... -6.1035156e-05\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-01-02-13.wav\n",
      "03-01-04-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-02-01-13.wav\n",
      "03-01-04-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-02-02-13.wav\n",
      "03-01-04-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-01-01-13.wav"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "03-01-04-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-01-02-13.wav\n",
      "03-01-04-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-02-01-13.wav\n",
      "03-01-04-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-02-02-13.wav\n",
      "03-01-04-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-01-01-13.wav\n",
      "03-01-05-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-01-02-13.wav\n",
      "03-01-05-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-02-01-13.wav\n",
      "03-01-05-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-02-02-13.wav\n",
      "03-01-05-01-02-02-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-01-01-13.wav\n",
      "03-01-05-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-01-02-13.wav\n",
      "03-01-05-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-02-01-13.wav\n",
      "03-01-05-02-02-01-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -7.9345703e-04\n",
      " -8.2397461e-04 -8.2397461e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00012207 0.00012207 0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-02-02-13.wav\n",
      "03-01-05-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-01-01-13.wav\n",
      "03-01-06-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-01-02-13.wav\n",
      "03-01-06-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-02-01-13.wav\n",
      "03-01-06-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-02-02-13.wav\n",
      "03-01-06-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-01-01-13.wav\n",
      "03-01-06-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-01-02-13.wav\n",
      "03-01-06-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-02-01-13.wav\n",
      "03-01-06-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-02-02-13.wav\n",
      "03-01-06-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-01-01-13.wav\n",
      "03-01-07-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-01-02-13.wav\n",
      "03-01-07-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-02-01-13.wav\n",
      "03-01-07-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-02-02-13.wav\n",
      "03-01-07-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-01-01-13.wav\n",
      "03-01-07-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-01-02-13.wav\n",
      "03-01-07-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-02-01-13.wav\n",
      "03-01-07-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-02-02-13.wav\n",
      "03-01-07-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-01-01-13.wav\n",
      "03-01-08-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-01-02-13.wav\n",
      "03-01-08-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-02-01-13.wav\n",
      "03-01-08-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-02-02-13.wav\n",
      "03-01-08-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-01-01-13.wav\n",
      "03-01-08-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-01-02-13.wav\n",
      "03-01-08-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-02-01-13.wav\n",
      "03-01-08-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-02-02-13.wav\n",
      "03-01-08-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-01-01-14.wav\n",
      "03-01-01-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-01-02-14.wav\n",
      "03-01-01-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-02-01-14.wav\n",
      "03-01-01-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-02-02-14.wav\n",
      "03-01-01-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-01-01-14.wav\n",
      "03-01-02-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-01-02-14.wav\n",
      "03-01-02-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-02-01-14.wav\n",
      "03-01-02-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-02-02-14.wav\n",
      "03-01-02-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-01-01-14.wav\n",
      "03-01-02-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-01-02-14.wav\n",
      "03-01-02-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-02-01-14.wav\n",
      "03-01-02-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-02-02-14.wav\n",
      "03-01-02-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-01-01-14.wav\n",
      "03-01-03-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-01-02-14.wav\n",
      "03-01-03-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-02-01-14.wav\n",
      "03-01-03-01-02-01-14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-02-02-14.wav\n",
      "03-01-03-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-01-01-14.wav\n",
      "03-01-03-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-01-02-14.wav\n",
      "03-01-03-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-02-01-14.wav\n",
      "03-01-03-02-02-01-14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-02-02-14.wav\n",
      "03-01-03-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-01-01-14.wav\n",
      "03-01-04-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-01-02-14.wav\n",
      "03-01-04-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-02-01-14.wav\n",
      "03-01-04-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-02-02-14.wav\n",
      "03-01-04-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-01-01-14.wav\n",
      "03-01-04-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-01-02-14.wav\n",
      "03-01-04-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-02-01-14.wav\n",
      "03-01-04-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-02-02-14.wav\n",
      "03-01-04-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-01-01-14.wav\n",
      "03-01-05-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-01-02-14.wav\n",
      "03-01-05-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-02-01-14.wav\n",
      "03-01-05-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-02-02-14.wav\n",
      "03-01-05-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-01-01-14.wav\n",
      "03-01-05-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-01-02-14.wav\n",
      "03-01-05-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-02-01-14.wav\n",
      "03-01-05-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-02-02-14.wav\n",
      "03-01-05-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-01-01-14.wav\n",
      "03-01-06-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-01-02-14.wav\n",
      "03-01-06-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-02-01-14.wav\n",
      "03-01-06-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-02-02-14.wav\n",
      "03-01-06-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-01-01-14.wav\n",
      "03-01-06-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-01-02-14.wav\n",
      "03-01-06-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-02-01-14.wav\n",
      "03-01-06-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-02-02-14.wav\n",
      "03-01-06-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-01-01-14.wav\n",
      "03-01-07-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-01-02-14.wav\n",
      "03-01-07-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-02-01-14.wav\n",
      "03-01-07-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-02-02-14.wav\n",
      "03-01-07-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-01-01-14.wav\n",
      "03-01-07-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-01-02-14.wav\n",
      "03-01-07-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-02-01-14.wav\n",
      "03-01-07-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-02-02-14.wav\n",
      "03-01-07-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-01-01-14.wav\n",
      "03-01-08-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-01-02-14.wav\n",
      "03-01-08-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-02-01-14.wav\n",
      "03-01-08-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-02-02-14.wav\n",
      "03-01-08-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-01-01-14.wav\n",
      "03-01-08-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-01-02-14.wav\n",
      "03-01-08-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-02-01-14.wav\n",
      "03-01-08-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-02-02-14.wav\n",
      "03-01-08-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-01-01-15.wav\n",
      "03-01-01-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-01-02-15.wav\n",
      "03-01-01-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-02-01-15.wav\n",
      "03-01-01-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-02-02-15.wav\n",
      "03-01-01-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-01-01-15.wav\n",
      "03-01-02-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-01-02-15.wav\n",
      "03-01-02-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-02-01-15.wav\n",
      "03-01-02-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-02-02-15.wav\n",
      "03-01-02-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-01-01-15.wav\n",
      "03-01-02-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-01-02-15.wav\n",
      "03-01-02-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-02-01-15.wav\n",
      "03-01-02-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-02-02-15.wav\n",
      "03-01-02-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-01-01-15.wav\n",
      "03-01-03-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-01-02-15.wav\n",
      "03-01-03-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-02-01-15.wav\n",
      "03-01-03-01-02-01-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 1.2207031e-04 1.2207031e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00210571 -0.00216675\n",
      " -0.0020752 ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-02-02-15.wav\n",
      "03-01-03-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-01-01-15.wav\n",
      "03-01-03-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-01-02-15.wav\n",
      "03-01-03-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-02-01-15.wav\n",
      "03-01-03-02-02-01-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 1.2207031e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-02-02-15.wav\n",
      "03-01-03-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-01-01-15.wav\n",
      "03-01-04-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-01-02-15.wav\n",
      "03-01-04-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-02-01-15.wav\n",
      "03-01-04-01-02-01-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 0.0000000e+00 3.0517578e-05 ... 1.5258789e-04 1.5258789e-04\n",
      " 1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04 -1.5258789e-04 -1.5258789e-04 ...  9.1552734e-05\n",
      "  9.1552734e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  1.5258789e-04\n",
      "  1.5258789e-04  1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-02-02-15.wav\n",
      "03-01-04-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-01-01-15.wav\n",
      "03-01-04-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-01-02-15.wav\n",
      "03-01-04-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-02-01-15.wav\n",
      "03-01-04-02-02-01-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00042725 0.00042725 0.00042725] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -1.2207031e-04 -1.2207031e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  1.3732910e-03\n",
      "  1.4038086e-03  1.4343262e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-02-02-15.wav\n",
      "03-01-04-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-01-01-15.wav\n",
      "03-01-05-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-01-02-15.wav\n",
      "03-01-05-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-02-01-15.wav\n",
      "03-01-05-01-02-01-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 9.1552734e-05  3.0517578e-05  1.2207031e-04 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.2207031e-04\n",
      " -1.5258789e-04 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-02-02-15.wav\n",
      "03-01-05-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-01-01-15.wav\n",
      "03-01-05-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-01-02-15.wav\n",
      "03-01-05-02-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00012207 -0.00012207\n",
      " -0.00012207] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-02-01-15.wav\n",
      "03-01-05-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-02-02-15.wav\n",
      "03-01-05-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-01-01-15.wav\n",
      "03-01-06-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-01-02-15.wav\n",
      "03-01-06-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-02-01-15.wav\n",
      "03-01-06-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-02-02-15.wav\n",
      "03-01-06-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-01-01-15.wav\n",
      "03-01-06-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-01-02-15.wav\n",
      "03-01-06-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-02-01-15.wav\n",
      "03-01-06-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-02-02-15.wav\n",
      "03-01-06-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-01-01-15.wav\n",
      "03-01-07-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-01-02-15.wav\n",
      "03-01-07-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-02-01-15.wav\n",
      "03-01-07-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-02-02-15.wav\n",
      "03-01-07-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-01-01-15.wav\n",
      "03-01-07-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-01-02-15.wav\n",
      "03-01-07-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-02-01-15.wav\n",
      "03-01-07-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-02-02-15.wav\n",
      "03-01-07-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-01-01-15.wav\n",
      "03-01-08-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-01-02-15.wav\n",
      "03-01-08-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-02-01-15.wav\n",
      "03-01-08-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-02-02-15.wav\n",
      "03-01-08-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-01-01-15.wav\n",
      "03-01-08-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-01-02-15.wav\n",
      "03-01-08-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-02-01-15.wav\n",
      "03-01-08-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-02-02-15.wav\n",
      "03-01-08-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-01-01-16.wav\n",
      "03-01-01-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-01-02-16.wav\n",
      "03-01-01-01-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  1.2207031e-04\n",
      "  1.5258789e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 6.1035156e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-02-01-16.wav\n",
      "03-01-01-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-02-02-16.wav\n",
      "03-01-01-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-01-01-16.wav\n",
      "03-01-02-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-01-02-16.wav\n",
      "03-01-02-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-02-01-16.wav\n",
      "03-01-02-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-02-02-16.wav\n",
      "03-01-02-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-01-01-16.wav\n",
      "03-01-02-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-01-02-16.wav\n",
      "03-01-02-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-02-01-16.wav\n",
      "03-01-02-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-02-02-16.wav\n",
      "03-01-02-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-01-01-16.wav\n",
      "03-01-03-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-01-02-16.wav\n",
      "03-01-03-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-02-01-16.wav\n",
      "03-01-03-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-02-02-16.wav\n",
      "03-01-03-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-01-01-16.wav\n",
      "03-01-03-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-01-02-16.wav\n",
      "03-01-03-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-02-01-16.wav\n",
      "03-01-03-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-02-02-16.wav\n",
      "03-01-03-02-02-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-01-01-16.wav\n",
      "03-01-04-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-01-02-16.wav\n",
      "03-01-04-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-02-01-16.wav\n",
      "03-01-04-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-02-02-16.wav\n",
      "03-01-04-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-01-01-16.wav\n",
      "03-01-04-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-01-02-16.wav\n",
      "03-01-04-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-02-01-16.wav\n",
      "03-01-04-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-02-02-16.wav\n",
      "03-01-04-02-02-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -6.1035156e-05 -1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-01-01-16.wav\n",
      "03-01-05-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-01-02-16.wav\n",
      "03-01-05-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-02-01-16.wav\n",
      "03-01-05-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-02-02-16.wav\n",
      "03-01-05-01-02-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-01-01-16.wav\n",
      "03-01-05-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-01-02-16.wav\n",
      "03-01-05-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-02-01-16.wav\n",
      "03-01-05-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-02-02-16.wav\n",
      "03-01-05-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-01-01-16.wav\n",
      "03-01-06-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-01-02-16.wav\n",
      "03-01-06-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-02-01-16.wav\n",
      "03-01-06-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-02-02-16.wav\n",
      "03-01-06-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-01-01-16.wav\n",
      "03-01-06-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-01-02-16.wav\n",
      "03-01-06-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-02-01-16.wav\n",
      "03-01-06-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-02-02-16.wav\n",
      "03-01-06-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-01-01-16.wav\n",
      "03-01-07-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-01-02-16.wav\n",
      "03-01-07-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-02-01-16.wav\n",
      "03-01-07-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-02-02-16.wav\n",
      "03-01-07-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-01-01-16.wav\n",
      "03-01-07-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-01-02-16.wav\n",
      "03-01-07-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-02-01-16.wav\n",
      "03-01-07-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-02-02-16.wav\n",
      "03-01-07-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-01-01-16.wav\n",
      "03-01-08-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-01-02-16.wav\n",
      "03-01-08-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-02-01-16.wav\n",
      "03-01-08-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-02-02-16.wav\n",
      "03-01-08-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-01-01-16.wav\n",
      "03-01-08-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-01-02-16.wav\n",
      "03-01-08-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-02-01-16.wav\n",
      "03-01-08-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-02-02-16.wav\n",
      "03-01-08-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-01-01-17.wav\n",
      "03-01-01-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-01-02-17.wav\n",
      "03-01-01-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-02-01-17.wav\n",
      "03-01-01-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-02-02-17.wav\n",
      "03-01-01-01-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-04  3.3569336e-04  3.0517578e-04 ... -9.1552734e-05\n",
      " -9.1552734e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[9.1552734e-05 9.1552734e-05 6.1035156e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -9.1552734e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-01-01-17.wav\n",
      "03-01-02-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-01-02-17.wav\n",
      "03-01-02-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-02-01-17.wav\n",
      "03-01-02-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-02-02-17.wav\n",
      "03-01-02-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-01-01-17.wav\n",
      "03-01-02-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-01-02-17.wav\n",
      "03-01-02-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-02-01-17.wav\n",
      "03-01-02-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-02-02-17.wav\n",
      "03-01-02-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-01-01-17.wav\n",
      "03-01-03-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-01-02-17.wav\n",
      "03-01-03-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-02-01-17.wav\n",
      "03-01-03-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-02-02-17.wav\n",
      "03-01-03-01-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  6.1035156e-05 ... -9.1552734e-05\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-2.1362305e-04 -9.1552734e-05  0.0000000e+00 ... -1.2207031e-04\n",
      " -1.5258789e-04 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 9.1552734e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[1.8310547e-04 1.5258789e-04 3.0517578e-05 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-01-01-17.wav\n",
      "03-01-03-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-01-02-17.wav\n",
      "03-01-03-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-02-01-17.wav\n",
      "03-01-03-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-02-02-17.wav\n",
      "03-01-03-02-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.5258789e-04 ... -2.4414062e-04\n",
      " -9.1552734e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.3569336e-04 -9.1552734e-05  3.9672852e-04 ...  1.5258789e-04\n",
      "  1.2207031e-04  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 1.8310547e-04  1.8310547e-04  6.1035156e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-01-01-17.wav\n",
      "03-01-04-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-01-02-17.wav\n",
      "03-01-04-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-02-01-17.wav\n",
      "03-01-04-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-02-02-17.wav\n",
      "03-01-04-01-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 1.2207031e-04 1.5258789e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.00012207 -0.00015259 -0.00018311 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 9.1552734e-05 9.1552734e-05 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00018311 0.00018311 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-01-01-17.wav\n",
      "03-01-04-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-01-02-17.wav\n",
      "03-01-04-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-02-01-17.wav\n",
      "03-01-04-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-02-02-17.wav\n",
      "03-01-04-02-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[1.8310547e-04 1.2207031e-04 3.0517578e-05 ... 1.2207031e-04 1.2207031e-04\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-04 -3.3569336e-04 -5.7983398e-04 ...  6.1035156e-05\n",
      "  9.1552734e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -6.1035156e-05 -6.1035156e-05 ... -1.5258789e-04\n",
      " -1.5258789e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-01-01-17.wav\n",
      "03-01-05-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-01-02-17.wav\n",
      "03-01-05-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-02-01-17.wav\n",
      "03-01-05-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-02-02-17.wav\n",
      "03-01-05-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-01-01-17.wav\n",
      "03-01-05-02-01-01-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ... -1.2207031e-04\n",
      " -1.5258789e-04 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[1.2207031e-04 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.5258789e-04 -6.1035156e-05 -1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.00018311 0.00018311 0.00018311 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-01-02-17.wav\n",
      "03-01-05-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-02-01-17.wav\n",
      "03-01-05-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-02-02-17.wav\n",
      "03-01-05-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-01-01-17.wav\n",
      "03-01-06-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-01-02-17.wav\n",
      "03-01-06-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-02-01-17.wav\n",
      "03-01-06-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-02-02-17.wav\n",
      "03-01-06-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-01-01-17.wav\n",
      "03-01-06-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-01-02-17.wav\n",
      "03-01-06-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-02-01-17.wav\n",
      "03-01-06-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-02-02-17.wav\n",
      "03-01-06-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-01-01-17.wav\n",
      "03-01-07-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-01-02-17.wav\n",
      "03-01-07-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-02-01-17.wav\n",
      "03-01-07-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-02-02-17.wav\n",
      "03-01-07-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-01-01-17.wav\n",
      "03-01-07-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-01-02-17.wav\n",
      "03-01-07-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-02-01-17.wav\n",
      "03-01-07-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-02-02-17.wav\n",
      "03-01-07-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-01-01-17.wav\n",
      "03-01-08-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-01-02-17.wav\n",
      "03-01-08-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-02-01-17.wav\n",
      "03-01-08-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-02-02-17.wav\n",
      "03-01-08-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-01-01-17.wav\n",
      "03-01-08-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-01-02-17.wav\n",
      "03-01-08-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-02-01-17.wav\n",
      "03-01-08-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-02-02-17.wav\n",
      "03-01-08-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-01-01-18.wav\n",
      "03-01-01-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-01-02-18.wav\n",
      "03-01-01-01-01-02-18.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-2.4414062e-04 -9.1552734e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-02-01-18.wav\n",
      "03-01-01-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-02-02-18.wav\n",
      "03-01-01-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-01-01-18.wav\n",
      "03-01-02-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-01-02-18.wav\n",
      "03-01-02-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-02-01-18.wav\n",
      "03-01-02-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-02-02-18.wav\n",
      "03-01-02-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-01-01-18.wav\n",
      "03-01-02-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-01-02-18.wav\n",
      "03-01-02-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-02-01-18.wav\n",
      "03-01-02-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-02-02-18.wav\n",
      "03-01-02-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-01-01-18.wav\n",
      "03-01-03-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-01-02-18.wav\n",
      "03-01-03-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-02-01-18.wav\n",
      "03-01-03-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-02-02-18.wav\n",
      "03-01-03-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-01-01-18.wav\n",
      "03-01-03-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-01-02-18.wav\n",
      "03-01-03-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-02-01-18.wav\n",
      "03-01-03-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-02-02-18.wav\n",
      "03-01-03-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-01-01-18.wav\n",
      "03-01-04-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-01-02-18.wav\n",
      "03-01-04-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-02-01-18.wav\n",
      "03-01-04-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-02-02-18.wav\n",
      "03-01-04-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-01-01-18.wav\n",
      "03-01-04-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-01-02-18.wav\n",
      "03-01-04-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-02-01-18.wav\n",
      "03-01-04-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-02-02-18.wav\n",
      "03-01-04-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-01-01-18.wav\n",
      "03-01-05-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-01-02-18.wav\n",
      "03-01-05-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-02-01-18.wav\n",
      "03-01-05-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-02-02-18.wav\n",
      "03-01-05-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-01-01-18.wav\n",
      "03-01-05-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-01-02-18.wav\n",
      "03-01-05-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-02-01-18.wav\n",
      "03-01-05-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-02-02-18.wav\n",
      "03-01-05-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-01-01-18.wav\n",
      "03-01-06-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-01-02-18.wav\n",
      "03-01-06-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-02-01-18.wav\n",
      "03-01-06-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-02-02-18.wav\n",
      "03-01-06-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-01-01-18.wav\n",
      "03-01-06-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-01-02-18.wav\n",
      "03-01-06-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-02-01-18.wav\n",
      "03-01-06-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-02-02-18.wav\n",
      "03-01-06-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-01-01-18.wav\n",
      "03-01-07-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-01-02-18.wav\n",
      "03-01-07-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-02-01-18.wav\n",
      "03-01-07-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-02-02-18.wav\n",
      "03-01-07-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-01-01-18.wav\n",
      "03-01-07-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-01-02-18.wav\n",
      "03-01-07-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-02-01-18.wav\n",
      "03-01-07-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-02-02-18.wav\n",
      "03-01-07-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-01-01-18.wav\n",
      "03-01-08-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-01-02-18.wav\n",
      "03-01-08-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-02-01-18.wav\n",
      "03-01-08-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-02-02-18.wav\n",
      "03-01-08-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-01-01-18.wav\n",
      "03-01-08-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-01-02-18.wav\n",
      "03-01-08-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-02-01-18.wav\n",
      "03-01-08-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-02-02-18.wav\n",
      "03-01-08-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-01-01-19.wav\n",
      "03-01-01-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-01-02-19.wav\n",
      "03-01-01-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-02-01-19.wav\n",
      "03-01-01-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-02-02-19.wav\n",
      "03-01-01-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-01-01-19.wav\n",
      "03-01-02-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-01-02-19.wav\n",
      "03-01-02-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-02-01-19.wav\n",
      "03-01-02-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-02-02-19.wav\n",
      "03-01-02-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-01-01-19.wav\n",
      "03-01-02-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-01-02-19.wav\n",
      "03-01-02-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-02-01-19.wav\n",
      "03-01-02-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-02-02-19.wav\n",
      "03-01-02-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-01-01-19.wav\n",
      "03-01-03-01-01-01-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.00018311 -0.00018311 -0.00021362 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.         0.         0.         ... 0.00308228 0.00311279 0.00308228] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 0.0000000e+00 ... 9.1552734e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-01-02-19.wav\n",
      "03-01-03-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-02-01-19.wav\n",
      "03-01-03-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-02-02-19.wav\n",
      "03-01-03-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-01-01-19.wav\n",
      "03-01-03-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-01-02-19.wav\n",
      "03-01-03-02-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -1.2207031e-04 ...  9.1552734e-05\n",
      "  9.1552734e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.00036621  0.00045776  0.00048828 ... -0.00021362 -0.00021362\n",
      " -0.00021362] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.00067139  0.00076294  0.00106812 ...  0.00344849 -0.00195312\n",
      " -0.00204468] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-02-01-19.wav\n",
      "03-01-03-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-02-02-19.wav\n",
      "03-01-03-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-01-01-19.wav\n",
      "03-01-04-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-01-02-19.wav\n",
      "03-01-04-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -1.2207031e-04 ...  3.0517578e-05\n",
      "  3.0517578e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 6.1035156e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-02-01-19.wav\n",
      "03-01-04-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-02-02-19.wav\n",
      "03-01-04-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-01-01-19.wav\n",
      "03-01-04-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-01-02-19.wav\n",
      "03-01-04-02-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00125122 -0.00125122\n",
      " -0.00125122] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.0022583  -0.00228882 -0.00234985 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.00048828 -0.00036621 -0.00027466 ... -0.00021362 -0.00021362\n",
      " -0.00021362] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-02-01-19.wav\n",
      "03-01-04-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-02-02-19.wav\n",
      "03-01-04-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-01-01-19.wav\n",
      "03-01-05-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-01-02-19.wav\n",
      "03-01-05-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -9.1552734e-05 ...  3.9672852e-04\n",
      "  3.9672852e-04  3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-0.00283813 -0.00286865 -0.00286865 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-02-01-19.wav\n",
      "03-01-05-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-02-02-19.wav\n",
      "03-01-05-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-01-01-19.wav\n",
      "03-01-05-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-01-02-19.wav\n",
      "03-01-05-02-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 6.1035156e-05 -3.0517578e-05  2.1362305e-04 ...  0.0000000e+00\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-02-01-19.wav\n",
      "03-01-05-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-02-02-19.wav\n",
      "03-01-05-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-01-01-19.wav\n",
      "03-01-06-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-01-02-19.wav\n",
      "03-01-06-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-02-01-19.wav\n",
      "03-01-06-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-02-02-19.wav\n",
      "03-01-06-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-01-01-19.wav\n",
      "03-01-06-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-01-02-19.wav\n",
      "03-01-06-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-02-01-19.wav\n",
      "03-01-06-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-02-02-19.wav\n",
      "03-01-06-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-01-01-19.wav\n",
      "03-01-07-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-01-02-19.wav\n",
      "03-01-07-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-02-01-19.wav\n",
      "03-01-07-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-02-02-19.wav\n",
      "03-01-07-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-01-01-19.wav\n",
      "03-01-07-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-01-02-19.wav\n",
      "03-01-07-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-02-01-19.wav\n",
      "03-01-07-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-02-02-19.wav\n",
      "03-01-07-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-01-01-19.wav\n",
      "03-01-08-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-01-02-19.wav\n",
      "03-01-08-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-02-01-19.wav\n",
      "03-01-08-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-02-02-19.wav\n",
      "03-01-08-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-01-01-19.wav\n",
      "03-01-08-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-01-02-19.wav\n",
      "03-01-08-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-02-01-19.wav\n",
      "03-01-08-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-02-02-19.wav\n",
      "03-01-08-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-01-01-20.wav\n",
      "03-01-01-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-01-02-20.wav\n",
      "03-01-01-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-02-01-20.wav\n",
      "03-01-01-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-02-02-20.wav\n",
      "03-01-01-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-01-01-20.wav\n",
      "03-01-02-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-01-02-20.wav\n",
      "03-01-02-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-02-01-20.wav\n",
      "03-01-02-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-02-02-20.wav\n",
      "03-01-02-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-01-01-20.wav\n",
      "03-01-02-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-01-02-20.wav\n",
      "03-01-02-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-02-01-20.wav\n",
      "03-01-02-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-02-02-20.wav\n",
      "03-01-02-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-01-01-20.wav\n",
      "03-01-03-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-01-02-20.wav\n",
      "03-01-03-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-02-01-20.wav\n",
      "03-01-03-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-02-02-20.wav\n",
      "03-01-03-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-01-01-20.wav\n",
      "03-01-03-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-01-02-20.wav\n",
      "03-01-03-02-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-02-01-20.wav\n",
      "03-01-03-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-02-02-20.wav\n",
      "03-01-03-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-01-01-20.wav\n",
      "03-01-04-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-01-02-20.wav\n",
      "03-01-04-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-02-01-20.wav\n",
      "03-01-04-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-02-02-20.wav\n",
      "03-01-04-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-01-01-20.wav\n",
      "03-01-04-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-01-02-20.wav\n",
      "03-01-04-02-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.01150513 -0.0135498\n",
      "  0.01361084] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-02-01-20.wav\n",
      "03-01-04-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-02-02-20.wav\n",
      "03-01-04-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-01-01-20.wav\n",
      "03-01-05-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-01-02-20.wav\n",
      "03-01-05-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-02-01-20.wav\n",
      "03-01-05-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-02-02-20.wav\n",
      "03-01-05-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-01-01-20.wav\n",
      "03-01-05-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-01-02-20.wav\n",
      "03-01-05-02-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-02-01-20.wav\n",
      "03-01-05-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-02-02-20.wav\n",
      "03-01-05-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-01-01-20.wav\n",
      "03-01-06-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-01-02-20.wav\n",
      "03-01-06-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-02-01-20.wav\n",
      "03-01-06-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-02-02-20.wav\n",
      "03-01-06-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-01-01-20.wav\n",
      "03-01-06-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-01-02-20.wav\n",
      "03-01-06-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-02-01-20.wav\n",
      "03-01-06-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-02-02-20.wav\n",
      "03-01-06-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-01-01-20.wav\n",
      "03-01-07-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-01-02-20.wav\n",
      "03-01-07-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-02-01-20.wav\n",
      "03-01-07-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-02-02-20.wav\n",
      "03-01-07-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-01-01-20.wav\n",
      "03-01-07-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-01-02-20.wav\n",
      "03-01-07-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-02-01-20.wav\n",
      "03-01-07-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-02-02-20.wav\n",
      "03-01-07-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-01-01-20.wav\n",
      "03-01-08-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-01-02-20.wav\n",
      "03-01-08-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-02-01-20.wav\n",
      "03-01-08-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-02-02-20.wav\n",
      "03-01-08-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-01-01-20.wav\n",
      "03-01-08-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-01-02-20.wav\n",
      "03-01-08-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-02-01-20.wav\n",
      "03-01-08-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-02-02-20.wav\n",
      "03-01-08-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-01-01-21.wav\n",
      "03-01-01-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-01-02-21.wav\n",
      "03-01-01-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-02-01-21.wav\n",
      "03-01-01-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-02-02-21.wav\n",
      "03-01-01-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-01-01-21.wav\n",
      "03-01-02-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-01-02-21.wav\n",
      "03-01-02-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-02-01-21.wav\n",
      "03-01-02-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-02-02-21.wav\n",
      "03-01-02-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-01-01-21.wav\n",
      "03-01-02-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-01-02-21.wav\n",
      "03-01-02-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-02-01-21.wav\n",
      "03-01-02-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-02-02-21.wav\n",
      "03-01-02-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-01-01-21.wav\n",
      "03-01-03-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-01-02-21.wav\n",
      "03-01-03-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-02-01-21.wav\n",
      "03-01-03-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-02-02-21.wav\n",
      "03-01-03-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-01-01-21.wav\n",
      "03-01-03-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-01-02-21.wav\n",
      "03-01-03-02-01-02-21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-02-01-21.wav\n",
      "03-01-03-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-02-02-21.wav\n",
      "03-01-03-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-01-01-21.wav\n",
      "03-01-04-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-01-02-21.wav\n",
      "03-01-04-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-02-01-21.wav\n",
      "03-01-04-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-02-02-21.wav\n",
      "03-01-04-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-01-01-21.wav\n",
      "03-01-04-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-01-02-21.wav\n",
      "03-01-04-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-02-01-21.wav\n",
      "03-01-04-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-02-02-21.wav\n",
      "03-01-04-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-01-01-21.wav\n",
      "03-01-05-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-01-02-21.wav\n",
      "03-01-05-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-02-01-21.wav\n",
      "03-01-05-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-02-02-21.wav\n",
      "03-01-05-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-01-01-21.wav\n",
      "03-01-05-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-01-02-21.wav\n",
      "03-01-05-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-02-01-21.wav\n",
      "03-01-05-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-02-02-21.wav\n",
      "03-01-05-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-01-01-21.wav\n",
      "03-01-06-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-01-02-21.wav\n",
      "03-01-06-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-02-01-21.wav\n",
      "03-01-06-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-02-02-21.wav\n",
      "03-01-06-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-01-01-21.wav\n",
      "03-01-06-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-01-02-21.wav\n",
      "03-01-06-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-02-01-21.wav\n",
      "03-01-06-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-02-02-21.wav\n",
      "03-01-06-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-01-01-21.wav\n",
      "03-01-07-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-01-02-21.wav\n",
      "03-01-07-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-02-01-21.wav\n",
      "03-01-07-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-02-02-21.wav\n",
      "03-01-07-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-01-01-21.wav\n",
      "03-01-07-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-01-02-21.wav\n",
      "03-01-07-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-02-01-21.wav\n",
      "03-01-07-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-02-02-21.wav\n",
      "03-01-07-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-01-01-21.wav\n",
      "03-01-08-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-01-02-21.wav\n",
      "03-01-08-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-02-01-21.wav\n",
      "03-01-08-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-02-02-21.wav\n",
      "03-01-08-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-01-01-21.wav\n",
      "03-01-08-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-01-02-21.wav\n",
      "03-01-08-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-02-01-21.wav\n",
      "03-01-08-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-02-02-21.wav\n",
      "03-01-08-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-01-01-22.wav\n",
      "03-01-01-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-01-02-22.wav\n",
      "03-01-01-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-02-01-22.wav\n",
      "03-01-01-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-02-02-22.wav\n",
      "03-01-01-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-01-01-22.wav\n",
      "03-01-02-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-01-02-22.wav\n",
      "03-01-02-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-02-01-22.wav\n",
      "03-01-02-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-02-02-22.wav\n",
      "03-01-02-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-01-01-22.wav\n",
      "03-01-02-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-01-02-22.wav\n",
      "03-01-02-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-02-01-22.wav\n",
      "03-01-02-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-02-02-22.wav\n",
      "03-01-02-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-01-01-22.wav\n",
      "03-01-03-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-01-02-22.wav\n",
      "03-01-03-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-02-01-22.wav\n",
      "03-01-03-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-02-02-22.wav\n",
      "03-01-03-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-01-01-22.wav\n",
      "03-01-03-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-01-02-22.wav\n",
      "03-01-03-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-02-01-22.wav\n",
      "03-01-03-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-02-02-22.wav\n",
      "03-01-03-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-01-01-22.wav\n",
      "03-01-04-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-01-02-22.wav\n",
      "03-01-04-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-02-01-22.wav\n",
      "03-01-04-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-02-02-22.wav\n",
      "03-01-04-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-01-01-22.wav\n",
      "03-01-04-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-01-02-22.wav\n",
      "03-01-04-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-02-01-22.wav\n",
      "03-01-04-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-02-02-22.wav\n",
      "03-01-04-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-01-01-22.wav\n",
      "03-01-05-01-01-01-22.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-01-02-22.wav\n",
      "03-01-05-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-02-01-22.wav\n",
      "03-01-05-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-02-02-22.wav\n",
      "03-01-05-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-01-01-22.wav\n",
      "03-01-05-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-01-02-22.wav\n",
      "03-01-05-02-01-02-22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-02-01-22.wav\n",
      "03-01-05-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-02-02-22.wav\n",
      "03-01-05-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-01-01-22.wav\n",
      "03-01-06-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-01-02-22.wav\n",
      "03-01-06-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-02-01-22.wav\n",
      "03-01-06-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-02-02-22.wav\n",
      "03-01-06-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-01-01-22.wav\n",
      "03-01-06-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-01-02-22.wav\n",
      "03-01-06-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-02-01-22.wav\n",
      "03-01-06-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-02-02-22.wav\n",
      "03-01-06-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-01-01-22.wav\n",
      "03-01-07-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-01-02-22.wav\n",
      "03-01-07-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-02-01-22.wav\n",
      "03-01-07-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-02-02-22.wav\n",
      "03-01-07-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-01-01-22.wav\n",
      "03-01-07-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-01-02-22.wav\n",
      "03-01-07-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-02-01-22.wav\n",
      "03-01-07-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-02-02-22.wav\n",
      "03-01-07-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-01-01-22.wav\n",
      "03-01-08-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-01-02-22.wav\n",
      "03-01-08-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-02-01-22.wav\n",
      "03-01-08-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-02-02-22.wav\n",
      "03-01-08-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-01-01-22.wav\n",
      "03-01-08-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-01-02-22.wav\n",
      "03-01-08-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-02-01-22.wav\n",
      "03-01-08-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-02-02-22.wav\n",
      "03-01-08-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-01-01-23.wav\n",
      "03-01-01-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-01-02-23.wav\n",
      "03-01-01-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-02-01-23.wav\n",
      "03-01-01-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-02-02-23.wav\n",
      "03-01-01-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-01-01-23.wav\n",
      "03-01-02-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-01-02-23.wav\n",
      "03-01-02-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-02-01-23.wav\n",
      "03-01-02-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-02-02-23.wav\n",
      "03-01-02-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-01-01-23.wav\n",
      "03-01-02-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-01-02-23.wav\n",
      "03-01-02-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-02-01-23.wav\n",
      "03-01-02-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-02-02-23.wav\n",
      "03-01-02-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-01-01-23.wav\n",
      "03-01-03-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-01-02-23.wav\n",
      "03-01-03-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-02-01-23.wav\n",
      "03-01-03-01-02-01-23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-02-02-23.wav\n",
      "03-01-03-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-01-01-23.wav\n",
      "03-01-03-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-01-02-23.wav\n",
      "03-01-03-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-02-01-23.wav\n",
      "03-01-03-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-02-02-23.wav\n",
      "03-01-03-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-01-01-23.wav\n",
      "03-01-04-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-01-02-23.wav\n",
      "03-01-04-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-02-01-23.wav\n",
      "03-01-04-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-02-02-23.wav\n",
      "03-01-04-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-01-01-23.wav\n",
      "03-01-04-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-01-02-23.wav\n",
      "03-01-04-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-02-01-23.wav\n",
      "03-01-04-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-02-02-23.wav\n",
      "03-01-04-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-01-01-23.wav\n",
      "03-01-05-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-01-02-23.wav\n",
      "03-01-05-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-02-01-23.wav\n",
      "03-01-05-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-02-02-23.wav\n",
      "03-01-05-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-01-01-23.wav\n",
      "03-01-05-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-01-02-23.wav\n",
      "03-01-05-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-02-01-23.wav\n",
      "03-01-05-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-02-02-23.wav\n",
      "03-01-05-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-01-01-23.wav\n",
      "03-01-06-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-01-02-23.wav\n",
      "03-01-06-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-02-01-23.wav\n",
      "03-01-06-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-02-02-23.wav\n",
      "03-01-06-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-01-01-23.wav\n",
      "03-01-06-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-01-02-23.wav\n",
      "03-01-06-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-02-01-23.wav\n",
      "03-01-06-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-02-02-23.wav\n",
      "03-01-06-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-01-01-23.wav\n",
      "03-01-07-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-01-02-23.wav\n",
      "03-01-07-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-02-01-23.wav\n",
      "03-01-07-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-02-02-23.wav\n",
      "03-01-07-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-01-01-23.wav\n",
      "03-01-07-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-01-02-23.wav\n",
      "03-01-07-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-02-01-23.wav\n",
      "03-01-07-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-02-02-23.wav\n",
      "03-01-07-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-01-01-23.wav\n",
      "03-01-08-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-01-02-23.wav\n",
      "03-01-08-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-02-01-23.wav\n",
      "03-01-08-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-02-02-23.wav\n",
      "03-01-08-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-01-01-23.wav\n",
      "03-01-08-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-01-02-23.wav\n",
      "03-01-08-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-02-01-23.wav\n",
      "03-01-08-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-02-02-23.wav\n",
      "03-01-08-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-01-01-24.wav\n",
      "03-01-01-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-01-02-24.wav\n",
      "03-01-01-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-02-01-24.wav\n",
      "03-01-01-01-02-01-24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-02-02-24.wav\n",
      "03-01-01-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-01-01-24.wav\n",
      "03-01-02-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-01-02-24.wav\n",
      "03-01-02-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-02-01-24.wav\n",
      "03-01-02-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-02-02-24.wav\n",
      "03-01-02-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-01-01-24.wav\n",
      "03-01-02-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-01-02-24.wav\n",
      "03-01-02-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-02-01-24.wav\n",
      "03-01-02-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-02-02-24.wav\n",
      "03-01-02-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-01-01-24.wav\n",
      "03-01-03-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-01-02-24.wav\n",
      "03-01-03-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-02-01-24.wav\n",
      "03-01-03-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-02-02-24.wav\n",
      "03-01-03-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-01-01-24.wav\n",
      "03-01-03-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-01-02-24.wav\n",
      "03-01-03-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-02-01-24.wav\n",
      "03-01-03-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-02-02-24.wav\n",
      "03-01-03-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-01-01-24.wav\n",
      "03-01-04-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-01-02-24.wav\n",
      "03-01-04-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-02-01-24.wav\n",
      "03-01-04-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-02-02-24.wav\n",
      "03-01-04-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-01-01-24.wav\n",
      "03-01-04-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-01-02-24.wav\n",
      "03-01-04-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-02-01-24.wav\n",
      "03-01-04-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-02-02-24.wav\n",
      "03-01-04-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-01-01-24.wav\n",
      "03-01-05-01-01-01-24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.5258789e-04\n",
      " -1.5258789e-04 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-01-02-24.wav\n",
      "03-01-05-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-02-01-24.wav\n",
      "03-01-05-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-02-02-24.wav\n",
      "03-01-05-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-01-01-24.wav\n",
      "03-01-05-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-01-02-24.wav\n",
      "03-01-05-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-02-01-24.wav\n",
      "03-01-05-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-02-02-24.wav\n",
      "03-01-05-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-01-01-24.wav\n",
      "03-01-06-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-01-02-24.wav\n",
      "03-01-06-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-02-01-24.wav\n",
      "03-01-06-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-02-02-24.wav\n",
      "03-01-06-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-01-01-24.wav\n",
      "03-01-06-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-01-02-24.wav\n",
      "03-01-06-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-02-01-24.wav\n",
      "03-01-06-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-02-02-24.wav\n",
      "03-01-06-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-01-01-24.wav\n",
      "03-01-07-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-01-02-24.wav\n",
      "03-01-07-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-02-01-24.wav\n",
      "03-01-07-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-02-02-24.wav\n",
      "03-01-07-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-01-01-24.wav\n",
      "03-01-07-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-01-02-24.wav\n",
      "03-01-07-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-02-01-24.wav\n",
      "03-01-07-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-02-02-24.wav\n",
      "03-01-07-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-01-01-24.wav\n",
      "03-01-08-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-01-02-24.wav\n",
      "03-01-08-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-02-01-24.wav\n",
      "03-01-08-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-02-02-24.wav\n",
      "03-01-08-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-01-01-24.wav\n",
      "03-01-08-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-01-02-24.wav\n",
      "03-01-08-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-02-01-24.wav\n",
      "03-01-08-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-02-02-24.wav\n",
      "03-01-08-02-02-02-24.wav\n",
      "[+] Number of training samples: 537\n",
      "[+] Number of testing samples: 135\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GO3OzGWt22Sq"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train= np.asarray(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape\n",
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)\n",
    "x_traincnn.shape,x_testcnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HmqNzFs85Ck6",
    "outputId": "18ef3b9d-a617-4aa4-9667-b52712b79d3f"
   },
   "source": [
    "# CNN - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhBOW8Rk5VKt"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))        #1\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))                           #2\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))                                                 #3\n",
    "model.add(Activation('softmax'))\n",
    "optimizer=keras.optimizers.RMSprop(learning_rate=0.001,\n",
    "    rho=0.9,\n",
    "    epsilon=None,\n",
    "    centered=False,\n",
    "    name='RMSprop'\n",
    ")\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "q5nm0kqP5hV1",
    "outputId": "4cbea3dc-c70e-4613-e05a-07cc5fd246af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 22, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 128)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2816)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 22536     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105,352\n",
      "Trainable params: 105,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K6opFz235tL0",
    "outputId": "b509e32f-8d14-477c-d8a1-35e919a159d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 3s 42ms/step - loss: 7.8132 - accuracy: 0.3054 - val_loss: 3.0787 - val_accuracy: 0.3630\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 3.2469 - accuracy: 0.3743 - val_loss: 2.8034 - val_accuracy: 0.3185\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 2.3190 - accuracy: 0.3855 - val_loss: 1.1809 - val_accuracy: 0.5333\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.4291 - accuracy: 0.4395 - val_loss: 1.3033 - val_accuracy: 0.5185\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.3179 - accuracy: 0.4376 - val_loss: 1.1138 - val_accuracy: 0.5481\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.1662 - accuracy: 0.4581 - val_loss: 1.0895 - val_accuracy: 0.4741\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.1531 - accuracy: 0.4786 - val_loss: 0.9893 - val_accuracy: 0.5111\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.0924 - accuracy: 0.5084 - val_loss: 1.2905 - val_accuracy: 0.4222\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.0748 - accuracy: 0.5158 - val_loss: 1.0592 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.9998 - accuracy: 0.5345 - val_loss: 0.8625 - val_accuracy: 0.6148\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.0088 - accuracy: 0.5568 - val_loss: 1.0676 - val_accuracy: 0.5778\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.9514 - accuracy: 0.5531 - val_loss: 0.9514 - val_accuracy: 0.5704\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.9413 - accuracy: 0.5587 - val_loss: 0.9157 - val_accuracy: 0.5704\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.8920 - accuracy: 0.6220 - val_loss: 0.8274 - val_accuracy: 0.6296\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8630 - accuracy: 0.5829 - val_loss: 0.9706 - val_accuracy: 0.6444\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8536 - accuracy: 0.6350 - val_loss: 0.7762 - val_accuracy: 0.6444\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8252 - accuracy: 0.6220 - val_loss: 0.9098 - val_accuracy: 0.6296\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8217 - accuracy: 0.6387 - val_loss: 0.9302 - val_accuracy: 0.5852\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8095 - accuracy: 0.6518 - val_loss: 0.9068 - val_accuracy: 0.6222\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8073 - accuracy: 0.6611 - val_loss: 0.9096 - val_accuracy: 0.6889\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7495 - accuracy: 0.6834 - val_loss: 0.7477 - val_accuracy: 0.6963\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7636 - accuracy: 0.6853 - val_loss: 0.8422 - val_accuracy: 0.6074\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7375 - accuracy: 0.6797 - val_loss: 0.9384 - val_accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7300 - accuracy: 0.6834 - val_loss: 0.8283 - val_accuracy: 0.6148\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.7157 - accuracy: 0.6965 - val_loss: 0.8001 - val_accuracy: 0.6444\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6654 - accuracy: 0.7374 - val_loss: 0.7894 - val_accuracy: 0.6148\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.6646 - accuracy: 0.7114 - val_loss: 0.8377 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6540 - accuracy: 0.7300 - val_loss: 0.8836 - val_accuracy: 0.6148\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6572 - accuracy: 0.7244 - val_loss: 0.7100 - val_accuracy: 0.7185\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.6461 - accuracy: 0.7207 - val_loss: 0.7516 - val_accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6058 - accuracy: 0.7505 - val_loss: 0.7169 - val_accuracy: 0.7111\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5681 - accuracy: 0.7449 - val_loss: 0.8801 - val_accuracy: 0.6370\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.5997 - accuracy: 0.7449 - val_loss: 0.7026 - val_accuracy: 0.7111\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5765 - accuracy: 0.7598 - val_loss: 0.7210 - val_accuracy: 0.6593\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.5382 - accuracy: 0.7821 - val_loss: 0.8814 - val_accuracy: 0.6815\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.5627 - accuracy: 0.7691 - val_loss: 0.7748 - val_accuracy: 0.6963\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4956 - accuracy: 0.8063 - val_loss: 0.8790 - val_accuracy: 0.6593\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 0.5039 - accuracy: 0.8026 - val_loss: 0.7075 - val_accuracy: 0.6963\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4889 - accuracy: 0.7858 - val_loss: 0.7617 - val_accuracy: 0.7037\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4691 - accuracy: 0.8156 - val_loss: 1.0061 - val_accuracy: 0.6296\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.4763 - accuracy: 0.8231 - val_loss: 0.7257 - val_accuracy: 0.6519\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4699 - accuracy: 0.8194 - val_loss: 0.7422 - val_accuracy: 0.7111\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4751 - accuracy: 0.8399 - val_loss: 0.6338 - val_accuracy: 0.6963\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4120 - accuracy: 0.8492 - val_loss: 0.6246 - val_accuracy: 0.7111\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.3807 - accuracy: 0.8603 - val_loss: 0.7121 - val_accuracy: 0.7037\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4388 - accuracy: 0.8231 - val_loss: 0.9662 - val_accuracy: 0.6741\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4340 - accuracy: 0.8622 - val_loss: 0.5908 - val_accuracy: 0.7037\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.3833 - accuracy: 0.8566 - val_loss: 0.8797 - val_accuracy: 0.6370\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.3882 - accuracy: 0.8734 - val_loss: 0.9599 - val_accuracy: 0.6222\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.3495 - accuracy: 0.8603 - val_loss: 1.0055 - val_accuracy: 0.6148\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRBYh-bMHucX"
   },
   "outputs": [],
   "source": [
    "em=['happy','sad','neutral','angry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using CNN-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GrrqoLzFAJDq",
    "outputId": "127a4973-55a9-4310-9df2-5d2ccef3f574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step\n",
      "sad\n",
      "[2.1499205e-02 2.1553180e-13 8.8360977e-33 1.6604527e-11 9.7850078e-01\n",
      " 2.1106075e-33 5.6266874e-33 3.5625421e-33]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_testcnn)\n",
    "n=predictions[1]\n",
    "print(em[1])\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CxJc4kIaD9IK",
    "outputId": "943689bb-a472-4a03-fd96-38a5d9e4c69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0055 - accuracy: 0.6148\n",
      "Restored model, accuracy: 61.48%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kVanJ86-FhwS",
    "outputId": "c8194727-9ef5-4e72-d1e2-26c6100cdb74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "result : happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14980\\90870015.py:20: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    }
   ],
   "source": [
    "filename = \"C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset/Actor_02/03-01-01-01-02-01-02.wav\"\n",
    "    # record the file (start talking)\n",
    "    #record_to_file(filename)\n",
    "    # extract features and reshape it\n",
    "features = np.array(extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1))\n",
    "    # predict\n",
    "f=np.expand_dims(features,axis=2)\n",
    "result = model.predict(f)[0]\n",
    "    # show the result !\n",
    "print(\"result :\",em[int(result[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1vlkqDPlA8A"
   },
   "source": [
    "# CNN - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQR38pmCSaNU"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "um = Sequential()\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
    "um.add(Activation('relu'))\n",
    "um.add(Dropout(0.25))\n",
    "um.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',))                  #2\n",
    "um.add(Activation('relu'))\n",
    "um.add(MaxPooling1D(pool_size=(8)))\n",
    "um.add(Dropout(0.25))\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',))                  #3\n",
    "um.add(Activation('relu'))\n",
    "um.add(Dropout(0.25))\n",
    "\n",
    "um.add(Flatten())\n",
    "um.add(Dense(8))                                        #4                      \n",
    "um.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.00005,epsilon=None,rho=0.9,decay=0.0)\n",
    "\n",
    "um.summary()\n",
    "\n",
    "um.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0XiAWqd1bg5M",
    "outputId": "7c46bbcc-c4b1-425d-f06d-5f516ac6a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 3s 31ms/step - loss: 10.3956 - accuracy: 0.1508 - val_loss: 2.1964 - val_accuracy: 0.2296\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 6.9648 - accuracy: 0.2588 - val_loss: 2.0040 - val_accuracy: 0.2519\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 6.2640 - accuracy: 0.2346 - val_loss: 1.5333 - val_accuracy: 0.3259\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 5.3013 - accuracy: 0.2719 - val_loss: 1.4507 - val_accuracy: 0.4222\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 5.3416 - accuracy: 0.2309 - val_loss: 1.2651 - val_accuracy: 0.4519\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 4.3266 - accuracy: 0.3240 - val_loss: 1.2888 - val_accuracy: 0.4148\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 4.4067 - accuracy: 0.2700 - val_loss: 1.2010 - val_accuracy: 0.4593\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 3.9510 - accuracy: 0.2812 - val_loss: 1.3214 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 3.3824 - accuracy: 0.3147 - val_loss: 1.3729 - val_accuracy: 0.3704\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 3.2767 - accuracy: 0.3035 - val_loss: 1.2503 - val_accuracy: 0.4593\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.9605 - accuracy: 0.3091 - val_loss: 1.2633 - val_accuracy: 0.4370\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.7017 - accuracy: 0.3091 - val_loss: 1.2664 - val_accuracy: 0.4000\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.5040 - accuracy: 0.3315 - val_loss: 1.2912 - val_accuracy: 0.3926\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.3374 - accuracy: 0.3240 - val_loss: 1.3076 - val_accuracy: 0.3926\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.3316 - accuracy: 0.2998 - val_loss: 1.3299 - val_accuracy: 0.3778\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.2462 - accuracy: 0.3147 - val_loss: 1.3404 - val_accuracy: 0.3704\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.1730 - accuracy: 0.2831 - val_loss: 1.3507 - val_accuracy: 0.3704\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.0620 - accuracy: 0.3166 - val_loss: 1.3601 - val_accuracy: 0.3556\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.9039 - accuracy: 0.3557 - val_loss: 1.3898 - val_accuracy: 0.3630\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.9046 - accuracy: 0.3259 - val_loss: 1.3927 - val_accuracy: 0.3926\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.9242 - accuracy: 0.2812 - val_loss: 1.4035 - val_accuracy: 0.3556\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.7298 - accuracy: 0.3575 - val_loss: 1.3732 - val_accuracy: 0.3852\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.7314 - accuracy: 0.3557 - val_loss: 1.3570 - val_accuracy: 0.3852\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.6892 - accuracy: 0.3687 - val_loss: 1.3421 - val_accuracy: 0.3926\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.7795 - accuracy: 0.3166 - val_loss: 1.3470 - val_accuracy: 0.3926\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.5744 - accuracy: 0.3613 - val_loss: 1.3371 - val_accuracy: 0.4074\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.6551 - accuracy: 0.3371 - val_loss: 1.3317 - val_accuracy: 0.4519\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.5540 - accuracy: 0.3855 - val_loss: 1.3263 - val_accuracy: 0.3852\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.5306 - accuracy: 0.3594 - val_loss: 1.3623 - val_accuracy: 0.3704\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.5758 - accuracy: 0.3501 - val_loss: 1.3495 - val_accuracy: 0.4074\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.5373 - accuracy: 0.3594 - val_loss: 1.3412 - val_accuracy: 0.4148\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.5962 - accuracy: 0.3408 - val_loss: 1.3554 - val_accuracy: 0.4148\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.5507 - accuracy: 0.3650 - val_loss: 1.3417 - val_accuracy: 0.3778\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.5178 - accuracy: 0.3445 - val_loss: 1.3526 - val_accuracy: 0.3704\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.4739 - accuracy: 0.3780 - val_loss: 1.3493 - val_accuracy: 0.4370\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.4816 - accuracy: 0.3501 - val_loss: 1.3391 - val_accuracy: 0.3704\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.5026 - accuracy: 0.3501 - val_loss: 1.3280 - val_accuracy: 0.4296\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.4640 - accuracy: 0.3538 - val_loss: 1.3231 - val_accuracy: 0.4074\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.5053 - accuracy: 0.3389 - val_loss: 1.3006 - val_accuracy: 0.5037\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.4448 - accuracy: 0.3836 - val_loss: 1.2990 - val_accuracy: 0.5037\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.4341 - accuracy: 0.3873 - val_loss: 1.2908 - val_accuracy: 0.4963\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3861 - accuracy: 0.3669 - val_loss: 1.2883 - val_accuracy: 0.5037\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3873 - accuracy: 0.3613 - val_loss: 1.2820 - val_accuracy: 0.5556\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3385 - accuracy: 0.4190 - val_loss: 1.2656 - val_accuracy: 0.4889\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.4021 - accuracy: 0.3836 - val_loss: 1.2673 - val_accuracy: 0.5259\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3524 - accuracy: 0.3892 - val_loss: 1.2823 - val_accuracy: 0.4444\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.3791 - accuracy: 0.3762 - val_loss: 1.2701 - val_accuracy: 0.4889\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3404 - accuracy: 0.3743 - val_loss: 1.2575 - val_accuracy: 0.5333\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3232 - accuracy: 0.4153 - val_loss: 1.2542 - val_accuracy: 0.4667\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3947 - accuracy: 0.3538 - val_loss: 1.2529 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "umhistory=um.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using CNN - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUtQ8Bwjhcmw",
    "outputId": "e2fb5814-290f-47fe-b4e3-7dbaec5c432d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2529 - accuracy: 0.4000\n",
      "Restored model, accuracy: 40.00%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = um.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Abdy_mt4nABa"
   },
   "source": [
    "# CNN - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V43ptFvXm-bj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "sm = Sequential()\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "sm.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #2\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(MaxPooling1D(pool_size=(8)))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #3\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #4\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Flatten())\n",
    "sm.add(Dense(8))                                        #5                     \n",
    "sm.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00005,epsilon=None,rho=0.9,decay=0.0)\n",
    "\n",
    "sm.summary()\n",
    "sm.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K51eTwPjnIGJ",
    "outputId": "82569664-abb9-4322-8290-f724a128949b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 4s 42ms/step - loss: 2.8234 - accuracy: 0.2477 - val_loss: 1.3379 - val_accuracy: 0.3407\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 2.3042 - accuracy: 0.2495 - val_loss: 1.3322 - val_accuracy: 0.3407\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 2.0668 - accuracy: 0.2980 - val_loss: 1.2598 - val_accuracy: 0.4667\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1.8761 - accuracy: 0.3035 - val_loss: 1.2342 - val_accuracy: 0.4667\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.7390 - accuracy: 0.3389 - val_loss: 1.3179 - val_accuracy: 0.3704\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.6653 - accuracy: 0.3240 - val_loss: 1.2329 - val_accuracy: 0.4000\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.5765 - accuracy: 0.3203 - val_loss: 1.2644 - val_accuracy: 0.3926\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.5909 - accuracy: 0.3259 - val_loss: 1.2508 - val_accuracy: 0.3704\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.5948 - accuracy: 0.3277 - val_loss: 1.2085 - val_accuracy: 0.4741\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.4268 - accuracy: 0.3743 - val_loss: 1.2149 - val_accuracy: 0.4444\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.4384 - accuracy: 0.3538 - val_loss: 1.2111 - val_accuracy: 0.4741\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.4436 - accuracy: 0.3501 - val_loss: 1.2403 - val_accuracy: 0.3704\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.3963 - accuracy: 0.3501 - val_loss: 1.2204 - val_accuracy: 0.4000\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.3637 - accuracy: 0.3855 - val_loss: 1.1771 - val_accuracy: 0.5407\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.3338 - accuracy: 0.3966 - val_loss: 1.1838 - val_accuracy: 0.5259\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.3812 - accuracy: 0.3650 - val_loss: 1.2237 - val_accuracy: 0.4074\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.3580 - accuracy: 0.3836 - val_loss: 1.2507 - val_accuracy: 0.3704\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.3461 - accuracy: 0.3557 - val_loss: 1.2000 - val_accuracy: 0.4148\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.3144 - accuracy: 0.3836 - val_loss: 1.1866 - val_accuracy: 0.5259\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.3215 - accuracy: 0.3855 - val_loss: 1.1815 - val_accuracy: 0.4148\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.3043 - accuracy: 0.3911 - val_loss: 1.1753 - val_accuracy: 0.5185\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.2751 - accuracy: 0.4134 - val_loss: 1.1751 - val_accuracy: 0.5111\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2899 - accuracy: 0.3985 - val_loss: 1.1599 - val_accuracy: 0.5333\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2749 - accuracy: 0.3966 - val_loss: 1.1766 - val_accuracy: 0.4593\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2959 - accuracy: 0.4060 - val_loss: 1.1674 - val_accuracy: 0.3926\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.2868 - accuracy: 0.3836 - val_loss: 1.1575 - val_accuracy: 0.5037\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.2833 - accuracy: 0.3966 - val_loss: 1.1608 - val_accuracy: 0.4222\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2926 - accuracy: 0.3929 - val_loss: 1.1404 - val_accuracy: 0.4963\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2658 - accuracy: 0.3948 - val_loss: 1.1620 - val_accuracy: 0.3926\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.2639 - accuracy: 0.3985 - val_loss: 1.1346 - val_accuracy: 0.4667\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.2720 - accuracy: 0.4097 - val_loss: 1.1274 - val_accuracy: 0.4963\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2355 - accuracy: 0.4395 - val_loss: 1.1483 - val_accuracy: 0.4222\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2798 - accuracy: 0.3818 - val_loss: 1.1189 - val_accuracy: 0.4963\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2304 - accuracy: 0.4264 - val_loss: 1.1285 - val_accuracy: 0.4000\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2474 - accuracy: 0.4022 - val_loss: 1.1273 - val_accuracy: 0.4074\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2251 - accuracy: 0.4246 - val_loss: 1.0998 - val_accuracy: 0.4741\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2182 - accuracy: 0.4413 - val_loss: 1.0908 - val_accuracy: 0.5111\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2029 - accuracy: 0.4376 - val_loss: 1.1066 - val_accuracy: 0.4222\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.1924 - accuracy: 0.4302 - val_loss: 1.0992 - val_accuracy: 0.4222\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2126 - accuracy: 0.4507 - val_loss: 1.0637 - val_accuracy: 0.5111\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.2166 - accuracy: 0.4432 - val_loss: 1.0867 - val_accuracy: 0.4444\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.1866 - accuracy: 0.4674 - val_loss: 1.1097 - val_accuracy: 0.3852\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2219 - accuracy: 0.4246 - val_loss: 1.0807 - val_accuracy: 0.4593\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2026 - accuracy: 0.4395 - val_loss: 1.0643 - val_accuracy: 0.5037\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.2108 - accuracy: 0.4395 - val_loss: 1.0632 - val_accuracy: 0.4889\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.1793 - accuracy: 0.4544 - val_loss: 1.0584 - val_accuracy: 0.4963\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.1767 - accuracy: 0.4618 - val_loss: 1.0431 - val_accuracy: 0.4741\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2179 - accuracy: 0.4227 - val_loss: 1.0216 - val_accuracy: 0.5630\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.1744 - accuracy: 0.4544 - val_loss: 1.0437 - val_accuracy: 0.4963\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.1904 - accuracy: 0.4488 - val_loss: 1.0411 - val_accuracy: 0.4963\n"
     ]
    }
   ],
   "source": [
    "smhistory=sm.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using CNN - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LBS8v4sWnIjJ",
    "outputId": "34487bd9-7587-4805-a2e6-9f19e8e9e419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0411 - accuracy: 0.4963\n",
      "Restored model, accuracy: 49.63%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = sm.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 180, 64)           16896     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,440\n",
      "Trainable params: 50,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_LSTM=Sequential()\n",
    "model_LSTM.add(layers.LSTM(64,return_sequences=True,input_shape=(180,1)))\n",
    "model_LSTM.add(layers.LSTM(64))\n",
    "model_LSTM.add(layers.Dense(8,activation='softmax'))\n",
    "print(model_LSTM.summary())\n",
    "model_LSTM.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 16s 231ms/step - loss: 2.0726 - accuracy: 0.2831 - val_loss: 2.0654 - val_accuracy: 0.3926\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 4s 148ms/step - loss: 2.0578 - accuracy: 0.2775 - val_loss: 2.0456 - val_accuracy: 0.3407\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 2.0323 - accuracy: 0.2719 - val_loss: 2.0089 - val_accuracy: 0.3407\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 5s 182ms/step - loss: 1.9793 - accuracy: 0.2719 - val_loss: 1.9201 - val_accuracy: 0.3407\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.8334 - accuracy: 0.2719 - val_loss: 1.6650 - val_accuracy: 0.3407\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.5968 - accuracy: 0.2719 - val_loss: 1.4954 - val_accuracy: 0.3407\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.4916 - accuracy: 0.2831 - val_loss: 1.4298 - val_accuracy: 0.2296\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 5s 178ms/step - loss: 1.4310 - accuracy: 0.2998 - val_loss: 1.3868 - val_accuracy: 0.2296\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.4052 - accuracy: 0.3017 - val_loss: 1.3692 - val_accuracy: 0.2296\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.3876 - accuracy: 0.3520 - val_loss: 1.3537 - val_accuracy: 0.3481\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.3721 - accuracy: 0.3296 - val_loss: 1.3381 - val_accuracy: 0.3630\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 1.3559 - accuracy: 0.3706 - val_loss: 1.3251 - val_accuracy: 0.4296\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 1.3440 - accuracy: 0.4209 - val_loss: 1.3042 - val_accuracy: 0.5037\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.3310 - accuracy: 0.4171 - val_loss: 1.2926 - val_accuracy: 0.5185\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 1.3178 - accuracy: 0.4246 - val_loss: 1.2762 - val_accuracy: 0.5111\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.3046 - accuracy: 0.4283 - val_loss: 1.2594 - val_accuracy: 0.5259\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 1.2933 - accuracy: 0.4115 - val_loss: 1.2440 - val_accuracy: 0.5259\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.2831 - accuracy: 0.4190 - val_loss: 1.2305 - val_accuracy: 0.5111\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 1.2709 - accuracy: 0.4246 - val_loss: 1.2203 - val_accuracy: 0.5333\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 5s 180ms/step - loss: 1.2610 - accuracy: 0.4209 - val_loss: 1.2080 - val_accuracy: 0.5111\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.2548 - accuracy: 0.4209 - val_loss: 1.1998 - val_accuracy: 0.5111\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.2471 - accuracy: 0.4134 - val_loss: 1.1889 - val_accuracy: 0.5037\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.2392 - accuracy: 0.4358 - val_loss: 1.1799 - val_accuracy: 0.4963\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.2322 - accuracy: 0.4153 - val_loss: 1.1872 - val_accuracy: 0.4889\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.2257 - accuracy: 0.4134 - val_loss: 1.1647 - val_accuracy: 0.5185\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.2193 - accuracy: 0.4432 - val_loss: 1.1859 - val_accuracy: 0.4815\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.2139 - accuracy: 0.4507 - val_loss: 1.1503 - val_accuracy: 0.4963\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.2114 - accuracy: 0.4339 - val_loss: 1.1425 - val_accuracy: 0.5185\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.2081 - accuracy: 0.4525 - val_loss: 1.1599 - val_accuracy: 0.4815\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.2015 - accuracy: 0.4413 - val_loss: 1.1441 - val_accuracy: 0.5185\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.1962 - accuracy: 0.4600 - val_loss: 1.1392 - val_accuracy: 0.5259\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.1920 - accuracy: 0.4618 - val_loss: 1.1247 - val_accuracy: 0.5481\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.1910 - accuracy: 0.4507 - val_loss: 1.1223 - val_accuracy: 0.5481\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.1894 - accuracy: 0.4562 - val_loss: 1.1165 - val_accuracy: 0.5481\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1804 - accuracy: 0.4655 - val_loss: 1.1149 - val_accuracy: 0.5407\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 1.1793 - accuracy: 0.4693 - val_loss: 1.1202 - val_accuracy: 0.5407\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.1754 - accuracy: 0.4730 - val_loss: 1.1050 - val_accuracy: 0.5333\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 5s 178ms/step - loss: 1.1730 - accuracy: 0.4674 - val_loss: 1.1165 - val_accuracy: 0.5333\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.1719 - accuracy: 0.4655 - val_loss: 1.1038 - val_accuracy: 0.5481\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1709 - accuracy: 0.4507 - val_loss: 1.0943 - val_accuracy: 0.5407\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 1.1695 - accuracy: 0.4655 - val_loss: 1.0906 - val_accuracy: 0.5481\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 1.1640 - accuracy: 0.4730 - val_loss: 1.0890 - val_accuracy: 0.5259\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1566 - accuracy: 0.4693 - val_loss: 1.0955 - val_accuracy: 0.5407\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1564 - accuracy: 0.4637 - val_loss: 1.0987 - val_accuracy: 0.5259\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1597 - accuracy: 0.4711 - val_loss: 1.0848 - val_accuracy: 0.5481\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.1527 - accuracy: 0.4860 - val_loss: 1.0757 - val_accuracy: 0.5333\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.1572 - accuracy: 0.4655 - val_loss: 1.0741 - val_accuracy: 0.5333\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.1519 - accuracy: 0.4823 - val_loss: 1.0709 - val_accuracy: 0.5407\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.1497 - accuracy: 0.4767 - val_loss: 1.0778 - val_accuracy: 0.5333\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1522 - accuracy: 0.4674 - val_loss: 1.0671 - val_accuracy: 0.5185\n"
     ]
    }
   ],
   "source": [
    "umhistory=model_LSTM.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 61ms/step - loss: 1.0671 - accuracy: 0.5185\n",
      "Restored model, accuracy: 51.85%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_LSTM.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9148), started 0:46:39 ago. (Use '!kill 9148' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9dd510e9ee60b8a1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9dd510e9ee60b8a1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOQfsKtSS2nu7fsGE+IWtmN",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CNN_SpeechEmotion.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
