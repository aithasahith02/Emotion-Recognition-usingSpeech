{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rSku0_cX3dB"
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# all emotions on RAVDESS dataset\n",
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# we allow only these emotions\n",
    "AVAILABLE_EMOTIONS = {\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"neutral\",\n",
    "    \"happy\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWJ9phRhUDrM"
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NI3q89z5YLVq"
   },
   "outputs": [],
   "source": [
    "def load_data(train_size=0.8,test_size=0.2):\n",
    "    X, y = [], []\n",
    "    try :\n",
    "        for file in glob.glob(\"C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset/Actor_*/*.wav\"):\n",
    "            # get the base name of the audio file\n",
    "            print(file)\n",
    "            basename = os.path.basename(file)\n",
    "            print(basename)\n",
    "          # get the emotion label\n",
    "            emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "          # we allow only AVAILABLE_EMOTIONS we set\n",
    "            if emotion not in AVAILABLE_EMOTIONS:\n",
    "                continue\n",
    "          # extract speech features\n",
    "            features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "          # add to data\n",
    "            X.append(features)\n",
    "            l={'happy':0.0,'sad':1.0,'neutral':3.0,'angry':4.0}\n",
    "            y.append(l[emotion])\n",
    "    except :\n",
    "         pass\n",
    "    # split the data to training and testing and return it\n",
    "    return train_test_split(np.array(X), y, test_size=test_size,train_size=train_size,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "p7USodbIYQli",
    "outputId": "7fd11920-7a3e-405e-a828-3f7d50aa97ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-01-01-01.wav\n",
      "03-01-01-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-01-02-01.wav\n",
      "03-01-01-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-02-01-01.wav\n",
      "03-01-01-01-02-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-01-01-02-02-01.wav\n",
      "03-01-01-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-01-01-01.wav\n",
      "03-01-02-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-01-02-01.wav\n",
      "03-01-02-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-02-01-01.wav\n",
      "03-01-02-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-01-02-02-01.wav\n",
      "03-01-02-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-01-01-01.wav\n",
      "03-01-02-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-01-02-01.wav\n",
      "03-01-02-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-02-01-01.wav\n",
      "03-01-02-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-02-02-02-02-01.wav\n",
      "03-01-02-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-01-01-01.wav\n",
      "03-01-03-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-01-02-01.wav\n",
      "03-01-03-01-01-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-02-01-01.wav\n",
      "03-01-03-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-01-02-02-01.wav\n",
      "03-01-03-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-01-01-01.wav\n",
      "03-01-03-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-01-02-01.wav\n",
      "03-01-03-02-01-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-02-01-01.wav\n",
      "03-01-03-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-03-02-02-02-01.wav\n",
      "03-01-03-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-01-01-01.wav\n",
      "03-01-04-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-01-02-01.wav\n",
      "03-01-04-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-02-01-01.wav\n",
      "03-01-04-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-01-02-02-01.wav\n",
      "03-01-04-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-01-01-01.wav\n",
      "03-01-04-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-01-02-01.wav\n",
      "03-01-04-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-02-01-01.wav\n",
      "03-01-04-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-04-02-02-02-01.wav\n",
      "03-01-04-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-01-01-01.wav\n",
      "03-01-05-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-01-02-01.wav\n",
      "03-01-05-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-02-01-01.wav\n",
      "03-01-05-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-01-02-02-01.wav\n",
      "03-01-05-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-01-01-01.wav\n",
      "03-01-05-02-01-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.00061035 -0.00048828 -0.00039673 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.00231934  0.00213623 -0.00231934 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-01-02-01.wav\n",
      "03-01-05-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-02-01-01.wav\n",
      "03-01-05-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-05-02-02-02-01.wav\n",
      "03-01-05-02-02-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 7.3242188e-04  1.0986328e-03 -6.7138672e-04 ...  9.1552734e-05\n",
      "  3.6621094e-04  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.00033569 0.00024414 0.00024414 ... 0.00036621 0.00033569 0.00045776] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-01-01-01.wav\n",
      "03-01-06-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-01-02-01.wav\n",
      "03-01-06-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-02-01-01.wav\n",
      "03-01-06-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-01-02-02-01.wav\n",
      "03-01-06-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-01-01-01.wav\n",
      "03-01-06-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-01-02-01.wav\n",
      "03-01-06-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-02-01-01.wav\n",
      "03-01-06-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-06-02-02-02-01.wav\n",
      "03-01-06-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-01-01-01.wav\n",
      "03-01-07-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-01-02-01.wav\n",
      "03-01-07-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-02-01-01.wav\n",
      "03-01-07-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-01-02-02-01.wav\n",
      "03-01-07-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-01-01-01.wav\n",
      "03-01-07-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-01-02-01.wav\n",
      "03-01-07-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-02-01-01.wav\n",
      "03-01-07-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-07-02-02-02-01.wav\n",
      "03-01-07-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-01-01-01.wav\n",
      "03-01-08-01-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-01-02-01.wav\n",
      "03-01-08-01-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-02-01-01.wav\n",
      "03-01-08-01-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-01-02-02-01.wav\n",
      "03-01-08-01-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-01-01-01.wav\n",
      "03-01-08-02-01-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-01-02-01.wav\n",
      "03-01-08-02-01-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-02-01-01.wav\n",
      "03-01-08-02-02-01-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_01\\03-01-08-02-02-02-01.wav\n",
      "03-01-08-02-02-02-01.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-01-01-02.wav\n",
      "03-01-01-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-01-02-02.wav\n",
      "03-01-01-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-02-01-02.wav\n",
      "03-01-01-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-01-01-02-02-02.wav\n",
      "03-01-01-01-02-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-01-01-02.wav\n",
      "03-01-02-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-01-02-02.wav\n",
      "03-01-02-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-02-01-02.wav\n",
      "03-01-02-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-01-02-02-02.wav\n",
      "03-01-02-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-01-01-02.wav\n",
      "03-01-02-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-01-02-02.wav\n",
      "03-01-02-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-02-01-02.wav\n",
      "03-01-02-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-02-02-02-02-02.wav\n",
      "03-01-02-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-01-01-02.wav\n",
      "03-01-03-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-01-02-02.wav\n",
      "03-01-03-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-02-01-02.wav\n",
      "03-01-03-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-01-02-02-02.wav\n",
      "03-01-03-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-01-01-02.wav\n",
      "03-01-03-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-01-02-02.wav\n",
      "03-01-03-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-02-01-02.wav\n",
      "03-01-03-02-02-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-03-02-02-02-02.wav\n",
      "03-01-03-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-01-01-02.wav\n",
      "03-01-04-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-01-02-02.wav\n",
      "03-01-04-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-02-01-02.wav\n",
      "03-01-04-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-01-02-02-02.wav\n",
      "03-01-04-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-01-01-02.wav\n",
      "03-01-04-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-01-02-02.wav\n",
      "03-01-04-02-01-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-02-01-02.wav\n",
      "03-01-04-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-04-02-02-02-02.wav\n",
      "03-01-04-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-01-01-02.wav\n",
      "03-01-05-01-01-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-01-02-02.wav\n",
      "03-01-05-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-02-01-02.wav\n",
      "03-01-05-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-01-02-02-02.wav\n",
      "03-01-05-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-01-01-02.wav\n",
      "03-01-05-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-01-02-02.wav\n",
      "03-01-05-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-02-01-02.wav\n",
      "03-01-05-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-05-02-02-02-02.wav\n",
      "03-01-05-02-02-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-01-01-02.wav\n",
      "03-01-06-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-01-02-02.wav\n",
      "03-01-06-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-02-01-02.wav\n",
      "03-01-06-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-01-02-02-02.wav\n",
      "03-01-06-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-01-01-02.wav\n",
      "03-01-06-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-01-02-02.wav\n",
      "03-01-06-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-02-01-02.wav\n",
      "03-01-06-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-06-02-02-02-02.wav\n",
      "03-01-06-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-01-01-02.wav\n",
      "03-01-07-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-01-02-02.wav\n",
      "03-01-07-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-02-01-02.wav\n",
      "03-01-07-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-01-02-02-02.wav\n",
      "03-01-07-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-01-01-02.wav\n",
      "03-01-07-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-01-02-02.wav\n",
      "03-01-07-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-02-01-02.wav\n",
      "03-01-07-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-07-02-02-02-02.wav\n",
      "03-01-07-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-01-01-02.wav\n",
      "03-01-08-01-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-01-02-02.wav\n",
      "03-01-08-01-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-02-01-02.wav\n",
      "03-01-08-01-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-01-02-02-02.wav\n",
      "03-01-08-01-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-01-01-02.wav\n",
      "03-01-08-02-01-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-01-02-02.wav\n",
      "03-01-08-02-01-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-02-01-02.wav\n",
      "03-01-08-02-02-01-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_02\\03-01-08-02-02-02-02.wav\n",
      "03-01-08-02-02-02-02.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-01-01-03.wav\n",
      "03-01-01-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-01-02-03.wav\n",
      "03-01-01-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-02-01-03.wav\n",
      "03-01-01-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-01-01-02-02-03.wav\n",
      "03-01-01-01-02-02-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  6.1035156e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[6.1035156e-05 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-01-01-03.wav\n",
      "03-01-02-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-01-02-03.wav\n",
      "03-01-02-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-02-01-03.wav\n",
      "03-01-02-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-01-02-02-03.wav\n",
      "03-01-02-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-01-01-03.wav\n",
      "03-01-02-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-01-02-03.wav\n",
      "03-01-02-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-02-01-03.wav\n",
      "03-01-02-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-02-02-02-02-03.wav\n",
      "03-01-02-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-01-01-03.wav\n",
      "03-01-03-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-01-02-03.wav\n",
      "03-01-03-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-02-01-03.wav\n",
      "03-01-03-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-01-02-02-03.wav\n",
      "03-01-03-01-02-02-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  9.1552734e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 5.1879883e-04 -6.1035156e-05 -4.2724609e-04 ...  0.0000000e+00\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-01-01-03.wav\n",
      "03-01-03-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-01-02-03.wav\n",
      "03-01-03-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-02-01-03.wav\n",
      "03-01-03-02-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 1.2207031e-04  1.5258789e-04 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.00027466 -0.00024414 -0.00027466 ... -0.00015259 -0.00021362\n",
      " -0.00024414] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-04 -1.0986328e-03 ...  2.7465820e-04\n",
      "  3.0517578e-04  3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-03-02-02-02-03.wav\n",
      "03-01-03-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-01-01-03.wav\n",
      "03-01-04-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-01-02-03.wav\n",
      "03-01-04-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-02-01-03.wav\n",
      "03-01-04-01-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -1.5258789e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 6.1035156e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00042725 -0.00039673\n",
      " -0.00033569] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  2.7465820e-04\n",
      "  3.0517578e-04  2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-01-02-02-03.wav\n",
      "03-01-04-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-01-01-03.wav\n",
      "03-01-04-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-01-02-03.wav\n",
      "03-01-04-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-02-01-03.wav\n",
      "03-01-04-02-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.7138672e-04 -7.0190430e-04 -6.1035156e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  3.0517578e-05 ... -3.6926270e-03\n",
      " -7.4768066e-03 -8.6975098e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.         0.         0.         ... 0.00247192 0.00247192 0.00244141] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.2207031e-04 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  9.1552734e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-04-02-02-02-03.wav\n",
      "03-01-04-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-01-01-03.wav\n",
      "03-01-05-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-01-02-03.wav\n",
      "03-01-05-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-02-01-03.wav\n",
      "03-01-05-01-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -1.8310547e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  3.0517578e-05 ... -5.8593750e-03\n",
      " -5.8898926e-03 -6.0729980e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.8310547e-04  1.2207031e-04  3.0517578e-04 ... -1.8310547e-04\n",
      " -6.1035156e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.4086914e-04  2.7465820e-04 -6.1035156e-05 ... -1.7089844e-03\n",
      " -1.8615723e-03 -1.8005371e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-01-02-02-03.wav\n",
      "03-01-05-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-01-01-03.wav\n",
      "03-01-05-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-01-02-03.wav\n",
      "03-01-05-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-02-01-03.wav\n",
      "03-01-05-02-02-01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[9.1552734e-05 2.1362305e-04 3.3569336e-04 ... 0.0000000e+00 3.0517578e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 9.4604492e-04 7.0190430e-04\n",
      " 8.8500977e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-05-02-02-02-03.wav\n",
      "03-01-05-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-01-01-03.wav\n",
      "03-01-06-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-01-02-03.wav\n",
      "03-01-06-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-02-01-03.wav\n",
      "03-01-06-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-01-02-02-03.wav\n",
      "03-01-06-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-01-01-03.wav\n",
      "03-01-06-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-01-02-03.wav\n",
      "03-01-06-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-02-01-03.wav\n",
      "03-01-06-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-06-02-02-02-03.wav\n",
      "03-01-06-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-01-01-03.wav\n",
      "03-01-07-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-01-02-03.wav\n",
      "03-01-07-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-02-01-03.wav\n",
      "03-01-07-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-01-02-02-03.wav\n",
      "03-01-07-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-01-01-03.wav\n",
      "03-01-07-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-01-02-03.wav\n",
      "03-01-07-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-02-01-03.wav\n",
      "03-01-07-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-07-02-02-02-03.wav\n",
      "03-01-07-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-01-01-03.wav\n",
      "03-01-08-01-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-01-02-03.wav\n",
      "03-01-08-01-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-02-01-03.wav\n",
      "03-01-08-01-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-01-02-02-03.wav\n",
      "03-01-08-01-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-01-01-03.wav\n",
      "03-01-08-02-01-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-01-02-03.wav\n",
      "03-01-08-02-01-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-02-01-03.wav\n",
      "03-01-08-02-02-01-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_03\\03-01-08-02-02-02-03.wav\n",
      "03-01-08-02-02-02-03.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-01-01-04.wav\n",
      "03-01-01-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-01-02-04.wav\n",
      "03-01-01-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-02-01-04.wav\n",
      "03-01-01-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-01-01-02-02-04.wav\n",
      "03-01-01-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-01-01-04.wav\n",
      "03-01-02-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-01-02-04.wav\n",
      "03-01-02-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-02-01-04.wav\n",
      "03-01-02-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-01-02-02-04.wav\n",
      "03-01-02-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-01-01-04.wav\n",
      "03-01-02-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-01-02-04.wav\n",
      "03-01-02-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-02-01-04.wav\n",
      "03-01-02-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-02-02-02-02-04.wav\n",
      "03-01-02-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-01-01-04.wav\n",
      "03-01-03-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-01-02-04.wav\n",
      "03-01-03-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-02-01-04.wav\n",
      "03-01-03-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-01-02-02-04.wav\n",
      "03-01-03-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-01-01-04.wav\n",
      "03-01-03-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-01-02-04.wav\n",
      "03-01-03-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-02-01-04.wav\n",
      "03-01-03-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-03-02-02-02-04.wav\n",
      "03-01-03-02-02-02-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-01-01-04.wav\n",
      "03-01-04-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-01-02-04.wav\n",
      "03-01-04-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-02-01-04.wav\n",
      "03-01-04-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-01-02-02-04.wav\n",
      "03-01-04-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-01-01-04.wav\n",
      "03-01-04-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-01-02-04.wav\n",
      "03-01-04-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-02-01-04.wav\n",
      "03-01-04-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-04-02-02-02-04.wav\n",
      "03-01-04-02-02-02-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.2207031e-04 -9.1552734e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 9.1552734e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-01-01-04.wav\n",
      "03-01-05-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-01-02-04.wav\n",
      "03-01-05-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-02-01-04.wav\n",
      "03-01-05-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-01-02-02-04.wav\n",
      "03-01-05-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-01-01-04.wav\n",
      "03-01-05-02-01-01-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-01-02-04.wav\n",
      "03-01-05-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-02-01-04.wav\n",
      "03-01-05-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-05-02-02-02-04.wav\n",
      "03-01-05-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-01-01-04.wav\n",
      "03-01-06-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-01-02-04.wav\n",
      "03-01-06-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-02-01-04.wav\n",
      "03-01-06-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-01-02-02-04.wav\n",
      "03-01-06-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-01-01-04.wav\n",
      "03-01-06-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-01-02-04.wav\n",
      "03-01-06-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-02-01-04.wav\n",
      "03-01-06-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-06-02-02-02-04.wav\n",
      "03-01-06-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-01-01-04.wav\n",
      "03-01-07-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-01-02-04.wav\n",
      "03-01-07-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-02-01-04.wav\n",
      "03-01-07-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-01-02-02-04.wav\n",
      "03-01-07-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-01-01-04.wav\n",
      "03-01-07-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-01-02-04.wav\n",
      "03-01-07-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-02-01-04.wav\n",
      "03-01-07-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-07-02-02-02-04.wav\n",
      "03-01-07-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-01-01-04.wav\n",
      "03-01-08-01-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-01-02-04.wav\n",
      "03-01-08-01-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-02-01-04.wav\n",
      "03-01-08-01-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-01-02-02-04.wav\n",
      "03-01-08-01-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-01-01-04.wav\n",
      "03-01-08-02-01-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-01-02-04.wav\n",
      "03-01-08-02-01-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-02-01-04.wav\n",
      "03-01-08-02-02-01-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_04\\03-01-08-02-02-02-04.wav\n",
      "03-01-08-02-02-02-04.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-01-01-05.wav\n",
      "03-01-01-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-01-02-05.wav\n",
      "03-01-01-01-01-02-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -9.1552734e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05  6.1035156e-05 ... -9.1552734e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-02-01-05.wav\n",
      "03-01-01-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-01-01-02-02-05.wav\n",
      "03-01-01-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-01-01-05.wav\n",
      "03-01-02-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-01-02-05.wav\n",
      "03-01-02-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-02-01-05.wav\n",
      "03-01-02-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-01-02-02-05.wav\n",
      "03-01-02-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-01-01-05.wav\n",
      "03-01-02-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-01-02-05.wav\n",
      "03-01-02-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-02-01-05.wav\n",
      "03-01-02-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-02-02-02-02-05.wav\n",
      "03-01-02-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-01-01-05.wav\n",
      "03-01-03-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-01-02-05.wav\n",
      "03-01-03-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-02-01-05.wav\n",
      "03-01-03-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-01-02-02-05.wav\n",
      "03-01-03-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-01-01-05.wav\n",
      "03-01-03-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-01-02-05.wav\n",
      "03-01-03-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-02-01-05.wav\n",
      "03-01-03-02-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 6.1035156e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.5258789e-04 -1.5258789e-04 -1.5258789e-04 ...  0.0000000e+00\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  6.1035156e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-03-02-02-02-05.wav\n",
      "03-01-03-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-01-01-05.wav\n",
      "03-01-04-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-01-02-05.wav\n",
      "03-01-04-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-02-01-05.wav\n",
      "03-01-04-01-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 3.0517578e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[9.1552734e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-01-02-02-05.wav\n",
      "03-01-04-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-01-01-05.wav\n",
      "03-01-04-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-01-02-05.wav\n",
      "03-01-04-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-02-01-05.wav\n",
      "03-01-04-02-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.00054932 0.00057983 0.00057983 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-04-02-02-02-05.wav\n",
      "03-01-04-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-01-01-05.wav\n",
      "03-01-05-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-01-02-05.wav\n",
      "03-01-05-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-02-01-05.wav\n",
      "03-01-05-01-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-01-02-02-05.wav\n",
      "03-01-05-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-01-01-05.wav\n",
      "03-01-05-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-01-02-05.wav\n",
      "03-01-05-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-02-01-05.wav\n",
      "03-01-05-02-02-01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -9.1552734e-05 ...  4.2724609e-04\n",
      "  4.2724609e-04  4.2724609e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-05-02-02-02-05.wav\n",
      "03-01-05-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-01-01-05.wav\n",
      "03-01-06-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-01-02-05.wav\n",
      "03-01-06-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-02-01-05.wav\n",
      "03-01-06-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-01-02-02-05.wav\n",
      "03-01-06-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-01-01-05.wav\n",
      "03-01-06-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-01-02-05.wav\n",
      "03-01-06-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-02-01-05.wav\n",
      "03-01-06-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-06-02-02-02-05.wav\n",
      "03-01-06-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-01-01-05.wav\n",
      "03-01-07-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-01-02-05.wav\n",
      "03-01-07-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-02-01-05.wav\n",
      "03-01-07-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-01-02-02-05.wav\n",
      "03-01-07-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-01-01-05.wav\n",
      "03-01-07-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-01-02-05.wav\n",
      "03-01-07-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-02-01-05.wav\n",
      "03-01-07-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-07-02-02-02-05.wav\n",
      "03-01-07-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-01-01-05.wav\n",
      "03-01-08-01-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-01-02-05.wav\n",
      "03-01-08-01-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-02-01-05.wav\n",
      "03-01-08-01-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-01-02-02-05.wav\n",
      "03-01-08-01-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-01-01-05.wav\n",
      "03-01-08-02-01-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-01-02-05.wav\n",
      "03-01-08-02-01-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-02-01-05.wav\n",
      "03-01-08-02-02-01-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_05\\03-01-08-02-02-02-05.wav\n",
      "03-01-08-02-02-02-05.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-01-01-06.wav\n",
      "03-01-01-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-01-02-06.wav\n",
      "03-01-01-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-02-01-06.wav\n",
      "03-01-01-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-01-01-02-02-06.wav\n",
      "03-01-01-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-01-01-06.wav\n",
      "03-01-02-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-01-02-06.wav\n",
      "03-01-02-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-02-01-06.wav\n",
      "03-01-02-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-01-02-02-06.wav\n",
      "03-01-02-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-01-01-06.wav\n",
      "03-01-02-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-01-02-06.wav\n",
      "03-01-02-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-02-01-06.wav\n",
      "03-01-02-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-02-02-02-02-06.wav\n",
      "03-01-02-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-01-01-06.wav\n",
      "03-01-03-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-01-02-06.wav\n",
      "03-01-03-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-02-01-06.wav\n",
      "03-01-03-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-01-02-02-06.wav\n",
      "03-01-03-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-01-01-06.wav\n",
      "03-01-03-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-01-02-06.wav\n",
      "03-01-03-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-02-01-06.wav\n",
      "03-01-03-02-02-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  3.0517578e-05\n",
      " -3.0517578e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-03-02-02-02-06.wav\n",
      "03-01-03-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-01-01-06.wav\n",
      "03-01-04-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-01-02-06.wav\n",
      "03-01-04-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-02-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 6.1035156e-04 6.1035156e-04\n",
      " 5.7983398e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-04-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-01-02-02-06.wav\n",
      "03-01-04-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-01-01-06.wav\n",
      "03-01-04-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-01-02-06.wav\n",
      "03-01-04-02-01-02-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.00024414 0.00021362 0.00021362 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-02-01-06.wav\n",
      "03-01-04-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-04-02-02-02-06.wav\n",
      "03-01-04-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-01-01-06.wav\n",
      "03-01-05-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-01-02-06.wav\n",
      "03-01-05-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-02-01-06.wav\n",
      "03-01-05-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-01-02-02-06.wav\n",
      "03-01-05-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-01-01-06.wav\n",
      "03-01-05-02-01-01-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.         0.         0.         ... 0.00015259 0.00015259 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-01-02-06.wav\n",
      "03-01-05-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-02-01-06.wav\n",
      "03-01-05-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-05-02-02-02-06.wav\n",
      "03-01-05-02-02-02-06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 8.2397461e-04  5.1879883e-04  3.0517578e-04 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 9.1552734e-05 -3.0517578e-05 -4.8828125e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  9.1552734e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-01-01-06.wav\n",
      "03-01-06-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-01-02-06.wav\n",
      "03-01-06-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-02-01-06.wav\n",
      "03-01-06-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-01-02-02-06.wav\n",
      "03-01-06-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-01-01-06.wav\n",
      "03-01-06-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-01-02-06.wav\n",
      "03-01-06-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-02-01-06.wav\n",
      "03-01-06-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-06-02-02-02-06.wav\n",
      "03-01-06-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-01-01-06.wav\n",
      "03-01-07-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-01-02-06.wav\n",
      "03-01-07-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-02-01-06.wav\n",
      "03-01-07-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-01-02-02-06.wav\n",
      "03-01-07-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-01-01-06.wav\n",
      "03-01-07-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-01-02-06.wav\n",
      "03-01-07-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-02-01-06.wav\n",
      "03-01-07-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-07-02-02-02-06.wav\n",
      "03-01-07-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-01-01-06.wav\n",
      "03-01-08-01-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-01-02-06.wav\n",
      "03-01-08-01-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-02-01-06.wav\n",
      "03-01-08-01-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-01-02-02-06.wav\n",
      "03-01-08-01-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-01-01-06.wav\n",
      "03-01-08-02-01-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-01-02-06.wav\n",
      "03-01-08-02-01-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-02-01-06.wav\n",
      "03-01-08-02-02-01-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_06\\03-01-08-02-02-02-06.wav\n",
      "03-01-08-02-02-02-06.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-01-01-07.wav\n",
      "03-01-01-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-01-02-07.wav\n",
      "03-01-01-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-02-01-07.wav\n",
      "03-01-01-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-01-01-02-02-07.wav\n",
      "03-01-01-01-02-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-2.1362305e-04 -1.8310547e-04  6.1035156e-05 ... -1.5258789e-04\n",
      " -1.8310547e-04 -2.4414062e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -1.2207031e-04  3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-01-01-07.wav\n",
      "03-01-02-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-01-02-07.wav\n",
      "03-01-02-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-02-01-07.wav\n",
      "03-01-02-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-01-02-02-07.wav\n",
      "03-01-02-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-01-01-07.wav\n",
      "03-01-02-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-01-02-07.wav\n",
      "03-01-02-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-02-01-07.wav\n",
      "03-01-02-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-02-02-02-02-07.wav\n",
      "03-01-02-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-01-01-07.wav\n",
      "03-01-03-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-01-02-07.wav\n",
      "03-01-03-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-02-01-07.wav\n",
      "03-01-03-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-01-02-02-07.wav\n",
      "03-01-03-01-02-02-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05  0.0000000e+00  3.0517578e-05 ...  2.7465820e-04\n",
      "  2.4414062e-04  2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  6.1035156e-05\n",
      "  9.1552734e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 2.1362305e-04  7.9345703e-04 -1.2207031e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-01-01-07.wav\n",
      "03-01-03-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-01-02-07.wav\n",
      "03-01-03-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-02-01-07.wav\n",
      "03-01-03-02-02-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05 -6.1035156e-05 ... -3.3569336e-04\n",
      " -3.9672852e-04 -4.2724609e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  4.2724609e-04  6.4086914e-04 ...  1.2207031e-04\n",
      "  9.1552734e-05  1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-03-02-02-02-07.wav\n",
      "03-01-03-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-01-01-07.wav\n",
      "03-01-04-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-01-02-07.wav\n",
      "03-01-04-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-02-01-07.wav\n",
      "03-01-04-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-01-02-02-07.wav\n",
      "03-01-04-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-01-01-07.wav\n",
      "03-01-04-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-01-02-07.wav\n",
      "03-01-04-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-02-01-07.wav\n",
      "03-01-04-02-02-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05 -2.4414062e-04 -3.9672852e-04 ...  3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  3.0517578e-05 ...  1.0681152e-03\n",
      "  1.0681152e-03  1.0681152e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.00042725  0.00033569  0.00033569 ... -0.00402832 -0.00390625\n",
      " -0.00390625] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-04-02-02-02-07.wav\n",
      "03-01-04-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-01-01-07.wav\n",
      "03-01-05-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-01-02-07.wav\n",
      "03-01-05-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-02-01-07.wav\n",
      "03-01-05-01-02-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -8.2397461e-04\n",
      " -8.2397461e-04 -8.2397461e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.1035156e-05  9.1552734e-05  1.2207031e-04 ... -2.1057129e-03\n",
      " -2.1362305e-03 -2.1362305e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-01-02-02-07.wav\n",
      "03-01-05-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-01-01-07.wav\n",
      "03-01-05-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-01-02-07.wav\n",
      "03-01-05-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-02-01-07.wav\n",
      "03-01-05-02-02-01-07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.00064087 -0.00057983 -0.00054932 ...  0.00231934  0.00228882\n",
      "  0.00228882] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.00012207  0.00015259  0.00012207 ... -0.00204468 -0.00201416\n",
      " -0.00204468] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -1.8310547e-04 ...  3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -3.3569336e-04\n",
      " -3.3569336e-04 -3.3569336e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-05-02-02-02-07.wav\n",
      "03-01-05-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-01-01-07.wav\n",
      "03-01-06-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-01-02-07.wav\n",
      "03-01-06-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-02-01-07.wav\n",
      "03-01-06-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-01-02-02-07.wav\n",
      "03-01-06-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-01-01-07.wav\n",
      "03-01-06-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-01-02-07.wav\n",
      "03-01-06-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-02-01-07.wav\n",
      "03-01-06-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-06-02-02-02-07.wav\n",
      "03-01-06-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-01-01-07.wav\n",
      "03-01-07-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-01-02-07.wav\n",
      "03-01-07-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-02-01-07.wav\n",
      "03-01-07-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-01-02-02-07.wav\n",
      "03-01-07-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-01-01-07.wav\n",
      "03-01-07-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-01-02-07.wav\n",
      "03-01-07-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-02-01-07.wav\n",
      "03-01-07-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-07-02-02-02-07.wav\n",
      "03-01-07-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-01-01-07.wav\n",
      "03-01-08-01-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-01-02-07.wav\n",
      "03-01-08-01-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-02-01-07.wav\n",
      "03-01-08-01-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-01-02-02-07.wav\n",
      "03-01-08-01-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-01-01-07.wav\n",
      "03-01-08-02-01-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-01-02-07.wav\n",
      "03-01-08-02-01-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-02-01-07.wav\n",
      "03-01-08-02-02-01-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_07\\03-01-08-02-02-02-07.wav\n",
      "03-01-08-02-02-02-07.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-01-01-08.wav\n",
      "03-01-01-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-01-02-08.wav\n",
      "03-01-01-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-02-01-08.wav\n",
      "03-01-01-01-02-01-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.00015259 -0.00015259 -0.00015259 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[9.1552734e-05 9.1552734e-05 1.2207031e-04 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.00018311 0.00018311 0.00021362 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-01-01-02-02-08.wav\n",
      "03-01-01-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-01-01-08.wav\n",
      "03-01-02-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-01-02-08.wav\n",
      "03-01-02-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-02-01-08.wav\n",
      "03-01-02-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-01-02-02-08.wav\n",
      "03-01-02-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-01-01-08.wav\n",
      "03-01-02-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-01-02-08.wav\n",
      "03-01-02-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-02-01-08.wav\n",
      "03-01-02-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-02-02-02-02-08.wav\n",
      "03-01-02-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-01-01-08.wav\n",
      "03-01-03-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-01-02-08.wav\n",
      "03-01-03-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-02-01-08.wav\n",
      "03-01-03-01-02-01-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 6.1035156e-05 ... 9.1552734e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  3.0517578e-05 ... -1.5258789e-04\n",
      " -1.2207031e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-01-02-02-08.wav\n",
      "03-01-03-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-01-01-08.wav\n",
      "03-01-03-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-01-02-08.wav\n",
      "03-01-03-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-02-01-08.wav\n",
      "03-01-03-02-02-01-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05 -6.1035156e-05 -6.1035156e-05 ...  6.1035156e-05\n",
      "  3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -3.6621094e-04\n",
      " -3.6621094e-04 -3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05 -6.1035156e-05 ... -2.7465820e-04\n",
      " -2.1362305e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-03-02-02-02-08.wav\n",
      "03-01-03-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-01-01-08.wav\n",
      "03-01-04-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-01-02-08.wav\n",
      "03-01-04-01-01-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[2.4414062e-04 2.4414062e-04 2.4414062e-04 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.00012207 0.00015259 0.00015259 ... 0.00015259 0.00018311 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-02-01-08.wav\n",
      "03-01-04-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-01-02-02-08.wav\n",
      "03-01-04-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-01-01-08.wav\n",
      "03-01-04-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-01-02-08.wav\n",
      "03-01-04-02-01-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 1.8310547e-04  2.1362305e-04  2.1362305e-04 ... -1.2207031e-04\n",
      "  0.0000000e+00 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.         0.         0.         ... 0.00088501 0.00076294 0.00076294] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.         0.         0.         ... 0.00231934 0.00238037 0.00234985] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-02-01-08.wav\n",
      "03-01-04-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-04-02-02-02-08.wav\n",
      "03-01-04-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-01-01-08.wav\n",
      "03-01-05-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-01-02-08.wav\n",
      "03-01-05-01-01-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ... -8.5449219e-04\n",
      " -6.4086914e-04  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ... -2.4414062e-04\n",
      " -2.1667480e-03 -2.4414062e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  6.1035156e-05  1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.00018311 -0.00018311 -0.00018311 ...  0.00027466  0.00027466\n",
      "  0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-02-01-08.wav\n",
      "03-01-05-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-01-02-02-08.wav\n",
      "03-01-05-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-01-01-08.wav\n",
      "03-01-05-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-01-02-08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.00018311  0.00015259  0.00018311 ... -0.00021362 -0.00018311\n",
      " -0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.00012207 0.00012207 0.00012207 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[1.8310547e-04 1.8310547e-04 1.8310547e-04 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-05-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-02-01-08.wav\n",
      "03-01-05-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-05-02-02-02-08.wav\n",
      "03-01-05-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-01-01-08.wav\n",
      "03-01-06-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-01-02-08.wav\n",
      "03-01-06-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-02-01-08.wav\n",
      "03-01-06-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-01-02-02-08.wav\n",
      "03-01-06-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-01-01-08.wav\n",
      "03-01-06-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-01-02-08.wav\n",
      "03-01-06-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-02-01-08.wav\n",
      "03-01-06-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-06-02-02-02-08.wav\n",
      "03-01-06-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-01-01-08.wav\n",
      "03-01-07-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-01-02-08.wav\n",
      "03-01-07-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-02-01-08.wav\n",
      "03-01-07-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-01-02-02-08.wav\n",
      "03-01-07-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-01-01-08.wav\n",
      "03-01-07-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-01-02-08.wav\n",
      "03-01-07-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-02-01-08.wav\n",
      "03-01-07-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-07-02-02-02-08.wav\n",
      "03-01-07-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-01-01-08.wav\n",
      "03-01-08-01-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-01-02-08.wav\n",
      "03-01-08-01-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-02-01-08.wav\n",
      "03-01-08-01-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-01-02-02-08.wav\n",
      "03-01-08-01-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-01-01-08.wav\n",
      "03-01-08-02-01-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-01-02-08.wav\n",
      "03-01-08-02-01-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-02-01-08.wav\n",
      "03-01-08-02-02-01-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_08\\03-01-08-02-02-02-08.wav\n",
      "03-01-08-02-02-02-08.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-01-01-09.wav\n",
      "03-01-01-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-01-02-09.wav\n",
      "03-01-01-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-02-01-09.wav\n",
      "03-01-01-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-01-01-02-02-09.wav\n",
      "03-01-01-01-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 8.5449219e-04  8.5449219e-04  8.8500977e-04 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-01-01-09.wav\n",
      "03-01-02-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-01-02-09.wav\n",
      "03-01-02-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-02-01-09.wav\n",
      "03-01-02-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-01-02-02-09.wav\n",
      "03-01-02-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-01-01-09.wav\n",
      "03-01-02-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-01-02-09.wav\n",
      "03-01-02-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-02-01-09.wav\n",
      "03-01-02-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-02-02-02-02-09.wav\n",
      "03-01-02-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-01-01-09.wav\n",
      "03-01-03-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-01-02-09.wav\n",
      "03-01-03-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-02-01-09.wav\n",
      "03-01-03-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-01-02-02-09.wav\n",
      "03-01-03-01-02-02-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 9.1552734e-05  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-01-01-09.wav\n",
      "03-01-03-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-01-02-09.wav\n",
      "03-01-03-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-02-01-09.wav\n",
      "03-01-03-02-02-01-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0007019  0.00067139 0.00067139 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -1.2207031e-04\n",
      " -1.2207031e-04 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05  3.0517578e-05  3.0517578e-05 ...  6.1035156e-05\n",
      " -3.0517578e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-03-02-02-02-09.wav\n",
      "03-01-03-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-01-01-09.wav\n",
      "03-01-04-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-01-02-09.wav\n",
      "03-01-04-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-02-01-09.wav\n",
      "03-01-04-01-02-01-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-01-02-02-09.wav\n",
      "03-01-04-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-01-01-09.wav\n",
      "03-01-04-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-01-02-09.wav\n",
      "03-01-04-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-02-01-09.wav\n",
      "03-01-04-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-04-02-02-02-09.wav\n",
      "03-01-04-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-01-01-09.wav\n",
      "03-01-05-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-01-02-09.wav\n",
      "03-01-05-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-02-01-09.wav\n",
      "03-01-05-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-01-02-02-09.wav\n",
      "03-01-05-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-01-01-09.wav\n",
      "03-01-05-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-01-02-09.wav\n",
      "03-01-05-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-02-01-09.wav\n",
      "03-01-05-02-02-01-09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00012207 -0.00012207\n",
      " -0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  0.0000000e+00 ... -2.7465820e-04\n",
      " -3.0517578e-04 -2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -1.5258789e-04\n",
      " -1.2207031e-04 -2.1362305e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[9.1552734e-05 1.2207031e-04 1.8310547e-04 ... 1.5258789e-04 1.8310547e-04\n",
      " 1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.00027466  0.00048828  0.0005188  ... -0.00036621 -0.00042725\n",
      " -0.00033569] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[6.1035156e-05 3.0517578e-05 6.1035156e-05 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  2.7465820e-04 ...  6.1035156e-05\n",
      "  9.1552734e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-05-02-02-02-09.wav\n",
      "03-01-05-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-01-01-09.wav\n",
      "03-01-06-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-01-02-09.wav\n",
      "03-01-06-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-02-01-09.wav\n",
      "03-01-06-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-01-02-02-09.wav\n",
      "03-01-06-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-01-01-09.wav\n",
      "03-01-06-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-01-02-09.wav\n",
      "03-01-06-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-02-01-09.wav\n",
      "03-01-06-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-06-02-02-02-09.wav\n",
      "03-01-06-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-01-01-09.wav\n",
      "03-01-07-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-01-02-09.wav\n",
      "03-01-07-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-02-01-09.wav\n",
      "03-01-07-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-01-02-02-09.wav\n",
      "03-01-07-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-01-01-09.wav\n",
      "03-01-07-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-01-02-09.wav\n",
      "03-01-07-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-02-01-09.wav\n",
      "03-01-07-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-07-02-02-02-09.wav\n",
      "03-01-07-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-01-01-09.wav\n",
      "03-01-08-01-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-01-02-09.wav\n",
      "03-01-08-01-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-02-01-09.wav\n",
      "03-01-08-01-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-01-02-02-09.wav\n",
      "03-01-08-01-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-01-01-09.wav\n",
      "03-01-08-02-01-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-01-02-09.wav\n",
      "03-01-08-02-01-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-02-01-09.wav\n",
      "03-01-08-02-02-01-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_09\\03-01-08-02-02-02-09.wav\n",
      "03-01-08-02-02-02-09.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-01-01-10.wav\n",
      "03-01-01-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-01-02-10.wav\n",
      "03-01-01-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-02-01-10.wav\n",
      "03-01-01-01-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-01-01-02-02-10.wav\n",
      "03-01-01-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-01-01-10.wav\n",
      "03-01-02-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-01-02-10.wav\n",
      "03-01-02-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-02-01-10.wav\n",
      "03-01-02-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-01-02-02-10.wav\n",
      "03-01-02-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-01-01-10.wav\n",
      "03-01-02-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-01-02-10.wav\n",
      "03-01-02-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-02-01-10.wav\n",
      "03-01-02-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-02-02-02-02-10.wav\n",
      "03-01-02-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-01-01-10.wav\n",
      "03-01-03-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-01-02-10.wav\n",
      "03-01-03-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-02-01-10.wav\n",
      "03-01-03-01-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  3.0517578e-05 ...  0.0000000e+00\n",
      " -9.1552734e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  3.0517578e-05 ...  3.9672852e-04\n",
      "  4.5776367e-04 -2.7465820e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-2.7465820e-04  1.8310547e-04 -6.1035156e-05 ...  9.1552734e-05\n",
      "  1.2207031e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-01-02-02-10.wav\n",
      "03-01-03-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-01-01-10.wav\n",
      "03-01-03-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-01-02-10.wav\n",
      "03-01-03-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-02-01-10.wav\n",
      "03-01-03-02-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 9.1552734e-05  9.1552734e-05  9.1552734e-05 ... -1.2207031e-04\n",
      " -9.1552734e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 1.4648438e-03  6.1035156e-04  2.1667480e-03 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-03-02-02-02-10.wav\n",
      "03-01-03-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-01-01-10.wav\n",
      "03-01-04-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-01-02-10.wav\n",
      "03-01-04-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-02-01-10.wav\n",
      "03-01-04-01-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -1.2207031e-04 -9.1552734e-05 ...  0.0000000e+00\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05 -6.1035156e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-01-02-02-10.wav\n",
      "03-01-04-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-01-01-10.wav\n",
      "03-01-04-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-01-02-10.wav\n",
      "03-01-04-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-02-01-10.wav\n",
      "03-01-04-02-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.9672852e-04  1.8310547e-04 -2.7465820e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05 -3.0517578e-05 -2.1362305e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.5258789e-04  6.1035156e-05  1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-04-02-02-02-10.wav\n",
      "03-01-04-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-01-01-10.wav\n",
      "03-01-05-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-01-02-10.wav\n",
      "03-01-05-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-02-01-10.wav\n",
      "03-01-05-01-02-01-10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.4086914e-04  2.7465820e-04 -4.5776367e-04 ...  1.2207031e-04\n",
      "  9.1552734e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 1.5258789e-04 1.2207031e-04 ... 3.0517578e-05 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[1.5258789e-04 1.5258789e-04 1.8310547e-04 ... 3.0517578e-05 3.0517578e-05\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-01-02-02-10.wav\n",
      "03-01-05-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-01-01-10.wav\n",
      "03-01-05-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-01-02-10.wav\n",
      "03-01-05-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-02-01-10.wav\n",
      "03-01-05-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-05-02-02-02-10.wav\n",
      "03-01-05-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-01-01-10.wav\n",
      "03-01-06-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-01-02-10.wav\n",
      "03-01-06-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-02-01-10.wav\n",
      "03-01-06-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-01-02-02-10.wav\n",
      "03-01-06-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-01-01-10.wav\n",
      "03-01-06-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-01-02-10.wav\n",
      "03-01-06-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-02-01-10.wav\n",
      "03-01-06-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-06-02-02-02-10.wav\n",
      "03-01-06-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-01-01-10.wav\n",
      "03-01-07-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-01-02-10.wav\n",
      "03-01-07-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-02-01-10.wav\n",
      "03-01-07-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-01-02-02-10.wav\n",
      "03-01-07-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-01-01-10.wav\n",
      "03-01-07-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-01-02-10.wav\n",
      "03-01-07-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-02-01-10.wav\n",
      "03-01-07-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-07-02-02-02-10.wav\n",
      "03-01-07-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-01-01-10.wav\n",
      "03-01-08-01-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-01-02-10.wav\n",
      "03-01-08-01-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-02-01-10.wav\n",
      "03-01-08-01-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-01-02-02-10.wav\n",
      "03-01-08-01-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-01-01-10.wav\n",
      "03-01-08-02-01-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-01-02-10.wav\n",
      "03-01-08-02-01-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-02-01-10.wav\n",
      "03-01-08-02-02-01-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_10\\03-01-08-02-02-02-10.wav\n",
      "03-01-08-02-02-02-10.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-01-01-11.wav\n",
      "03-01-01-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-01-02-11.wav\n",
      "03-01-01-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05  3.0517578e-05  6.1035156e-05 ... -3.0517578e-05\n",
      "  6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-02-01-11.wav\n",
      "03-01-01-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-01-01-02-02-11.wav\n",
      "03-01-01-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-01-01-11.wav\n",
      "03-01-02-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-01-02-11.wav\n",
      "03-01-02-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-02-01-11.wav\n",
      "03-01-02-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-01-02-02-11.wav\n",
      "03-01-02-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-01-01-11.wav\n",
      "03-01-02-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-01-02-11.wav\n",
      "03-01-02-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-02-01-11.wav\n",
      "03-01-02-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-02-02-02-02-11.wav\n",
      "03-01-02-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-01-01-11.wav\n",
      "03-01-03-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-01-02-11.wav\n",
      "03-01-03-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  4.5776367e-04\n",
      "  4.5776367e-04  4.5776367e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05 -9.1552734e-05 -6.1035156e-05 ... -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-02-01-11.wav\n",
      "03-01-03-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-01-02-02-11.wav\n",
      "03-01-03-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-01-01-11.wav\n",
      "03-01-03-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-01-02-11.wav\n",
      "03-01-03-02-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 6.1035156e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ...  3.0517578e-05\n",
      "  2.1362305e-04  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-02-01-11.wav\n",
      "03-01-03-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-03-02-02-02-11.wav\n",
      "03-01-03-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-01-01-11.wav\n",
      "03-01-04-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-01-02-11.wav\n",
      "03-01-04-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[1.2207031e-04 9.1552734e-05 9.1552734e-05 ... 1.8310547e-04 1.8310547e-04\n",
      " 1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 1.5258789e-04  1.2207031e-04  1.2207031e-04 ... -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-02-01-11.wav\n",
      "03-01-04-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-01-02-02-11.wav\n",
      "03-01-04-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-01-01-11.wav\n",
      "03-01-04-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-01-02-11.wav\n",
      "03-01-04-02-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -6.1035156e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05  3.0517578e-05 ... -9.1552734e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-02-01-11.wav\n",
      "03-01-04-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-04-02-02-02-11.wav\n",
      "03-01-04-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-01-01-11.wav\n",
      "03-01-05-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-01-02-11.wav\n",
      "03-01-05-01-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[6.1035156e-05 9.1552734e-05 9.1552734e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.2207031e-04 -1.5258789e-04 -1.5258789e-04 ...  6.1035156e-05\n",
      "  6.1035156e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-02-01-11.wav\n",
      "03-01-05-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-01-02-02-11.wav\n",
      "03-01-05-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-01-01-11.wav\n",
      "03-01-05-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-01-02-11.wav\n",
      "03-01-05-02-01-02-11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -6.1035156e-05 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00027466 -0.00027466\n",
      " -0.00027466] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.2207031e-04 -9.1552734e-05 -6.1035156e-05 ... -1.2207031e-04\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-02-01-11.wav\n",
      "03-01-05-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-05-02-02-02-11.wav\n",
      "03-01-05-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-01-01-11.wav\n",
      "03-01-06-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-01-02-11.wav\n",
      "03-01-06-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-02-01-11.wav\n",
      "03-01-06-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-01-02-02-11.wav\n",
      "03-01-06-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-01-01-11.wav\n",
      "03-01-06-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-01-02-11.wav\n",
      "03-01-06-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-02-01-11.wav\n",
      "03-01-06-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-06-02-02-02-11.wav\n",
      "03-01-06-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-01-01-11.wav\n",
      "03-01-07-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-01-02-11.wav\n",
      "03-01-07-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-02-01-11.wav\n",
      "03-01-07-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-01-02-02-11.wav\n",
      "03-01-07-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-01-01-11.wav\n",
      "03-01-07-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-01-02-11.wav\n",
      "03-01-07-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-02-01-11.wav\n",
      "03-01-07-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-07-02-02-02-11.wav\n",
      "03-01-07-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-01-01-11.wav\n",
      "03-01-08-01-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-01-02-11.wav\n",
      "03-01-08-01-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-02-01-11.wav\n",
      "03-01-08-01-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-01-02-02-11.wav\n",
      "03-01-08-01-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-01-01-11.wav\n",
      "03-01-08-02-01-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-01-02-11.wav\n",
      "03-01-08-02-01-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-02-01-11.wav\n",
      "03-01-08-02-02-01-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_11\\03-01-08-02-02-02-11.wav\n",
      "03-01-08-02-02-02-11.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-01-01-12.wav\n",
      "03-01-01-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-01-02-12.wav\n",
      "03-01-01-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-02-01-12.wav\n",
      "03-01-01-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-01-01-02-02-12.wav\n",
      "03-01-01-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-01-01-12.wav\n",
      "03-01-02-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-01-02-12.wav\n",
      "03-01-02-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-02-01-12.wav\n",
      "03-01-02-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-01-02-02-12.wav\n",
      "03-01-02-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-01-01-12.wav\n",
      "03-01-02-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-01-02-12.wav\n",
      "03-01-02-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-02-01-12.wav\n",
      "03-01-02-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-02-02-02-02-12.wav\n",
      "03-01-02-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-01-01-12.wav\n",
      "03-01-03-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-01-02-12.wav\n",
      "03-01-03-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-02-01-12.wav\n",
      "03-01-03-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-01-02-02-12.wav\n",
      "03-01-03-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-01-01-12.wav\n",
      "03-01-03-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-01-02-12.wav\n",
      "03-01-03-02-01-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00021362 -0.00024414\n",
      " -0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-02-01-12.wav\n",
      "03-01-03-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-03-02-02-02-12.wav\n",
      "03-01-03-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-01-01-12.wav\n",
      "03-01-04-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-01-02-12.wav\n",
      "03-01-04-01-01-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -3.0212402e-03\n",
      " -3.0212402e-03 -3.0212402e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[1.5258789e-04 1.5258789e-04 9.1552734e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-02-01-12.wav\n",
      "03-01-04-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-01-02-02-12.wav\n",
      "03-01-04-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-01-01-12.wav\n",
      "03-01-04-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-01-02-12.wav\n",
      "03-01-04-02-01-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.00033569 0.00033569 0.00033569 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.0015564  -0.0015564\n",
      " -0.00158691] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-02-01-12.wav\n",
      "03-01-04-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-04-02-02-02-12.wav\n",
      "03-01-04-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-01-01-12.wav\n",
      "03-01-05-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-01-02-12.wav\n",
      "03-01-05-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-02-01-12.wav\n",
      "03-01-05-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-01-02-02-12.wav\n",
      "03-01-05-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-01-01-12.wav\n",
      "03-01-05-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-01-02-12.wav\n",
      "03-01-05-02-01-02-12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  0.0000000e+00 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00152588 -0.00149536\n",
      " -0.00149536] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.         0.         0.         ... 0.00283813 0.0027771  0.0027771 ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-02-01-12.wav\n",
      "03-01-05-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-05-02-02-02-12.wav\n",
      "03-01-05-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-01-01-12.wav\n",
      "03-01-06-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-01-02-12.wav\n",
      "03-01-06-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-02-01-12.wav\n",
      "03-01-06-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-01-02-02-12.wav\n",
      "03-01-06-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-01-01-12.wav\n",
      "03-01-06-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-01-02-12.wav\n",
      "03-01-06-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-02-01-12.wav\n",
      "03-01-06-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-06-02-02-02-12.wav\n",
      "03-01-06-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-01-01-12.wav\n",
      "03-01-07-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-01-02-12.wav\n",
      "03-01-07-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-02-01-12.wav\n",
      "03-01-07-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-01-02-02-12.wav\n",
      "03-01-07-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-01-01-12.wav\n",
      "03-01-07-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-01-02-12.wav\n",
      "03-01-07-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-02-01-12.wav\n",
      "03-01-07-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-07-02-02-02-12.wav\n",
      "03-01-07-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-01-01-12.wav\n",
      "03-01-08-01-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-01-02-12.wav\n",
      "03-01-08-01-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-02-01-12.wav\n",
      "03-01-08-01-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-01-02-02-12.wav\n",
      "03-01-08-01-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-01-01-12.wav\n",
      "03-01-08-02-01-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-01-02-12.wav\n",
      "03-01-08-02-01-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-02-01-12.wav\n",
      "03-01-08-02-02-01-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_12\\03-01-08-02-02-02-12.wav\n",
      "03-01-08-02-02-02-12.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-01-01-13.wav\n",
      "03-01-01-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-01-02-13.wav\n",
      "03-01-01-01-01-02-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00021362 -0.00027466\n",
      " -0.00024414] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-02-01-13.wav\n",
      "03-01-01-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-01-01-02-02-13.wav\n",
      "03-01-01-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-01-01-13.wav\n",
      "03-01-02-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-01-02-13.wav\n",
      "03-01-02-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-02-01-13.wav\n",
      "03-01-02-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-01-02-02-13.wav\n",
      "03-01-02-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-01-01-13.wav\n",
      "03-01-02-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-01-02-13.wav\n",
      "03-01-02-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-02-01-13.wav\n",
      "03-01-02-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-02-02-02-02-13.wav\n",
      "03-01-02-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-01-01-13.wav\n",
      "03-01-03-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-01-02-13.wav\n",
      "03-01-03-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-02-01-13.wav\n",
      "03-01-03-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-01-02-02-13.wav\n",
      "03-01-03-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-01-01-13.wav\n",
      "03-01-03-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-01-02-13.wav\n",
      "03-01-03-02-01-02-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.1035156e-05  3.0517578e-05  3.0517578e-05 ... -6.1035156e-05\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-02-01-13.wav\n",
      "03-01-03-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-03-02-02-02-13.wav\n",
      "03-01-03-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-01-01-13.wav\n",
      "03-01-04-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-01-02-13.wav\n",
      "03-01-04-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-02-01-13.wav\n",
      "03-01-04-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-01-02-02-13.wav\n",
      "03-01-04-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-01-01-13.wav\n",
      "03-01-04-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-01-02-13.wav\n",
      "03-01-04-02-01-02-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 3.0517578e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-02-01-13.wav\n",
      "03-01-04-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-04-02-02-02-13.wav\n",
      "03-01-04-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-01-01-13.wav\n",
      "03-01-05-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-01-02-13.wav\n",
      "03-01-05-01-01-02-13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-02-01-13.wav\n",
      "03-01-05-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-01-02-02-13.wav\n",
      "03-01-05-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-01-01-13.wav\n",
      "03-01-05-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-01-02-13.wav\n",
      "03-01-05-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-02-01-13.wav\n",
      "03-01-05-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-05-02-02-02-13.wav\n",
      "03-01-05-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-01-01-13.wav\n",
      "03-01-06-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-01-02-13.wav\n",
      "03-01-06-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-02-01-13.wav\n",
      "03-01-06-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-01-02-02-13.wav\n",
      "03-01-06-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-01-01-13.wav\n",
      "03-01-06-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-01-02-13.wav\n",
      "03-01-06-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-02-01-13.wav\n",
      "03-01-06-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-06-02-02-02-13.wav\n",
      "03-01-06-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-01-01-13.wav\n",
      "03-01-07-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-01-02-13.wav\n",
      "03-01-07-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-02-01-13.wav\n",
      "03-01-07-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-01-02-02-13.wav\n",
      "03-01-07-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-01-01-13.wav\n",
      "03-01-07-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-01-02-13.wav\n",
      "03-01-07-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-02-01-13.wav\n",
      "03-01-07-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-07-02-02-02-13.wav\n",
      "03-01-07-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-01-01-13.wav\n",
      "03-01-08-01-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-01-02-13.wav\n",
      "03-01-08-01-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-02-01-13.wav\n",
      "03-01-08-01-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-01-02-02-13.wav\n",
      "03-01-08-01-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-01-01-13.wav\n",
      "03-01-08-02-01-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-01-02-13.wav\n",
      "03-01-08-02-01-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-02-01-13.wav\n",
      "03-01-08-02-02-01-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_13\\03-01-08-02-02-02-13.wav\n",
      "03-01-08-02-02-02-13.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-01-01-14.wav\n",
      "03-01-01-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-01-02-14.wav\n",
      "03-01-01-01-01-02-14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -7.9345703e-04\n",
      " -8.2397461e-04 -8.2397461e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.         0.         0.         ... 0.00012207 0.00012207 0.00015259] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-02-01-14.wav\n",
      "03-01-01-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-01-01-02-02-14.wav\n",
      "03-01-01-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-01-01-14.wav\n",
      "03-01-02-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-01-02-14.wav\n",
      "03-01-02-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-02-01-14.wav\n",
      "03-01-02-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-01-02-02-14.wav\n",
      "03-01-02-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-01-01-14.wav\n",
      "03-01-02-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-01-02-14.wav\n",
      "03-01-02-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-02-01-14.wav\n",
      "03-01-02-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-02-02-02-02-14.wav\n",
      "03-01-02-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-01-01-14.wav\n",
      "03-01-03-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-01-02-14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-03-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-02-01-14.wav\n",
      "03-01-03-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-01-02-02-14.wav\n",
      "03-01-03-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-01-01-14.wav\n",
      "03-01-03-02-01-01-14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-01-02-14.wav\n",
      "03-01-03-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-02-01-14.wav\n",
      "03-01-03-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-03-02-02-02-14.wav\n",
      "03-01-03-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-01-01-14.wav\n",
      "03-01-04-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-01-02-14.wav\n",
      "03-01-04-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-02-01-14.wav\n",
      "03-01-04-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-01-02-02-14.wav\n",
      "03-01-04-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-01-01-14.wav\n",
      "03-01-04-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-01-02-14.wav\n",
      "03-01-04-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-02-01-14.wav\n",
      "03-01-04-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-04-02-02-02-14.wav\n",
      "03-01-04-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-01-01-14.wav\n",
      "03-01-05-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-01-02-14.wav\n",
      "03-01-05-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-02-01-14.wav\n",
      "03-01-05-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-01-02-02-14.wav\n",
      "03-01-05-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-01-01-14.wav\n",
      "03-01-05-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-01-02-14.wav\n",
      "03-01-05-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-02-01-14.wav\n",
      "03-01-05-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-05-02-02-02-14.wav\n",
      "03-01-05-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-01-01-14.wav\n",
      "03-01-06-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-01-02-14.wav\n",
      "03-01-06-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-02-01-14.wav\n",
      "03-01-06-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-01-02-02-14.wav\n",
      "03-01-06-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-01-01-14.wav\n",
      "03-01-06-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-01-02-14.wav\n",
      "03-01-06-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-02-01-14.wav\n",
      "03-01-06-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-06-02-02-02-14.wav\n",
      "03-01-06-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-01-01-14.wav\n",
      "03-01-07-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-01-02-14.wav\n",
      "03-01-07-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-02-01-14.wav\n",
      "03-01-07-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-01-02-02-14.wav\n",
      "03-01-07-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-01-01-14.wav\n",
      "03-01-07-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-01-02-14.wav\n",
      "03-01-07-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-02-01-14.wav\n",
      "03-01-07-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-07-02-02-02-14.wav\n",
      "03-01-07-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-01-01-14.wav\n",
      "03-01-08-01-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-01-02-14.wav\n",
      "03-01-08-01-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-02-01-14.wav\n",
      "03-01-08-01-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-01-02-02-14.wav\n",
      "03-01-08-01-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-01-01-14.wav\n",
      "03-01-08-02-01-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-01-02-14.wav\n",
      "03-01-08-02-01-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-02-01-14.wav\n",
      "03-01-08-02-02-01-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_14\\03-01-08-02-02-02-14.wav\n",
      "03-01-08-02-02-02-14.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-01-01-15.wav\n",
      "03-01-01-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-01-02-15.wav\n",
      "03-01-01-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-02-01-15.wav\n",
      "03-01-01-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-01-01-02-02-15.wav\n",
      "03-01-01-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-01-01-15.wav\n",
      "03-01-02-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-01-02-15.wav\n",
      "03-01-02-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-02-01-15.wav\n",
      "03-01-02-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-01-02-02-15.wav\n",
      "03-01-02-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-01-01-15.wav\n",
      "03-01-02-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-01-02-15.wav\n",
      "03-01-02-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-02-01-15.wav\n",
      "03-01-02-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-02-02-02-02-15.wav\n",
      "03-01-02-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-01-01-15.wav\n",
      "03-01-03-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-01-02-15.wav\n",
      "03-01-03-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-02-01-15.wav\n",
      "03-01-03-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-01-02-02-15.wav\n",
      "03-01-03-01-02-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 1.2207031e-04 1.2207031e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00210571 -0.00216675\n",
      " -0.0020752 ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-01-01-15.wav\n",
      "03-01-03-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-01-02-15.wav\n",
      "03-01-03-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-02-01-15.wav\n",
      "03-01-03-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-03-02-02-02-15.wav\n",
      "03-01-03-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-01-01-15.wav\n",
      "03-01-04-01-01-01-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.1552734e-05 1.2207031e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[6.1035156e-05 0.0000000e+00 3.0517578e-05 ... 1.5258789e-04 1.5258789e-04\n",
      " 1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.5258789e-04 -1.5258789e-04 -1.5258789e-04 ...  9.1552734e-05\n",
      "  9.1552734e-05  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-01-02-15.wav\n",
      "03-01-04-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-02-01-15.wav\n",
      "03-01-04-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-01-02-02-15.wav\n",
      "03-01-04-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-01-01-15.wav\n",
      "03-01-04-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-01-02-15.wav\n",
      "03-01-04-02-01-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00 -3.0517578e-05 ...  1.5258789e-04\n",
      "  1.5258789e-04  1.8310547e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -3.0517578e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.         0.         0.         ... 0.00042725 0.00042725 0.00042725] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05 -1.2207031e-04 -1.2207031e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-02-01-15.wav\n",
      "03-01-04-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-04-02-02-02-15.wav\n",
      "03-01-04-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-01-01-15.wav\n",
      "03-01-05-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-01-02-15.wav\n",
      "03-01-05-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-02-01-15.wav\n",
      "03-01-05-01-02-01-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  1.3732910e-03\n",
      "  1.4038086e-03  1.4343262e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 9.1552734e-05  3.0517578e-05  1.2207031e-04 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.2207031e-04\n",
      " -1.5258789e-04 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00 -3.0517578e-05 ...  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-01-02-02-15.wav\n",
      "03-01-05-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-01-01-15.wav\n",
      "03-01-05-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-01-02-15.wav\n",
      "03-01-05-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-02-01-15.wav\n",
      "03-01-05-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-05-02-02-02-15.wav\n",
      "03-01-05-02-02-02-15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  0.0000000e+00 ... -6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00012207 -0.00012207\n",
      " -0.00012207] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -6.1035156e-05 -6.1035156e-05 ...  1.2207031e-04\n",
      "  1.5258789e-04  9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-01-01-15.wav\n",
      "03-01-06-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-01-02-15.wav\n",
      "03-01-06-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-02-01-15.wav\n",
      "03-01-06-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-01-02-02-15.wav\n",
      "03-01-06-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-01-01-15.wav\n",
      "03-01-06-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-01-02-15.wav\n",
      "03-01-06-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-02-01-15.wav\n",
      "03-01-06-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-06-02-02-02-15.wav\n",
      "03-01-06-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-01-01-15.wav\n",
      "03-01-07-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-01-02-15.wav\n",
      "03-01-07-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-02-01-15.wav\n",
      "03-01-07-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-01-02-02-15.wav\n",
      "03-01-07-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-01-01-15.wav\n",
      "03-01-07-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-01-02-15.wav\n",
      "03-01-07-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-02-01-15.wav\n",
      "03-01-07-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-07-02-02-02-15.wav\n",
      "03-01-07-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-01-01-15.wav\n",
      "03-01-08-01-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-01-02-15.wav\n",
      "03-01-08-01-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-02-01-15.wav\n",
      "03-01-08-01-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-01-02-02-15.wav\n",
      "03-01-08-01-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-01-01-15.wav\n",
      "03-01-08-02-01-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-01-02-15.wav\n",
      "03-01-08-02-01-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-02-01-15.wav\n",
      "03-01-08-02-02-01-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_15\\03-01-08-02-02-02-15.wav\n",
      "03-01-08-02-02-02-15.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-01-01-16.wav\n",
      "03-01-01-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-01-02-16.wav\n",
      "03-01-01-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-02-01-16.wav\n",
      "03-01-01-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-01-01-02-02-16.wav\n",
      "03-01-01-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-01-01-16.wav\n",
      "03-01-02-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-01-02-16.wav\n",
      "03-01-02-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-02-01-16.wav\n",
      "03-01-02-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-01-02-02-16.wav"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.0517578e-05 6.1035156e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "03-01-02-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-01-01-16.wav\n",
      "03-01-02-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-01-02-16.wav\n",
      "03-01-02-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-02-01-16.wav\n",
      "03-01-02-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-02-02-02-02-16.wav\n",
      "03-01-02-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-01-01-16.wav\n",
      "03-01-03-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-01-02-16.wav\n",
      "03-01-03-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-02-01-16.wav\n",
      "03-01-03-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-01-02-02-16.wav\n",
      "03-01-03-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-01-01-16.wav\n",
      "03-01-03-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-01-02-16.wav\n",
      "03-01-03-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-02-01-16.wav\n",
      "03-01-03-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-03-02-02-02-16.wav\n",
      "03-01-03-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-01-01-16.wav\n",
      "03-01-04-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-01-02-16.wav\n",
      "03-01-04-01-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-02-01-16.wav\n",
      "03-01-04-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-01-02-02-16.wav\n",
      "03-01-04-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-01-01-16.wav\n",
      "03-01-04-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-01-02-16.wav\n",
      "03-01-04-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-02-01-16.wav\n",
      "03-01-04-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-04-02-02-02-16.wav\n",
      "03-01-04-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-01-01-16.wav\n",
      "03-01-05-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-01-02-16.wav\n",
      "03-01-05-01-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -6.1035156e-05 -1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-02-01-16.wav\n",
      "03-01-05-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-01-02-02-16.wav\n",
      "03-01-05-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-01-01-16.wav\n",
      "03-01-05-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-01-02-16.wav\n",
      "03-01-05-02-01-02-16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -6.1035156e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-02-01-16.wav\n",
      "03-01-05-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-05-02-02-02-16.wav\n",
      "03-01-05-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-01-01-16.wav\n",
      "03-01-06-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-01-02-16.wav\n",
      "03-01-06-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-02-01-16.wav\n",
      "03-01-06-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-01-02-02-16.wav\n",
      "03-01-06-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-01-01-16.wav\n",
      "03-01-06-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-01-02-16.wav\n",
      "03-01-06-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-02-01-16.wav\n",
      "03-01-06-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-06-02-02-02-16.wav\n",
      "03-01-06-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-01-01-16.wav\n",
      "03-01-07-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-01-02-16.wav\n",
      "03-01-07-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-02-01-16.wav\n",
      "03-01-07-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-01-02-02-16.wav\n",
      "03-01-07-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-01-01-16.wav\n",
      "03-01-07-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-01-02-16.wav\n",
      "03-01-07-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-02-01-16.wav\n",
      "03-01-07-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-07-02-02-02-16.wav\n",
      "03-01-07-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-01-01-16.wav\n",
      "03-01-08-01-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-01-02-16.wav\n",
      "03-01-08-01-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-02-01-16.wav\n",
      "03-01-08-01-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-01-02-02-16.wav\n",
      "03-01-08-01-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-01-01-16.wav\n",
      "03-01-08-02-01-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-01-02-16.wav\n",
      "03-01-08-02-01-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-02-01-16.wav\n",
      "03-01-08-02-02-01-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_16\\03-01-08-02-02-02-16.wav\n",
      "03-01-08-02-02-02-16.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-01-01-17.wav\n",
      "03-01-01-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-01-02-17.wav\n",
      "03-01-01-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-04  3.3569336e-04  3.0517578e-04 ... -9.1552734e-05\n",
      " -9.1552734e-05 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[9.1552734e-05 9.1552734e-05 6.1035156e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  3.0517578e-05  3.0517578e-05 ... -9.1552734e-05\n",
      " -6.1035156e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-6.1035156e-05 -3.0517578e-05  0.0000000e+00 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-02-01-17.wav\n",
      "03-01-01-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-01-01-02-02-17.wav\n",
      "03-01-01-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-01-01-17.wav\n",
      "03-01-02-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-01-02-17.wav\n",
      "03-01-02-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-02-01-17.wav\n",
      "03-01-02-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-01-02-02-17.wav\n",
      "03-01-02-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-01-01-17.wav\n",
      "03-01-02-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-01-02-17.wav\n",
      "03-01-02-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-02-01-17.wav\n",
      "03-01-02-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-02-02-02-02-17.wav\n",
      "03-01-02-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-01-01-17.wav\n",
      "03-01-03-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-01-02-17.wav\n",
      "03-01-03-01-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.1035156e-05  6.1035156e-05  6.1035156e-05 ... -9.1552734e-05\n",
      " -9.1552734e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-2.1362305e-04 -9.1552734e-05  0.0000000e+00 ... -1.2207031e-04\n",
      " -1.5258789e-04 -1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[6.1035156e-05 6.1035156e-05 9.1552734e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[1.8310547e-04 1.5258789e-04 3.0517578e-05 ... 9.1552734e-05 9.1552734e-05\n",
      " 9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-02-01-17.wav\n",
      "03-01-03-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-01-02-02-17.wav\n",
      "03-01-03-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-01-01-17.wav\n",
      "03-01-03-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-01-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.5258789e-04 ... -2.4414062e-04\n",
      " -9.1552734e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.3569336e-04 -9.1552734e-05  3.9672852e-04 ...  1.5258789e-04\n",
      "  1.2207031e-04  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-03-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-02-01-17.wav\n",
      "03-01-03-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-03-02-02-02-17.wav\n",
      "03-01-03-02-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 1.8310547e-04  1.8310547e-04  6.1035156e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 3.0517578e-05 3.0517578e-05 ... 1.2207031e-04 1.5258789e-04\n",
      " 1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.00012207 -0.00015259 -0.00018311 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 9.1552734e-05 9.1552734e-05 ... 6.1035156e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-01-01-17.wav\n",
      "03-01-04-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-01-02-17.wav\n",
      "03-01-04-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-02-01-17.wav\n",
      "03-01-04-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-01-02-02-17.wav\n",
      "03-01-04-01-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.         0.         0.         ... 0.00018311 0.00018311 0.00018311] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[1.8310547e-04 1.2207031e-04 3.0517578e-05 ... 1.2207031e-04 1.2207031e-04\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-01-01-17.wav\n",
      "03-01-04-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-01-02-17.wav\n",
      "03-01-04-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-02-01-17.wav\n",
      "03-01-04-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-04-02-02-02-17.wav\n",
      "03-01-04-02-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-04 -3.3569336e-04 -5.7983398e-04 ...  6.1035156e-05\n",
      "  9.1552734e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05 -6.1035156e-05 -6.1035156e-05 ... -1.5258789e-04\n",
      " -1.5258789e-04 -1.5258789e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00 -3.0517578e-05 -3.0517578e-05 ... -1.2207031e-04\n",
      " -1.5258789e-04 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-01-01-17.wav\n",
      "03-01-05-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-01-02-17.wav\n",
      "03-01-05-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-02-01-17.wav\n",
      "03-01-05-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-01-02-02-17.wav\n",
      "03-01-05-01-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[1.2207031e-04 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-9.1552734e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.5258789e-04 -6.1035156e-05 -1.5258789e-04 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.00018311 0.00018311 0.00018311 ... 0.         0.         0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-01-01-17.wav\n",
      "03-01-05-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-01-02-17.wav\n",
      "03-01-05-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-02-01-17.wav\n",
      "03-01-05-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-05-02-02-02-17.wav\n",
      "03-01-05-02-02-02-17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-2.4414062e-04 -9.1552734e-05 -3.0517578e-05 ... -6.1035156e-05\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-01-01-17.wav\n",
      "03-01-06-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-01-02-17.wav\n",
      "03-01-06-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-02-01-17.wav\n",
      "03-01-06-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-01-02-02-17.wav\n",
      "03-01-06-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-01-01-17.wav\n",
      "03-01-06-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-01-02-17.wav\n",
      "03-01-06-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-02-01-17.wav\n",
      "03-01-06-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-06-02-02-02-17.wav\n",
      "03-01-06-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-01-01-17.wav\n",
      "03-01-07-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-01-02-17.wav\n",
      "03-01-07-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-02-01-17.wav\n",
      "03-01-07-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-01-02-02-17.wav\n",
      "03-01-07-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-01-01-17.wav\n",
      "03-01-07-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-01-02-17.wav\n",
      "03-01-07-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-02-01-17.wav\n",
      "03-01-07-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-07-02-02-02-17.wav\n",
      "03-01-07-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-01-01-17.wav\n",
      "03-01-08-01-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-01-02-17.wav\n",
      "03-01-08-01-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-02-01-17.wav\n",
      "03-01-08-01-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-01-02-02-17.wav\n",
      "03-01-08-01-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-01-01-17.wav\n",
      "03-01-08-02-01-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-01-02-17.wav\n",
      "03-01-08-02-01-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-02-01-17.wav\n",
      "03-01-08-02-02-01-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_17\\03-01-08-02-02-02-17.wav\n",
      "03-01-08-02-02-02-17.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-01-01-18.wav\n",
      "03-01-01-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-01-02-18.wav\n",
      "03-01-01-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-02-01-18.wav\n",
      "03-01-01-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-01-01-02-02-18.wav\n",
      "03-01-01-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-01-01-18.wav\n",
      "03-01-02-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-01-02-18.wav\n",
      "03-01-02-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-02-01-18.wav\n",
      "03-01-02-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-01-02-02-18.wav\n",
      "03-01-02-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-01-01-18.wav\n",
      "03-01-02-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-01-02-18.wav\n",
      "03-01-02-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-02-01-18.wav\n",
      "03-01-02-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-02-02-02-02-18.wav\n",
      "03-01-02-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-01-01-18.wav\n",
      "03-01-03-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-01-02-18.wav\n",
      "03-01-03-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-02-01-18.wav\n",
      "03-01-03-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-01-02-02-18.wav\n",
      "03-01-03-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-01-01-18.wav\n",
      "03-01-03-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-01-02-18.wav\n",
      "03-01-03-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-02-01-18.wav\n",
      "03-01-03-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-03-02-02-02-18.wav\n",
      "03-01-03-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-01-01-18.wav\n",
      "03-01-04-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-01-02-18.wav\n",
      "03-01-04-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-02-01-18.wav\n",
      "03-01-04-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-01-02-02-18.wav\n",
      "03-01-04-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-01-01-18.wav\n",
      "03-01-04-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-01-02-18.wav\n",
      "03-01-04-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-02-01-18.wav\n",
      "03-01-04-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-04-02-02-02-18.wav\n",
      "03-01-04-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-01-01-18.wav\n",
      "03-01-05-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-01-02-18.wav\n",
      "03-01-05-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-02-01-18.wav\n",
      "03-01-05-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-01-02-02-18.wav\n",
      "03-01-05-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-01-01-18.wav\n",
      "03-01-05-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-01-02-18.wav\n",
      "03-01-05-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-02-01-18.wav\n",
      "03-01-05-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-05-02-02-02-18.wav\n",
      "03-01-05-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-01-01-18.wav\n",
      "03-01-06-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-01-02-18.wav\n",
      "03-01-06-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-02-01-18.wav\n",
      "03-01-06-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-01-02-02-18.wav\n",
      "03-01-06-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-01-01-18.wav\n",
      "03-01-06-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-01-02-18.wav\n",
      "03-01-06-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-02-01-18.wav\n",
      "03-01-06-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-06-02-02-02-18.wav\n",
      "03-01-06-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-01-01-18.wav\n",
      "03-01-07-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-01-02-18.wav\n",
      "03-01-07-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-02-01-18.wav\n",
      "03-01-07-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-01-02-02-18.wav\n",
      "03-01-07-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-01-01-18.wav\n",
      "03-01-07-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-01-02-18.wav\n",
      "03-01-07-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-02-01-18.wav\n",
      "03-01-07-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-07-02-02-02-18.wav\n",
      "03-01-07-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-01-01-18.wav\n",
      "03-01-08-01-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-01-02-18.wav\n",
      "03-01-08-01-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-02-01-18.wav\n",
      "03-01-08-01-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-01-02-02-18.wav\n",
      "03-01-08-01-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-01-01-18.wav\n",
      "03-01-08-02-01-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-01-02-18.wav\n",
      "03-01-08-02-01-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-02-01-18.wav\n",
      "03-01-08-02-02-01-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_18\\03-01-08-02-02-02-18.wav\n",
      "03-01-08-02-02-02-18.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-01-01-19.wav\n",
      "03-01-01-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-01-02-19.wav\n",
      "03-01-01-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-02-01-19.wav\n",
      "03-01-01-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-01-01-02-02-19.wav\n",
      "03-01-01-01-02-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.00018311 -0.00018311 -0.00021362 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.         0.         0.         ... 0.00308228 0.00311279 0.00308228] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 3.0517578e-05 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-01-01-19.wav\n",
      "03-01-02-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-01-02-19.wav\n",
      "03-01-02-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-02-01-19.wav\n",
      "03-01-02-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-01-02-02-19.wav\n",
      "03-01-02-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-01-01-19.wav\n",
      "03-01-02-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-01-02-19.wav\n",
      "03-01-02-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-02-01-19.wav\n",
      "03-01-02-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-02-02-02-02-19.wav\n",
      "03-01-02-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-01-01-19.wav\n",
      "03-01-03-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-01-02-19.wav\n",
      "03-01-03-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-02-01-19.wav\n",
      "03-01-03-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-01-02-02-19.wav\n",
      "03-01-03-01-02-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 0.0000000e+00 ... 9.1552734e-05 6.1035156e-05\n",
      " 6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -1.2207031e-04 ...  9.1552734e-05\n",
      "  9.1552734e-05  1.2207031e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.00036621  0.00045776  0.00048828 ... -0.00021362 -0.00021362\n",
      " -0.00021362] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-01-01-19.wav\n",
      "03-01-03-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-01-02-19.wav\n",
      "03-01-03-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-02-01-19.wav\n",
      "03-01-03-02-02-01-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.00067139  0.00076294  0.00106812 ...  0.00344849 -0.00195312\n",
      " -0.00204468] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -1.2207031e-04 ...  3.0517578e-05\n",
      "  3.0517578e-05  6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-03-02-02-02-19.wav\n",
      "03-01-03-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-01-01-19.wav\n",
      "03-01-04-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-01-02-19.wav\n",
      "03-01-04-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-02-01-19.wav\n",
      "03-01-04-01-02-01-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 6.1035156e-05 6.1035156e-05 ... 6.1035156e-05 3.0517578e-05\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 1.2207031e-04  1.2207031e-04  1.2207031e-04 ... -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00125122 -0.00125122\n",
      " -0.00125122] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-01-02-02-19.wav\n",
      "03-01-04-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-01-01-19.wav\n",
      "03-01-04-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-01-02-19.wav\n",
      "03-01-04-02-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.0022583  -0.00228882 -0.00234985 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00  0.0000000e+00 ... -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.00048828 -0.00036621 -0.00027466 ... -0.00021362 -0.00021362\n",
      " -0.00021362] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-02-01-19.wav\n",
      "03-01-04-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-04-02-02-02-19.wav\n",
      "03-01-04-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-01-01-19.wav\n",
      "03-01-05-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-01-02-19.wav\n",
      "03-01-05-01-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-1.2207031e-04 -1.2207031e-04 -9.1552734e-05 ...  3.9672852e-04\n",
      "  3.9672852e-04  3.6621094e-04] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      " -3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-0.00283813 -0.00286865 -0.00286865 ...  0.          0.\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-02-01-19.wav\n",
      "03-01-05-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-01-02-02-19.wav\n",
      "03-01-05-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-01-01-19.wav\n",
      "03-01-05-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-01-02-19.wav\n",
      "03-01-05-02-01-02-19.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -9.1552734e-05\n",
      " -9.1552734e-05 -9.1552734e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 6.1035156e-05 -3.0517578e-05  2.1362305e-04 ...  0.0000000e+00\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-02-01-19.wav\n",
      "03-01-05-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-05-02-02-02-19.wav\n",
      "03-01-05-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-01-01-19.wav\n",
      "03-01-06-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-01-02-19.wav\n",
      "03-01-06-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-02-01-19.wav\n",
      "03-01-06-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-01-02-02-19.wav\n",
      "03-01-06-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-01-01-19.wav\n",
      "03-01-06-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-01-02-19.wav\n",
      "03-01-06-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-02-01-19.wav\n",
      "03-01-06-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-06-02-02-02-19.wav\n",
      "03-01-06-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-01-01-19.wav\n",
      "03-01-07-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-01-02-19.wav\n",
      "03-01-07-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-02-01-19.wav\n",
      "03-01-07-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-01-02-02-19.wav\n",
      "03-01-07-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-01-01-19.wav\n",
      "03-01-07-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-01-02-19.wav\n",
      "03-01-07-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-02-01-19.wav\n",
      "03-01-07-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-07-02-02-02-19.wav\n",
      "03-01-07-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-01-01-19.wav\n",
      "03-01-08-01-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-01-02-19.wav\n",
      "03-01-08-01-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-02-01-19.wav\n",
      "03-01-08-01-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-01-02-02-19.wav\n",
      "03-01-08-01-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-01-01-19.wav\n",
      "03-01-08-02-01-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-01-02-19.wav\n",
      "03-01-08-02-01-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-02-01-19.wav\n",
      "03-01-08-02-02-01-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_19\\03-01-08-02-02-02-19.wav\n",
      "03-01-08-02-02-02-19.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-01-01-20.wav\n",
      "03-01-01-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-01-02-20.wav\n",
      "03-01-01-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-02-01-20.wav\n",
      "03-01-01-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-01-01-02-02-20.wav\n",
      "03-01-01-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-01-01-20.wav\n",
      "03-01-02-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-01-02-20.wav\n",
      "03-01-02-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-02-01-20.wav\n",
      "03-01-02-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-01-02-02-20.wav\n",
      "03-01-02-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-01-01-20.wav\n",
      "03-01-02-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-01-02-20.wav\n",
      "03-01-02-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-02-01-20.wav\n",
      "03-01-02-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-02-02-02-02-20.wav\n",
      "03-01-02-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-01-01-20.wav\n",
      "03-01-03-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-01-02-20.wav\n",
      "03-01-03-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-02-01-20.wav\n",
      "03-01-03-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-01-02-02-20.wav\n",
      "03-01-03-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-01-01-20.wav\n",
      "03-01-03-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-01-02-20.wav\n",
      "03-01-03-02-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "  3.0517578e-05 -6.1035156e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-02-01-20.wav\n",
      "03-01-03-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-03-02-02-02-20.wav\n",
      "03-01-03-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-01-01-20.wav\n",
      "03-01-04-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-01-02-20.wav\n",
      "03-01-04-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-02-01-20.wav\n",
      "03-01-04-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-01-02-02-20.wav\n",
      "03-01-04-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-01-01-20.wav\n",
      "03-01-04-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-01-02-20.wav\n",
      "03-01-04-02-01-02-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.01150513 -0.0135498\n",
      "  0.01361084] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-02-01-20.wav\n",
      "03-01-04-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-04-02-02-02-20.wav\n",
      "03-01-04-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-01-01-20.wav\n",
      "03-01-05-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-01-02-20.wav\n",
      "03-01-05-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-02-01-20.wav\n",
      "03-01-05-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-01-02-02-20.wav\n",
      "03-01-05-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-01-01-20.wav\n",
      "03-01-05-02-01-01-20.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  3.0517578e-05 -9.1552734e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05  0.0000000e+00  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 3.0517578e-05  0.0000000e+00 -3.0517578e-05 ... -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-01-02-20.wav\n",
      "03-01-05-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-02-01-20.wav\n",
      "03-01-05-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-05-02-02-02-20.wav\n",
      "03-01-05-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-01-01-20.wav\n",
      "03-01-06-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-01-02-20.wav\n",
      "03-01-06-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-02-01-20.wav\n",
      "03-01-06-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-01-02-02-20.wav\n",
      "03-01-06-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-01-01-20.wav\n",
      "03-01-06-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-01-02-20.wav\n",
      "03-01-06-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-02-01-20.wav\n",
      "03-01-06-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-06-02-02-02-20.wav\n",
      "03-01-06-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-01-01-20.wav\n",
      "03-01-07-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-01-02-20.wav\n",
      "03-01-07-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-02-01-20.wav\n",
      "03-01-07-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-01-02-02-20.wav\n",
      "03-01-07-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-01-01-20.wav\n",
      "03-01-07-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-01-02-20.wav\n",
      "03-01-07-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-02-01-20.wav\n",
      "03-01-07-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-07-02-02-02-20.wav\n",
      "03-01-07-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-01-01-20.wav\n",
      "03-01-08-01-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-01-02-20.wav\n",
      "03-01-08-01-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-02-01-20.wav\n",
      "03-01-08-01-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-01-02-02-20.wav\n",
      "03-01-08-01-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-01-01-20.wav\n",
      "03-01-08-02-01-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-01-02-20.wav\n",
      "03-01-08-02-01-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-02-01-20.wav\n",
      "03-01-08-02-02-01-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_20\\03-01-08-02-02-02-20.wav\n",
      "03-01-08-02-02-02-20.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-01-01-21.wav\n",
      "03-01-01-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-01-02-21.wav\n",
      "03-01-01-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-02-01-21.wav\n",
      "03-01-01-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-01-01-02-02-21.wav\n",
      "03-01-01-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-01-01-21.wav\n",
      "03-01-02-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-01-02-21.wav\n",
      "03-01-02-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-02-01-21.wav\n",
      "03-01-02-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-01-02-02-21.wav\n",
      "03-01-02-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-01-01-21.wav\n",
      "03-01-02-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-01-02-21.wav\n",
      "03-01-02-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-02-01-21.wav\n",
      "03-01-02-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-02-02-02-02-21.wav\n",
      "03-01-02-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-01-01-21.wav\n",
      "03-01-03-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-01-02-21.wav\n",
      "03-01-03-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-02-01-21.wav\n",
      "03-01-03-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-01-02-02-21.wav\n",
      "03-01-03-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-01-01-21.wav\n",
      "03-01-03-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-01-02-21.wav\n",
      "03-01-03-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-02-01-21.wav\n",
      "03-01-03-02-02-01-21.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[3.0517578e-05 0.0000000e+00 3.0517578e-05 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-03-02-02-02-21.wav\n",
      "03-01-03-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-01-01-21.wav\n",
      "03-01-04-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-01-02-21.wav\n",
      "03-01-04-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-02-01-21.wav\n",
      "03-01-04-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-01-02-02-21.wav\n",
      "03-01-04-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-01-01-21.wav\n",
      "03-01-04-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-01-02-21.wav\n",
      "03-01-04-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-02-01-21.wav\n",
      "03-01-04-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-04-02-02-02-21.wav\n",
      "03-01-04-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-01-01-21.wav\n",
      "03-01-05-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-01-02-21.wav\n",
      "03-01-05-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-02-01-21.wav\n",
      "03-01-05-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-01-02-02-21.wav\n",
      "03-01-05-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-01-01-21.wav\n",
      "03-01-05-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-01-02-21.wav\n",
      "03-01-05-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-02-01-21.wav\n",
      "03-01-05-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-05-02-02-02-21.wav\n",
      "03-01-05-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-01-01-21.wav\n",
      "03-01-06-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-01-02-21.wav\n",
      "03-01-06-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-02-01-21.wav\n",
      "03-01-06-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-01-02-02-21.wav\n",
      "03-01-06-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-01-01-21.wav\n",
      "03-01-06-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-01-02-21.wav\n",
      "03-01-06-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-02-01-21.wav\n",
      "03-01-06-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-06-02-02-02-21.wav\n",
      "03-01-06-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-01-01-21.wav\n",
      "03-01-07-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-01-02-21.wav\n",
      "03-01-07-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-02-01-21.wav\n",
      "03-01-07-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-01-02-02-21.wav\n",
      "03-01-07-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-01-01-21.wav\n",
      "03-01-07-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-01-02-21.wav\n",
      "03-01-07-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-02-01-21.wav\n",
      "03-01-07-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-07-02-02-02-21.wav\n",
      "03-01-07-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-01-01-21.wav\n",
      "03-01-08-01-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-01-02-21.wav\n",
      "03-01-08-01-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-02-01-21.wav\n",
      "03-01-08-01-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-01-02-02-21.wav\n",
      "03-01-08-01-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-01-01-21.wav\n",
      "03-01-08-02-01-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-01-02-21.wav\n",
      "03-01-08-02-01-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-02-01-21.wav\n",
      "03-01-08-02-02-01-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_21\\03-01-08-02-02-02-21.wav\n",
      "03-01-08-02-02-02-21.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-01-01-22.wav\n",
      "03-01-01-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-01-02-22.wav\n",
      "03-01-01-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-02-01-22.wav\n",
      "03-01-01-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-01-01-02-02-22.wav\n",
      "03-01-01-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-01-01-22.wav\n",
      "03-01-02-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-01-02-22.wav\n",
      "03-01-02-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-02-01-22.wav\n",
      "03-01-02-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-01-02-02-22.wav\n",
      "03-01-02-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-01-01-22.wav\n",
      "03-01-02-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-01-02-22.wav\n",
      "03-01-02-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-02-01-22.wav\n",
      "03-01-02-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-02-02-02-02-22.wav\n",
      "03-01-02-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-01-01-22.wav\n",
      "03-01-03-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-01-02-22.wav\n",
      "03-01-03-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-02-01-22.wav\n",
      "03-01-03-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-01-02-02-22.wav\n",
      "03-01-03-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-01-01-22.wav\n",
      "03-01-03-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-01-02-22.wav\n",
      "03-01-03-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-02-01-22.wav\n",
      "03-01-03-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-03-02-02-02-22.wav\n",
      "03-01-03-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-01-01-22.wav\n",
      "03-01-04-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-01-02-22.wav\n",
      "03-01-04-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-02-01-22.wav\n",
      "03-01-04-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-01-02-02-22.wav\n",
      "03-01-04-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-01-01-22.wav\n",
      "03-01-04-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-01-02-22.wav\n",
      "03-01-04-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-02-01-22.wav\n",
      "03-01-04-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-04-02-02-02-22.wav\n",
      "03-01-04-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-01-01-22.wav\n",
      "03-01-05-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-01-02-22.wav\n",
      "03-01-05-01-01-02-22.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-02-01-22.wav\n",
      "03-01-05-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-01-02-02-22.wav\n",
      "03-01-05-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-01-01-22.wav\n",
      "03-01-05-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-01-02-22.wav\n",
      "03-01-05-02-01-02-22.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -6.1035156e-05 -6.1035156e-05 ...  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-02-01-22.wav\n",
      "03-01-05-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-05-02-02-02-22.wav\n",
      "03-01-05-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-01-01-22.wav\n",
      "03-01-06-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-01-02-22.wav\n",
      "03-01-06-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-02-01-22.wav\n",
      "03-01-06-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-01-02-02-22.wav\n",
      "03-01-06-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-01-01-22.wav\n",
      "03-01-06-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-01-02-22.wav\n",
      "03-01-06-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-02-01-22.wav\n",
      "03-01-06-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-06-02-02-02-22.wav\n",
      "03-01-06-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-01-01-22.wav\n",
      "03-01-07-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-01-02-22.wav\n",
      "03-01-07-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-02-01-22.wav\n",
      "03-01-07-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-01-02-02-22.wav\n",
      "03-01-07-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-01-01-22.wav\n",
      "03-01-07-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-01-02-22.wav\n",
      "03-01-07-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-02-01-22.wav\n",
      "03-01-07-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-07-02-02-02-22.wav\n",
      "03-01-07-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-01-01-22.wav\n",
      "03-01-08-01-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-01-02-22.wav\n",
      "03-01-08-01-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-02-01-22.wav\n",
      "03-01-08-01-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-01-02-02-22.wav\n",
      "03-01-08-01-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-01-01-22.wav\n",
      "03-01-08-02-01-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-01-02-22.wav\n",
      "03-01-08-02-01-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-02-01-22.wav\n",
      "03-01-08-02-02-01-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_22\\03-01-08-02-02-02-22.wav\n",
      "03-01-08-02-02-02-22.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-01-01-23.wav\n",
      "03-01-01-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-01-02-23.wav\n",
      "03-01-01-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-02-01-23.wav\n",
      "03-01-01-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-01-01-02-02-23.wav\n",
      "03-01-01-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-01-01-23.wav\n",
      "03-01-02-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-01-02-23.wav\n",
      "03-01-02-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-02-01-23.wav\n",
      "03-01-02-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-01-02-02-23.wav\n",
      "03-01-02-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-01-01-23.wav\n",
      "03-01-02-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-01-02-23.wav\n",
      "03-01-02-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-02-01-23.wav\n",
      "03-01-02-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-02-02-02-02-23.wav\n",
      "03-01-02-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-01-01-23.wav\n",
      "03-01-03-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-01-02-23.wav\n",
      "03-01-03-01-01-02-23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-02-01-23.wav\n",
      "03-01-03-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-01-02-02-23.wav\n",
      "03-01-03-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-01-01-23.wav\n",
      "03-01-03-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-01-02-23.wav\n",
      "03-01-03-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-02-01-23.wav\n",
      "03-01-03-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-03-02-02-02-23.wav\n",
      "03-01-03-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-01-01-23.wav\n",
      "03-01-04-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-01-02-23.wav\n",
      "03-01-04-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-02-01-23.wav\n",
      "03-01-04-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-01-02-02-23.wav\n",
      "03-01-04-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-01-01-23.wav\n",
      "03-01-04-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-01-02-23.wav\n",
      "03-01-04-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-02-01-23.wav\n",
      "03-01-04-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-04-02-02-02-23.wav\n",
      "03-01-04-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-01-01-23.wav\n",
      "03-01-05-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-01-02-23.wav\n",
      "03-01-05-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-02-01-23.wav\n",
      "03-01-05-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-01-02-02-23.wav\n",
      "03-01-05-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-01-01-23.wav\n",
      "03-01-05-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-01-02-23.wav\n",
      "03-01-05-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-02-01-23.wav\n",
      "03-01-05-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-05-02-02-02-23.wav\n",
      "03-01-05-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-01-01-23.wav\n",
      "03-01-06-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-01-02-23.wav\n",
      "03-01-06-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-02-01-23.wav\n",
      "03-01-06-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-01-02-02-23.wav\n",
      "03-01-06-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-01-01-23.wav\n",
      "03-01-06-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-01-02-23.wav\n",
      "03-01-06-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-02-01-23.wav\n",
      "03-01-06-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-06-02-02-02-23.wav\n",
      "03-01-06-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-01-01-23.wav\n",
      "03-01-07-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-01-02-23.wav\n",
      "03-01-07-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-02-01-23.wav\n",
      "03-01-07-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-01-02-02-23.wav\n",
      "03-01-07-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-01-01-23.wav\n",
      "03-01-07-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-01-02-23.wav\n",
      "03-01-07-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-02-01-23.wav\n",
      "03-01-07-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-07-02-02-02-23.wav\n",
      "03-01-07-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-01-01-23.wav\n",
      "03-01-08-01-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-01-02-23.wav\n",
      "03-01-08-01-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-02-01-23.wav\n",
      "03-01-08-01-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-01-02-02-23.wav\n",
      "03-01-08-01-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-01-01-23.wav\n",
      "03-01-08-02-01-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-01-02-23.wav\n",
      "03-01-08-02-01-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-02-01-23.wav\n",
      "03-01-08-02-02-01-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_23\\03-01-08-02-02-02-23.wav\n",
      "03-01-08-02-02-02-23.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-01-01-24.wav\n",
      "03-01-01-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-01-02-24.wav\n",
      "03-01-01-01-01-02-24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-02-01-24.wav\n",
      "03-01-01-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-01-01-02-02-24.wav\n",
      "03-01-01-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-01-01-24.wav\n",
      "03-01-02-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-01-02-24.wav\n",
      "03-01-02-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-02-01-24.wav\n",
      "03-01-02-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-01-02-02-24.wav\n",
      "03-01-02-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-01-01-24.wav\n",
      "03-01-02-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-01-02-24.wav\n",
      "03-01-02-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-02-01-24.wav\n",
      "03-01-02-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-02-02-02-02-24.wav\n",
      "03-01-02-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-01-01-24.wav\n",
      "03-01-03-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-01-02-24.wav\n",
      "03-01-03-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-02-01-24.wav\n",
      "03-01-03-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-01-02-02-24.wav\n",
      "03-01-03-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-01-01-24.wav\n",
      "03-01-03-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-01-02-24.wav\n",
      "03-01-03-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-02-01-24.wav\n",
      "03-01-03-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-03-02-02-02-24.wav\n",
      "03-01-03-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-01-01-24.wav\n",
      "03-01-04-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-01-02-24.wav\n",
      "03-01-04-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-02-01-24.wav\n",
      "03-01-04-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-01-02-02-24.wav\n",
      "03-01-04-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-01-01-24.wav\n",
      "03-01-04-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-01-02-24.wav\n",
      "03-01-04-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-02-01-24.wav\n",
      "03-01-04-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-04-02-02-02-24.wav\n",
      "03-01-04-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-01-01-24.wav\n",
      "03-01-05-01-01-01-24.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.5258789e-04\n",
      " -1.5258789e-04 -3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-01-02-24.wav\n",
      "03-01-05-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-02-01-24.wav\n",
      "03-01-05-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-01-02-02-24.wav\n",
      "03-01-05-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-01-01-24.wav\n",
      "03-01-05-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-01-02-24.wav\n",
      "03-01-05-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-02-01-24.wav\n",
      "03-01-05-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-05-02-02-02-24.wav\n",
      "03-01-05-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-01-01-24.wav\n",
      "03-01-06-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-01-02-24.wav\n",
      "03-01-06-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-02-01-24.wav\n",
      "03-01-06-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-01-02-02-24.wav\n",
      "03-01-06-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-01-01-24.wav\n",
      "03-01-06-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-01-02-24.wav\n",
      "03-01-06-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-02-01-24.wav\n",
      "03-01-06-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-06-02-02-02-24.wav\n",
      "03-01-06-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-01-01-24.wav\n",
      "03-01-07-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-01-02-24.wav\n",
      "03-01-07-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-02-01-24.wav\n",
      "03-01-07-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-01-02-02-24.wav\n",
      "03-01-07-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-01-01-24.wav\n",
      "03-01-07-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-01-02-24.wav\n",
      "03-01-07-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-02-01-24.wav\n",
      "03-01-07-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-07-02-02-02-24.wav\n",
      "03-01-07-02-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-01-01-24.wav\n",
      "03-01-08-01-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-01-02-24.wav\n",
      "03-01-08-01-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-02-01-24.wav\n",
      "03-01-08-01-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-01-02-02-24.wav\n",
      "03-01-08-01-02-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-01-01-24.wav\n",
      "03-01-08-02-01-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-01-02-24.wav\n",
      "03-01-08-02-01-02-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-02-01-24.wav\n",
      "03-01-08-02-02-01-24.wav\n",
      "C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset\\Actor_24\\03-01-08-02-02-02-24.wav\n",
      "03-01-08-02-02-02-24.wav\n",
      "[+] Number of training samples: 537\n",
      "[+] Number of testing samples: 135\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GO3OzGWt22Sq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray(X_train)\n",
    "y_train= np.asarray(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p_HrHWFo3KFH",
    "outputId": "af800f38-dd0d-4cfa-f9eb-c0dee1d90791"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((537, 180), (537,), (135, 180), (135,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cuGn3O113iVS"
   },
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HmqNzFs85Ck6",
    "outputId": "18ef3b9d-a617-4aa4-9667-b52712b79d3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((537, 180, 1), (135, 180, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape,x_testcnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhBOW8Rk5VKt"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))        #1\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))                           #2\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))                                                 #3\n",
    "model.add(Activation('softmax'))\n",
    "optimizer=keras.optimizers.RMSprop(learning_rate=0.001,\n",
    "    rho=0.9,\n",
    "    epsilon=None,\n",
    "    centered=False,\n",
    "    name='RMSprop'\n",
    ")\n",
    "\n",
    "#opt = keras.optimizers.rmsprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "q5nm0kqP5hV1",
    "outputId": "4cbea3dc-c70e-4613-e05a-07cc5fd246af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 22, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 128)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2816)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 22536     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105,352\n",
      "Trainable params: 105,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "S-fAEnOR5nvH",
    "outputId": "4fc146d4-b84b-42d0-bed9-85beaab3226b"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8960), started 1 day, 2:56:39 ago. (Use '!kill 8960' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-aae73ab0a48abe78\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-aae73ab0a48abe78\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!rm -rf ./logs/\n",
    "import tensorflow\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K6opFz235tL0",
    "outputId": "b509e32f-8d14-477c-d8a1-35e919a159d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 3s 46ms/step - loss: 7.6534 - accuracy: 0.3073 - val_loss: 3.7073 - val_accuracy: 0.2889\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 2.9742 - accuracy: 0.3594 - val_loss: 3.1445 - val_accuracy: 0.3481\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.9623 - accuracy: 0.4134 - val_loss: 1.1853 - val_accuracy: 0.3630\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.4010 - accuracy: 0.4451 - val_loss: 1.5197 - val_accuracy: 0.3407\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3161 - accuracy: 0.4600 - val_loss: 1.0305 - val_accuracy: 0.5481\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.0860 - accuracy: 0.5102 - val_loss: 1.1469 - val_accuracy: 0.5704\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.1023 - accuracy: 0.4898 - val_loss: 1.0632 - val_accuracy: 0.4963\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.0635 - accuracy: 0.5289 - val_loss: 0.8881 - val_accuracy: 0.5926\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.0620 - accuracy: 0.5196 - val_loss: 1.0044 - val_accuracy: 0.5259\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.9922 - accuracy: 0.5624 - val_loss: 1.0138 - val_accuracy: 0.5778\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.9888 - accuracy: 0.5400 - val_loss: 0.9467 - val_accuracy: 0.5926\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.9692 - accuracy: 0.5773 - val_loss: 0.9613 - val_accuracy: 0.5704\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.9660 - accuracy: 0.5587 - val_loss: 0.8747 - val_accuracy: 0.6000\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.8816 - accuracy: 0.6089 - val_loss: 1.0202 - val_accuracy: 0.5852\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.8879 - accuracy: 0.5996 - val_loss: 0.9122 - val_accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.8475 - accuracy: 0.6331 - val_loss: 0.9862 - val_accuracy: 0.6148\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8647 - accuracy: 0.6089 - val_loss: 0.8169 - val_accuracy: 0.6000\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.8453 - accuracy: 0.6350 - val_loss: 0.7440 - val_accuracy: 0.6889\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.7954 - accuracy: 0.6499 - val_loss: 0.7716 - val_accuracy: 0.6519\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.8027 - accuracy: 0.6387 - val_loss: 1.0043 - val_accuracy: 0.4815\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.7888 - accuracy: 0.6443 - val_loss: 0.8102 - val_accuracy: 0.6074\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.7534 - accuracy: 0.6611 - val_loss: 0.8845 - val_accuracy: 0.5852\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.7452 - accuracy: 0.6853 - val_loss: 0.8304 - val_accuracy: 0.6593\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.7283 - accuracy: 0.7114 - val_loss: 0.7753 - val_accuracy: 0.6148\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.7013 - accuracy: 0.7132 - val_loss: 0.8574 - val_accuracy: 0.6000\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.6809 - accuracy: 0.7114 - val_loss: 0.7114 - val_accuracy: 0.6741\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.6839 - accuracy: 0.7039 - val_loss: 0.7083 - val_accuracy: 0.6741\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.6544 - accuracy: 0.7188 - val_loss: 0.7973 - val_accuracy: 0.6000\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 0.6642 - accuracy: 0.7393 - val_loss: 0.7014 - val_accuracy: 0.6593\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.6131 - accuracy: 0.7542 - val_loss: 0.7304 - val_accuracy: 0.6444\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.6084 - accuracy: 0.7449 - val_loss: 0.6833 - val_accuracy: 0.6815\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.6172 - accuracy: 0.7169 - val_loss: 0.6996 - val_accuracy: 0.6519\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.6324 - accuracy: 0.7281 - val_loss: 0.6743 - val_accuracy: 0.7185\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5553 - accuracy: 0.7840 - val_loss: 0.7077 - val_accuracy: 0.6815\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5476 - accuracy: 0.7840 - val_loss: 0.6540 - val_accuracy: 0.6963\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5733 - accuracy: 0.7542 - val_loss: 0.6718 - val_accuracy: 0.7185\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.5365 - accuracy: 0.7970 - val_loss: 0.7461 - val_accuracy: 0.6444\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5425 - accuracy: 0.7821 - val_loss: 0.7602 - val_accuracy: 0.6741\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5285 - accuracy: 0.7858 - val_loss: 0.8261 - val_accuracy: 0.6963\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.5053 - accuracy: 0.7970 - val_loss: 0.6406 - val_accuracy: 0.7481\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4820 - accuracy: 0.8026 - val_loss: 0.9194 - val_accuracy: 0.6296\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4793 - accuracy: 0.8231 - val_loss: 1.2170 - val_accuracy: 0.5481\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4812 - accuracy: 0.8212 - val_loss: 0.6684 - val_accuracy: 0.7185\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4502 - accuracy: 0.8436 - val_loss: 0.6762 - val_accuracy: 0.6815\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4446 - accuracy: 0.8287 - val_loss: 0.7971 - val_accuracy: 0.6519\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4068 - accuracy: 0.8268 - val_loss: 0.7821 - val_accuracy: 0.6444\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4382 - accuracy: 0.8380 - val_loss: 0.8603 - val_accuracy: 0.6741\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4089 - accuracy: 0.8454 - val_loss: 0.7887 - val_accuracy: 0.6815\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.4530 - accuracy: 0.8175 - val_loss: 0.7817 - val_accuracy: 0.7037\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 0.3791 - accuracy: 0.8547 - val_loss: 0.8971 - val_accuracy: 0.6889\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRBYh-bMHucX"
   },
   "outputs": [],
   "source": [
    "em=['happy','sad','neutral','angry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GrrqoLzFAJDq",
    "outputId": "127a4973-55a9-4310-9df2-5d2ccef3f574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step\n",
      "sad\n",
      "[1.3474981e-01 1.6509653e-12 1.5825342e-29 1.1531325e-10 8.6525017e-01\n",
      " 1.3481200e-29 5.8116304e-31 2.4360877e-29]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_testcnn)\n",
    "n=predictions[1]\n",
    "print(em[1])\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CxJc4kIaD9IK",
    "outputId": "943689bb-a472-4a03-fd96-38a5d9e4c69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8971 - accuracy: 0.6889\n",
      "Restored model, accuracy: 68.89%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kVanJ86-FhwS",
    "outputId": "c8194727-9ef5-4e72-d1e2-26c6100cdb74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "result : happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6296\\1163463125.py:31: FutureWarning: Pass y=[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00 0.0000000e+00\n",
      " 3.0517578e-05] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    }
   ],
   "source": [
    "filename = \"C:/Users/hp/MINI_PROJECT-Speech-Emotion-Recognization/dataset/Actor_02/03-01-01-01-02-01-02.wav\"\n",
    "    # record the file (start talking)\n",
    "    #record_to_file(filename)\n",
    "    # extract features and reshape it\n",
    "features = np.array(extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1))\n",
    "    # predict\n",
    "f=np.expand_dims(features,axis=2)\n",
    "result = model.predict(f)[0]\n",
    "    # show the result !\n",
    "print(\"result :\",em[int(result[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1vlkqDPlA8A"
   },
   "source": [
    "**Second**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQR38pmCSaNU"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "um = Sequential()\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
    "um.add(Activation('relu'))\n",
    "um.add(Dropout(0.25))\n",
    "um.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',))                  #2\n",
    "um.add(Activation('relu'))\n",
    "um.add(MaxPooling1D(pool_size=(8)))\n",
    "um.add(Dropout(0.25))\n",
    "\n",
    "um.add(Conv1D(128, 5,padding='same',))                  #3\n",
    "um.add(Activation('relu'))\n",
    "um.add(Dropout(0.25))\n",
    "\n",
    "um.add(Flatten())\n",
    "um.add(Dense(8))                                        #4                      \n",
    "um.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.00005,epsilon=None,rho=0.9,decay=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "xfXWyKwKbNfB",
    "outputId": "af9f6e6f-aa1c-430d-c334-73dcc5606d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 22, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 2, 128)            82048     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,920\n",
      "Trainable params: 166,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "um.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBIGulu3bSaj"
   },
   "outputs": [],
   "source": [
    "um.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0XiAWqd1bg5M",
    "outputId": "7c46bbcc-c4b1-425d-f06d-5f516ac6a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 3s 33ms/step - loss: 10.0141 - accuracy: 0.1899 - val_loss: 1.4867 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 1s 20ms/step - loss: 7.3589 - accuracy: 0.2439 - val_loss: 1.3917 - val_accuracy: 0.4148\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 6.9053 - accuracy: 0.2142 - val_loss: 1.4032 - val_accuracy: 0.4444\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 5.8683 - accuracy: 0.2533 - val_loss: 1.9117 - val_accuracy: 0.4444\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 5.3614 - accuracy: 0.2961 - val_loss: 1.4411 - val_accuracy: 0.5037\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 4.3319 - accuracy: 0.3091 - val_loss: 1.2958 - val_accuracy: 0.4519\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 4.6236 - accuracy: 0.2663 - val_loss: 1.3137 - val_accuracy: 0.4593\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 4.0225 - accuracy: 0.2812 - val_loss: 1.2974 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 3.8388 - accuracy: 0.2737 - val_loss: 1.2516 - val_accuracy: 0.4519\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 3.6170 - accuracy: 0.2812 - val_loss: 1.3269 - val_accuracy: 0.4444\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 3.0726 - accuracy: 0.3222 - val_loss: 1.2529 - val_accuracy: 0.4963\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 3.1597 - accuracy: 0.2942 - val_loss: 1.2940 - val_accuracy: 0.4222\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 2.8173 - accuracy: 0.3203 - val_loss: 1.3453 - val_accuracy: 0.3630\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 2.6057 - accuracy: 0.3203 - val_loss: 1.2687 - val_accuracy: 0.4444\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 2.4051 - accuracy: 0.3259 - val_loss: 1.2969 - val_accuracy: 0.3259\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 2.3654 - accuracy: 0.3296 - val_loss: 1.2363 - val_accuracy: 0.4815\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 2.1539 - accuracy: 0.3557 - val_loss: 1.2431 - val_accuracy: 0.4519\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 2.1160 - accuracy: 0.3445 - val_loss: 1.2560 - val_accuracy: 0.5185\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.9700 - accuracy: 0.3464 - val_loss: 1.2642 - val_accuracy: 0.4963\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.8802 - accuracy: 0.3650 - val_loss: 1.2789 - val_accuracy: 0.4815\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.9127 - accuracy: 0.3371 - val_loss: 1.2752 - val_accuracy: 0.4222\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.8770 - accuracy: 0.3445 - val_loss: 1.2415 - val_accuracy: 0.4889\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.8403 - accuracy: 0.3389 - val_loss: 1.2445 - val_accuracy: 0.4667\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.7631 - accuracy: 0.3445 - val_loss: 1.2322 - val_accuracy: 0.4741\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.7227 - accuracy: 0.3520 - val_loss: 1.2384 - val_accuracy: 0.4963\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.7607 - accuracy: 0.3501 - val_loss: 1.2390 - val_accuracy: 0.5185\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.7116 - accuracy: 0.3557 - val_loss: 1.2439 - val_accuracy: 0.5111\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.6569 - accuracy: 0.3520 - val_loss: 1.2607 - val_accuracy: 0.5111\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.6076 - accuracy: 0.3780 - val_loss: 1.2409 - val_accuracy: 0.5407\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.5963 - accuracy: 0.3333 - val_loss: 1.2339 - val_accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.5759 - accuracy: 0.3780 - val_loss: 1.2544 - val_accuracy: 0.5259\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.5104 - accuracy: 0.3445 - val_loss: 1.2550 - val_accuracy: 0.5407\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.5242 - accuracy: 0.3631 - val_loss: 1.2458 - val_accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.4595 - accuracy: 0.3799 - val_loss: 1.2614 - val_accuracy: 0.5185\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.5375 - accuracy: 0.3333 - val_loss: 1.2726 - val_accuracy: 0.4889\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.4564 - accuracy: 0.3762 - val_loss: 1.2643 - val_accuracy: 0.5185\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3929 - accuracy: 0.4078 - val_loss: 1.2558 - val_accuracy: 0.5185\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.4306 - accuracy: 0.3613 - val_loss: 1.2668 - val_accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.4724 - accuracy: 0.3538 - val_loss: 1.2744 - val_accuracy: 0.5704\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.4191 - accuracy: 0.3836 - val_loss: 1.2568 - val_accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.4088 - accuracy: 0.3687 - val_loss: 1.2479 - val_accuracy: 0.5481\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.4628 - accuracy: 0.3408 - val_loss: 1.2460 - val_accuracy: 0.5185\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.4258 - accuracy: 0.3631 - val_loss: 1.2401 - val_accuracy: 0.4889\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3767 - accuracy: 0.3724 - val_loss: 1.2368 - val_accuracy: 0.4963\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3758 - accuracy: 0.3799 - val_loss: 1.2438 - val_accuracy: 0.5185\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.3923 - accuracy: 0.4060 - val_loss: 1.2456 - val_accuracy: 0.4815\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.3410 - accuracy: 0.3985 - val_loss: 1.2485 - val_accuracy: 0.4815\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.4009 - accuracy: 0.3613 - val_loss: 1.2443 - val_accuracy: 0.4667\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.3712 - accuracy: 0.4097 - val_loss: 1.2474 - val_accuracy: 0.4815\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3474 - accuracy: 0.3929 - val_loss: 1.2503 - val_accuracy: 0.5111\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3172 - accuracy: 0.4246 - val_loss: 1.2455 - val_accuracy: 0.4519\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 1.2894 - accuracy: 0.4395 - val_loss: 1.2354 - val_accuracy: 0.4889\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 1.3581 - accuracy: 0.3706 - val_loss: 1.2448 - val_accuracy: 0.3481\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2828 - accuracy: 0.4264 - val_loss: 1.2378 - val_accuracy: 0.5185\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3469 - accuracy: 0.4153 - val_loss: 1.2389 - val_accuracy: 0.4593\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3542 - accuracy: 0.4004 - val_loss: 1.2039 - val_accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2919 - accuracy: 0.4209 - val_loss: 1.1994 - val_accuracy: 0.5037\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3187 - accuracy: 0.3631 - val_loss: 1.2001 - val_accuracy: 0.5111\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3181 - accuracy: 0.3892 - val_loss: 1.1908 - val_accuracy: 0.4815\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2859 - accuracy: 0.4115 - val_loss: 1.1761 - val_accuracy: 0.4741\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3010 - accuracy: 0.4115 - val_loss: 1.1784 - val_accuracy: 0.5111\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3131 - accuracy: 0.4041 - val_loss: 1.1756 - val_accuracy: 0.5259\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2734 - accuracy: 0.4264 - val_loss: 1.1898 - val_accuracy: 0.5185\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2652 - accuracy: 0.4097 - val_loss: 1.1800 - val_accuracy: 0.4815\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.3062 - accuracy: 0.4134 - val_loss: 1.1985 - val_accuracy: 0.4667\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2533 - accuracy: 0.4320 - val_loss: 1.1880 - val_accuracy: 0.4593\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.2775 - accuracy: 0.4209 - val_loss: 1.1870 - val_accuracy: 0.3926\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.2718 - accuracy: 0.3929 - val_loss: 1.1836 - val_accuracy: 0.4148\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2728 - accuracy: 0.4376 - val_loss: 1.1880 - val_accuracy: 0.4519\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.2554 - accuracy: 0.4209 - val_loss: 1.1664 - val_accuracy: 0.4963\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.2460 - accuracy: 0.3948 - val_loss: 1.1647 - val_accuracy: 0.5185\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2243 - accuracy: 0.4246 - val_loss: 1.1518 - val_accuracy: 0.5259\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2763 - accuracy: 0.4227 - val_loss: 1.1525 - val_accuracy: 0.5111\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2646 - accuracy: 0.3855 - val_loss: 1.1517 - val_accuracy: 0.5259\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.2890 - accuracy: 0.3948 - val_loss: 1.1531 - val_accuracy: 0.5630\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.2491 - accuracy: 0.4097 - val_loss: 1.1514 - val_accuracy: 0.5037\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.2572 - accuracy: 0.4097 - val_loss: 1.1481 - val_accuracy: 0.5407\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2200 - accuracy: 0.4190 - val_loss: 1.1456 - val_accuracy: 0.5259\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2282 - accuracy: 0.4358 - val_loss: 1.1317 - val_accuracy: 0.5556\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2446 - accuracy: 0.4022 - val_loss: 1.1452 - val_accuracy: 0.5037\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2361 - accuracy: 0.4097 - val_loss: 1.1403 - val_accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2533 - accuracy: 0.4227 - val_loss: 1.1527 - val_accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2555 - accuracy: 0.4153 - val_loss: 1.1530 - val_accuracy: 0.5259\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.2136 - accuracy: 0.4097 - val_loss: 1.1448 - val_accuracy: 0.5630\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.2328 - accuracy: 0.4376 - val_loss: 1.1471 - val_accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2064 - accuracy: 0.4115 - val_loss: 1.1540 - val_accuracy: 0.5704\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2151 - accuracy: 0.4488 - val_loss: 1.1654 - val_accuracy: 0.5037\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2145 - accuracy: 0.4302 - val_loss: 1.1499 - val_accuracy: 0.5407\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2449 - accuracy: 0.4358 - val_loss: 1.1417 - val_accuracy: 0.5407\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2145 - accuracy: 0.4246 - val_loss: 1.1510 - val_accuracy: 0.4963\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2375 - accuracy: 0.4358 - val_loss: 1.1389 - val_accuracy: 0.5704\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.2161 - accuracy: 0.4562 - val_loss: 1.1360 - val_accuracy: 0.5259\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.2036 - accuracy: 0.4544 - val_loss: 1.1369 - val_accuracy: 0.4593\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.2235 - accuracy: 0.4078 - val_loss: 1.1410 - val_accuracy: 0.4963\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.1679 - accuracy: 0.4581 - val_loss: 1.1253 - val_accuracy: 0.5185\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.1993 - accuracy: 0.4115 - val_loss: 1.1236 - val_accuracy: 0.5037\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.2280 - accuracy: 0.4227 - val_loss: 1.1246 - val_accuracy: 0.5185\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 1.1841 - accuracy: 0.4302 - val_loss: 1.1297 - val_accuracy: 0.5185\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.2111 - accuracy: 0.4134 - val_loss: 1.1261 - val_accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.1582 - accuracy: 0.4507 - val_loss: 1.1014 - val_accuracy: 0.5259\n"
     ]
    }
   ],
   "source": [
    "umhistory=um.fit(x_traincnn, y_train, batch_size=20, epochs=100, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8960), started 1 day, 2:55:54 ago. (Use '!kill 8960' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-497fba1238f2121\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-497fba1238f2121\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!rm -rf ./logs/\n",
    "import tensorflow\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUtQ8Bwjhcmw",
    "outputId": "e2fb5814-290f-47fe-b4e3-7dbaec5c432d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1014 - accuracy: 0.5259\n",
      "Restored model, accuracy: 52.59%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = um.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Abdy_mt4nABa"
   },
   "source": [
    "**Fourth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V43ptFvXm-bj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "sm = Sequential()\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',input_shape=(180,1)))#1\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "sm.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #2\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(MaxPooling1D(pool_size=(8)))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #3\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Conv1D(128, 5,padding='same',))                  #4\n",
    "sm.add(Activation('relu'))\n",
    "sm.add(Dropout(0.1))\n",
    "\n",
    "sm.add(Flatten())\n",
    "sm.add(Dense(8))                                        #5                     \n",
    "sm.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00005,epsilon=None,rho=0.9,decay=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "YKvLhSPPnG6C",
    "outputId": "dd72e5cf-e6e4-4c84-a7bb-d0e5e0820b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 22, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 2, 128)            82048     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 2, 128)            82048     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,968\n",
      "Trainable params: 248,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPJIfLcGnH0x"
   },
   "outputs": [],
   "source": [
    "sm.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K51eTwPjnIGJ",
    "outputId": "82569664-abb9-4322-8290-f724a128949b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 4s 43ms/step - loss: 3.0166 - accuracy: 0.2104 - val_loss: 1.4519 - val_accuracy: 0.3407\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 2.1454 - accuracy: 0.2663 - val_loss: 1.3476 - val_accuracy: 0.4296\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 2.0680 - accuracy: 0.2719 - val_loss: 1.3594 - val_accuracy: 0.4222\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.8225 - accuracy: 0.3035 - val_loss: 1.3261 - val_accuracy: 0.4222\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.6746 - accuracy: 0.3073 - val_loss: 1.2878 - val_accuracy: 0.4519\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.7217 - accuracy: 0.2905 - val_loss: 1.2452 - val_accuracy: 0.4593\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.5960 - accuracy: 0.3259 - val_loss: 1.2544 - val_accuracy: 0.4519\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.5902 - accuracy: 0.3184 - val_loss: 1.2352 - val_accuracy: 0.4519\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.5709 - accuracy: 0.3259 - val_loss: 1.2058 - val_accuracy: 0.4815\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.4317 - accuracy: 0.3669 - val_loss: 1.2161 - val_accuracy: 0.4593\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.4089 - accuracy: 0.3445 - val_loss: 1.1919 - val_accuracy: 0.4741\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.4452 - accuracy: 0.3575 - val_loss: 1.1825 - val_accuracy: 0.4889\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.4044 - accuracy: 0.3669 - val_loss: 1.1902 - val_accuracy: 0.4889\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.3962 - accuracy: 0.3613 - val_loss: 1.1834 - val_accuracy: 0.5111\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.3628 - accuracy: 0.3780 - val_loss: 1.1741 - val_accuracy: 0.4889\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.3393 - accuracy: 0.3892 - val_loss: 1.1680 - val_accuracy: 0.5185\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.3175 - accuracy: 0.4004 - val_loss: 1.1530 - val_accuracy: 0.5111\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.3512 - accuracy: 0.3799 - val_loss: 1.1621 - val_accuracy: 0.5037\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.3226 - accuracy: 0.3873 - val_loss: 1.1593 - val_accuracy: 0.4963\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.2706 - accuracy: 0.4153 - val_loss: 1.1515 - val_accuracy: 0.4815\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.3246 - accuracy: 0.3892 - val_loss: 1.1506 - val_accuracy: 0.5037\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.3309 - accuracy: 0.3482 - val_loss: 1.1432 - val_accuracy: 0.5185\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.2549 - accuracy: 0.4022 - val_loss: 1.1586 - val_accuracy: 0.4222\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.2907 - accuracy: 0.4004 - val_loss: 1.1324 - val_accuracy: 0.5407\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.2703 - accuracy: 0.4153 - val_loss: 1.1304 - val_accuracy: 0.4963\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.2311 - accuracy: 0.4134 - val_loss: 1.1305 - val_accuracy: 0.5407\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.2862 - accuracy: 0.4004 - val_loss: 1.1182 - val_accuracy: 0.5111\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.2480 - accuracy: 0.4320 - val_loss: 1.1093 - val_accuracy: 0.5185\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.2358 - accuracy: 0.4153 - val_loss: 1.0932 - val_accuracy: 0.5333\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 1.1963 - accuracy: 0.4171 - val_loss: 1.1101 - val_accuracy: 0.4444\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 1.2524 - accuracy: 0.4115 - val_loss: 1.0893 - val_accuracy: 0.5259\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.2116 - accuracy: 0.4413 - val_loss: 1.0755 - val_accuracy: 0.5407\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.2017 - accuracy: 0.4283 - val_loss: 1.0819 - val_accuracy: 0.5407\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.2151 - accuracy: 0.4358 - val_loss: 1.0667 - val_accuracy: 0.5185\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.2122 - accuracy: 0.4190 - val_loss: 1.0494 - val_accuracy: 0.5481\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.2178 - accuracy: 0.4283 - val_loss: 1.0474 - val_accuracy: 0.5407\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.1875 - accuracy: 0.4451 - val_loss: 1.0405 - val_accuracy: 0.5111\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1.2208 - accuracy: 0.4264 - val_loss: 1.0620 - val_accuracy: 0.5481\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.1806 - accuracy: 0.4581 - val_loss: 1.0385 - val_accuracy: 0.5333\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 1.2028 - accuracy: 0.4320 - val_loss: 1.0391 - val_accuracy: 0.5481\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.1751 - accuracy: 0.4004 - val_loss: 1.0471 - val_accuracy: 0.5852\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1.1626 - accuracy: 0.4581 - val_loss: 1.0531 - val_accuracy: 0.5556\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.1938 - accuracy: 0.4507 - val_loss: 1.0285 - val_accuracy: 0.5407\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1.1682 - accuracy: 0.4451 - val_loss: 1.0259 - val_accuracy: 0.5704\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 1.1639 - accuracy: 0.4600 - val_loss: 1.0217 - val_accuracy: 0.5926\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 1.1841 - accuracy: 0.4339 - val_loss: 1.0512 - val_accuracy: 0.5037\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.1323 - accuracy: 0.4711 - val_loss: 1.0456 - val_accuracy: 0.5259\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.1690 - accuracy: 0.4432 - val_loss: 1.0236 - val_accuracy: 0.5852\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 1.1617 - accuracy: 0.4562 - val_loss: 1.0307 - val_accuracy: 0.5333\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.1594 - accuracy: 0.4432 - val_loss: 1.0364 - val_accuracy: 0.5630\n"
     ]
    }
   ],
   "source": [
    "smhistory=sm.fit(x_traincnn, y_train, batch_size=20, epochs=50, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8960), started 1 day, 2:56:39 ago. (Use '!kill 8960' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6d153540e7bc7115\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6d153540e7bc7115\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!rm -rf ./logs/\n",
    "import tensorflow\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LBS8v4sWnIjJ",
    "outputId": "34487bd9-7587-4805-a2e6-9f19e8e9e419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0364 - accuracy: 0.5630\n",
      "Restored model, accuracy: 56.30%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = sm.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 180, 64)           16896     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,440\n",
      "Trainable params: 50,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_LSTM=Sequential()\n",
    "model_LSTM.add(layers.LSTM(64,return_sequences=True,input_shape=(180,1)))\n",
    "model_LSTM.add(layers.LSTM(64))\n",
    "model_LSTM.add(layers.Dense(8,activation='softmax'))\n",
    "print(model_LSTM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 15s 246ms/step - loss: 2.0730 - accuracy: 0.2868 - val_loss: 2.0664 - val_accuracy: 0.3111\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 2.0592 - accuracy: 0.2831 - val_loss: 2.0492 - val_accuracy: 0.3037\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 2.0371 - accuracy: 0.2812 - val_loss: 2.0200 - val_accuracy: 0.3037\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 5s 179ms/step - loss: 1.9975 - accuracy: 0.2812 - val_loss: 1.9638 - val_accuracy: 0.3037\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 5s 185ms/step - loss: 1.9119 - accuracy: 0.2812 - val_loss: 1.8328 - val_accuracy: 0.3037\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 5s 182ms/step - loss: 1.7316 - accuracy: 0.2812 - val_loss: 1.6157 - val_accuracy: 0.3037\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 5s 187ms/step - loss: 1.5800 - accuracy: 0.2812 - val_loss: 1.5073 - val_accuracy: 0.3037\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 5s 187ms/step - loss: 1.5090 - accuracy: 0.2812 - val_loss: 1.4514 - val_accuracy: 0.3037\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.4668 - accuracy: 0.2812 - val_loss: 1.4209 - val_accuracy: 0.3037\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.4382 - accuracy: 0.2812 - val_loss: 1.3977 - val_accuracy: 0.3037\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 5s 192ms/step - loss: 1.4166 - accuracy: 0.3501 - val_loss: 1.3824 - val_accuracy: 0.4296\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 5s 195ms/step - loss: 1.4002 - accuracy: 0.3780 - val_loss: 1.3660 - val_accuracy: 0.4593\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 5s 180ms/step - loss: 1.3837 - accuracy: 0.3669 - val_loss: 1.3535 - val_accuracy: 0.5111\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 1.3705 - accuracy: 0.3855 - val_loss: 1.3330 - val_accuracy: 0.4593\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.3556 - accuracy: 0.3855 - val_loss: 1.3166 - val_accuracy: 0.4963\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.3434 - accuracy: 0.3985 - val_loss: 1.3038 - val_accuracy: 0.4667\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.3281 - accuracy: 0.3799 - val_loss: 1.2902 - val_accuracy: 0.4815\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.3181 - accuracy: 0.3929 - val_loss: 1.2690 - val_accuracy: 0.4889\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.3070 - accuracy: 0.3911 - val_loss: 1.2554 - val_accuracy: 0.4889\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.2926 - accuracy: 0.4190 - val_loss: 1.2536 - val_accuracy: 0.4519\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.2868 - accuracy: 0.3892 - val_loss: 1.2328 - val_accuracy: 0.4889\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 1.2777 - accuracy: 0.3966 - val_loss: 1.2169 - val_accuracy: 0.4889\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 1.2671 - accuracy: 0.4320 - val_loss: 1.2100 - val_accuracy: 0.5185\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 1.2538 - accuracy: 0.4264 - val_loss: 1.2006 - val_accuracy: 0.4963\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.2548 - accuracy: 0.4134 - val_loss: 1.1916 - val_accuracy: 0.4963\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.2450 - accuracy: 0.4376 - val_loss: 1.1958 - val_accuracy: 0.4963\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.2346 - accuracy: 0.4171 - val_loss: 1.1744 - val_accuracy: 0.4815\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.2346 - accuracy: 0.4227 - val_loss: 1.1689 - val_accuracy: 0.4815\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.2281 - accuracy: 0.4227 - val_loss: 1.1627 - val_accuracy: 0.4741\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 1.2228 - accuracy: 0.4320 - val_loss: 1.1643 - val_accuracy: 0.5185\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.2227 - accuracy: 0.4358 - val_loss: 1.1550 - val_accuracy: 0.5037\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.2144 - accuracy: 0.4395 - val_loss: 1.1650 - val_accuracy: 0.5037\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.2157 - accuracy: 0.4339 - val_loss: 1.1463 - val_accuracy: 0.5037\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.2094 - accuracy: 0.4283 - val_loss: 1.1406 - val_accuracy: 0.5037\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.2089 - accuracy: 0.4339 - val_loss: 1.1373 - val_accuracy: 0.4963\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1998 - accuracy: 0.4525 - val_loss: 1.1356 - val_accuracy: 0.5111\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 1.1988 - accuracy: 0.4376 - val_loss: 1.1316 - val_accuracy: 0.5111\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1997 - accuracy: 0.4451 - val_loss: 1.1291 - val_accuracy: 0.5259\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 1.1965 - accuracy: 0.4637 - val_loss: 1.1403 - val_accuracy: 0.4963\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 4s 163ms/step - loss: 1.1904 - accuracy: 0.4320 - val_loss: 1.1658 - val_accuracy: 0.4815\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 1.1917 - accuracy: 0.4432 - val_loss: 1.1222 - val_accuracy: 0.5185\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1858 - accuracy: 0.4432 - val_loss: 1.1781 - val_accuracy: 0.4815\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.1851 - accuracy: 0.4432 - val_loss: 1.1123 - val_accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1759 - accuracy: 0.4562 - val_loss: 1.1249 - val_accuracy: 0.5185\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.1822 - accuracy: 0.4600 - val_loss: 1.1076 - val_accuracy: 0.5407\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.1764 - accuracy: 0.4469 - val_loss: 1.1068 - val_accuracy: 0.5259\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.1720 - accuracy: 0.4618 - val_loss: 1.1045 - val_accuracy: 0.5259\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.1706 - accuracy: 0.4544 - val_loss: 1.1016 - val_accuracy: 0.5407\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.1709 - accuracy: 0.4525 - val_loss: 1.0975 - val_accuracy: 0.5481\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.1708 - accuracy: 0.4562 - val_loss: 1.1015 - val_accuracy: 0.5111\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.1669 - accuracy: 0.4618 - val_loss: 1.0957 - val_accuracy: 0.5407\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 1.1652 - accuracy: 0.4469 - val_loss: 1.0908 - val_accuracy: 0.5185\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1652 - accuracy: 0.4488 - val_loss: 1.0888 - val_accuracy: 0.5259\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.1626 - accuracy: 0.4562 - val_loss: 1.0857 - val_accuracy: 0.5481\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.1610 - accuracy: 0.4618 - val_loss: 1.0847 - val_accuracy: 0.5407\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.1624 - accuracy: 0.4581 - val_loss: 1.1048 - val_accuracy: 0.5037\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1583 - accuracy: 0.4600 - val_loss: 1.0946 - val_accuracy: 0.4963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 1.1566 - accuracy: 0.4600 - val_loss: 1.0798 - val_accuracy: 0.5111\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 1.1573 - accuracy: 0.4525 - val_loss: 1.0875 - val_accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 1.1492 - accuracy: 0.4637 - val_loss: 1.0817 - val_accuracy: 0.5481\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.1514 - accuracy: 0.4637 - val_loss: 1.0908 - val_accuracy: 0.5037\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.1571 - accuracy: 0.4525 - val_loss: 1.0918 - val_accuracy: 0.5185\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.1506 - accuracy: 0.4600 - val_loss: 1.0724 - val_accuracy: 0.5407\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.1499 - accuracy: 0.4581 - val_loss: 1.0697 - val_accuracy: 0.5185\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1478 - accuracy: 0.4637 - val_loss: 1.0680 - val_accuracy: 0.5111\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 1.1503 - accuracy: 0.4693 - val_loss: 1.0668 - val_accuracy: 0.5111\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1453 - accuracy: 0.4749 - val_loss: 1.0848 - val_accuracy: 0.5259\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.1435 - accuracy: 0.4655 - val_loss: 1.0646 - val_accuracy: 0.5185\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1376 - accuracy: 0.4637 - val_loss: 1.0625 - val_accuracy: 0.5407\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1432 - accuracy: 0.4655 - val_loss: 1.0613 - val_accuracy: 0.5111\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.1396 - accuracy: 0.4767 - val_loss: 1.0587 - val_accuracy: 0.5037\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1378 - accuracy: 0.4693 - val_loss: 1.0599 - val_accuracy: 0.5111\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 1.1378 - accuracy: 0.4730 - val_loss: 1.0571 - val_accuracy: 0.5037\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1397 - accuracy: 0.4655 - val_loss: 1.0558 - val_accuracy: 0.5481\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1367 - accuracy: 0.4674 - val_loss: 1.0531 - val_accuracy: 0.5185\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1354 - accuracy: 0.4749 - val_loss: 1.0574 - val_accuracy: 0.5407\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1309 - accuracy: 0.4544 - val_loss: 1.0483 - val_accuracy: 0.5037\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.1290 - accuracy: 0.4730 - val_loss: 1.0482 - val_accuracy: 0.5259\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 1.1299 - accuracy: 0.4823 - val_loss: 1.0455 - val_accuracy: 0.5407\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 1.1295 - accuracy: 0.4730 - val_loss: 1.0439 - val_accuracy: 0.5259\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.1265 - accuracy: 0.4730 - val_loss: 1.0577 - val_accuracy: 0.5407\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 1.1278 - accuracy: 0.4767 - val_loss: 1.0562 - val_accuracy: 0.5481\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1241 - accuracy: 0.4767 - val_loss: 1.0484 - val_accuracy: 0.5407\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1252 - accuracy: 0.4730 - val_loss: 1.0360 - val_accuracy: 0.5481\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.1197 - accuracy: 0.4823 - val_loss: 1.0337 - val_accuracy: 0.5481\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1221 - accuracy: 0.4823 - val_loss: 1.0316 - val_accuracy: 0.5407\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 1.1191 - accuracy: 0.4860 - val_loss: 1.0375 - val_accuracy: 0.5185\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 1.1145 - accuracy: 0.4823 - val_loss: 1.0981 - val_accuracy: 0.5259\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 1.1180 - accuracy: 0.4749 - val_loss: 1.0278 - val_accuracy: 0.5556\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1214 - accuracy: 0.4767 - val_loss: 1.0230 - val_accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1119 - accuracy: 0.4879 - val_loss: 1.0374 - val_accuracy: 0.5556\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.1108 - accuracy: 0.4991 - val_loss: 1.0203 - val_accuracy: 0.5556\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1170 - accuracy: 0.4842 - val_loss: 1.0178 - val_accuracy: 0.5556\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1114 - accuracy: 0.4804 - val_loss: 1.0221 - val_accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.1124 - accuracy: 0.4953 - val_loss: 1.0132 - val_accuracy: 0.5185\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 1.1104 - accuracy: 0.4916 - val_loss: 1.0089 - val_accuracy: 0.5556\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.1186 - accuracy: 0.4767 - val_loss: 1.0084 - val_accuracy: 0.5259\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 1.1091 - accuracy: 0.4898 - val_loss: 1.0125 - val_accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 1.1085 - accuracy: 0.4991 - val_loss: 1.0082 - val_accuracy: 0.5407\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 1.1004 - accuracy: 0.4879 - val_loss: 1.0023 - val_accuracy: 0.5185\n"
     ]
    }
   ],
   "source": [
    "umhistory=model_LSTM.fit(x_traincnn, y_train, batch_size=20, epochs=100, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 64ms/step - loss: 1.0023 - accuracy: 0.5185\n",
      "Restored model, accuracy: 51.85%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_LSTM.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8960), started 1 day, 3:17:01 ago. (Use '!kill 8960' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7a8755e96f61cb2f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7a8755e96f61cb2f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!rm -rf ./logs/\n",
    "import tensorflow\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback=tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOQfsKtSS2nu7fsGE+IWtmN",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CNN_SpeechEmotion.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
